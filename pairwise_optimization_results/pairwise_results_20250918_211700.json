{
  "metadata": {
    "timestamp": "2025-09-18T21:17:00.659362",
    "total_tasks": 100,
    "successful_tasks": 100
  },
  "results": [
    {
      "task_id": "a75a3291-a745-40d4-b631-fd2804c65c4f",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.046511627906976744,
        "mapping_precision": 0.07692307692307693,
        "mapping_recall": 0.10526315789473684,
        "mapping_f1_score": 0.08888888888888889,
        "mapping_true_positives": 2,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 17,
        "gold_mappings_count": 23,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9021739130434783,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "Procedure=\"387713003\""
        ],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\"",
          "CancerCondition=\"C1268991\""
        ],
        "false_negative_examples": [
          "ResearchStudy=\"R-00317\"",
          "MedicationStatement=\"387458008\"",
          "ClinicalTrial=\"n/a\"",
          "PatientCharacteristic=\"263495000\"",
          "CancerDiseaseStatus=\"373066001\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.010833740234375
    },
    {
      "task_id": "c9c84cae-cd3f-4fbd-997a-6a619230daf6",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.28125,
        "mapping_precision": 0.47368421052631576,
        "mapping_recall": 0.4090909090909091,
        "mapping_f1_score": 0.43902439024390244,
        "mapping_true_positives": 9,
        "mapping_false_positives": 10,
        "mapping_false_negatives": 13,
        "gold_mappings_count": 28,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9107142857142857,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "Condition=\"I51.9\"",
          "ResearchStudy=\"NCT00386685\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "Observation=\"LP998223-8\"",
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "Observation=\"21908-9\""
        ],
        "false_negative_examples": [
          "GenomicVariant=\"LA14042-8\"",
          "MedicationStatement=\"L01XC01\"",
          "MedicationStatement=\"XRP9881\"",
          "ResearchStudy=\"secondary\"",
          "MedicationStatement=\"386872004\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 24.1849422454834
    },
    {
      "task_id": "2ee3ddf7-b379-4a97-bd48-28b4c600a9a0",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.10526315789473684,
        "mapping_precision": 0.14285714285714285,
        "mapping_recall": 0.2857142857142857,
        "mapping_f1_score": 0.19047619047619047,
        "mapping_true_positives": 4,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 17,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9764705882352942,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:1100\"",
          "GenomicVariant=\"HGNC:1101\"",
          "CancerCondition=\"254837009\"",
          "Procedure=\"396487001\""
        ],
        "false_positive_examples": [
          "Patient=\"50\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"21894-1\"",
          "CancerCondition=\"C1290384\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"126906006\"",
          "CancerCondition=\"109838007\"",
          "CancerCondition=\"254582000\"",
          "CancerRelatedRadiationProcedure=\"108290001\"",
          "Observation=\"385669000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 27.26912498474121
    },
    {
      "task_id": "a5e126c5-75ec-49cf-aaba-4eb4b0d0616c",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-chat",
      "metrics": {
        "mapping_jaccard_similarity": 0.352112676056338,
        "mapping_precision": 0.5102040816326531,
        "mapping_recall": 0.5319148936170213,
        "mapping_f1_score": 0.5208333333333334,
        "mapping_true_positives": 25,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 22,
        "gold_mappings_count": 51,
        "comp_mappings_count": 54,
        "gold_avg_confidence": 0.85,
        "comp_avg_confidence": 0.8351851851851853,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Patient=\"BG001\"",
          "Observation=\"69453-9\"",
          "ECOGPerformanceStatus=\"LA9623-5\""
        ],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"LOINC_PLACEHOLDER\"",
          "Observation=\"72107-6\"",
          "Observation=\"77994-7\"",
          "CancerRelatedSurgicalProcedure=\"446551000124108\"",
          "GenomicVariant=\"LA26606-1\""
        ],
        "false_negative_examples": [
          "Patient=\"305780008\"",
          "Observation=\"72171-2\"",
          "CancerDiseaseStatus=\"385633008\"",
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerRelatedRadiationProcedure=\"LA28873-6\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 30.259370803833008
    },
    {
      "task_id": "4c00c7bd-9771-4642-9186-18b20c8633b6",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_simple_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.15789473684210525,
        "mapping_precision": 0.2553191489361702,
        "mapping_recall": 0.2926829268292683,
        "mapping_f1_score": 0.2727272727272727,
        "mapping_true_positives": 12,
        "mapping_false_positives": 35,
        "mapping_false_negatives": 29,
        "gold_mappings_count": 53,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.8650943396226415,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.919\"",
          "CancerCondition=\"C91110\"",
          "CancerCondition=\"363346000\""
        ],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\"",
          "Observation=\"69453-9\"",
          "ECOGPerformanceStatus=\"LA9623-5\""
        ],
        "false_negative_examples": [
          "Patient=\"72892002\"",
          "ClinicalTrial=\"clinical-trial\"",
          "GenomicVariant=\"LA26609-4\"",
          "Patient=\"442083009\"",
          "Patient=\"424144002\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 9.232282638549805
    },
    {
      "task_id": "0e19d621-bb3d-4cc9-be1c-c1517f1dba6d",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.030303030303030304,
        "mapping_precision": 0.0425531914893617,
        "mapping_recall": 0.09523809523809523,
        "mapping_f1_score": 0.0588235294117647,
        "mapping_true_positives": 2,
        "mapping_false_positives": 45,
        "mapping_false_negatives": 19,
        "gold_mappings_count": 55,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.7354545454545455,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "Procedure=\"387713003\""
        ],
        "false_positive_examples": [
          "Condition=\"E10.9\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\"",
          "Observation=\"33728-7\"",
          "Observation=\"2160-0\""
        ],
        "false_negative_examples": [
          "Observation=\"unknown\"",
          "StudyDesign=\"NA\"",
          "Observation=\"1182471000000100\"",
          "Finding=\"165889000\"",
          "StudyDesign=\"OTHER\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 21.710872650146484
    },
    {
      "task_id": "bcc72bbb-650d-4ac6-abdd-b0fbdf7ecd98",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_simple_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.11904761904761904,
        "mapping_precision": 0.2631578947368421,
        "mapping_recall": 0.17857142857142858,
        "mapping_f1_score": 0.2127659574468085,
        "mapping_true_positives": 5,
        "mapping_false_positives": 14,
        "mapping_false_negatives": 23,
        "gold_mappings_count": 34,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9352941176470588,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "ResearchStudy=\"NCT00386685\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "Observation=\"LP998223-8\"",
          "Condition=\"I51.9\"",
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\""
        ],
        "false_negative_examples": [
          "ResearchStudy.primaryPurposeType=\"TREATMENT\"",
          "ECOGPerformanceStatus=\"LA9622-7\"",
          "Patient=\"LA10402-1\"",
          "MedicationStatement=\"763158003\"",
          "Comorbidity=\"I50.9\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 5.150318145751953
    },
    {
      "task_id": "e65d305b-c88a-4fc7-b26f-239ae2110d42",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_simple_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.10256410256410256,
        "mapping_precision": 0.14285714285714285,
        "mapping_recall": 0.26666666666666666,
        "mapping_f1_score": 0.18604651162790697,
        "mapping_true_positives": 4,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 17,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9617647058823531,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:1100\"",
          "GenomicVariant=\"HGNC:1101\"",
          "CancerCondition=\"254837009\"",
          "Procedure=\"396487001\""
        ],
        "false_positive_examples": [
          "Patient=\"50\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"21894-1\"",
          "CancerCondition=\"C1290384\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"254982004\"",
          "Observation=\"385432009\"",
          "CancerRelatedRadiationProcedure=\"108290001\"",
          "CancerCondition=\"93761005\"",
          "CancerStageGroup=\"cM0\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 6.992101669311523
    },
    {
      "task_id": "0fcb2376-c9f0-4816-adb5-7350acae5e83",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 264.4031047821045
    },
    {
      "task_id": "bca959c9-4cee-4f3f-955c-1c4d4d0691ff",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 265.9029960632324
    },
    {
      "task_id": "79312ef3-da37-4677-b8aa-b0b389b2cab3",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"50\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "ResearchStudy=\"research-study\"",
          "CancerRelatedSurgicalProcedure=\"236627004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 243.47186088562012
    },
    {
      "task_id": "7c5ebbda-84f5-4f86-b97b-e71dd5387b23",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_simple_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 238.56401443481445
    },
    {
      "task_id": "a01d9818-9220-4584-a9cc-395477cdb920",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-chat",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0,
        "mapping_recall": 0.0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 0,
        "mapping_false_negatives": 26,
        "gold_mappings_count": 31,
        "comp_mappings_count": 0,
        "gold_avg_confidence": 0.8951612903225806,
        "comp_avg_confidence": 0,
        "true_positive_examples": [],
        "false_positive_examples": [],
        "false_negative_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.0
      },
      "status": "Success",
      "duration_ms": 269.23370361328125
    },
    {
      "task_id": "36addf07-cea1-4a6d-9f8b-f4741feec671",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_simple_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "AdverseEvent=\"419620001\"",
          "Condition=\"E10.9\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 231.46295547485352
    },
    {
      "task_id": "e73296cb-d83a-4460-851a-7c30e54fe34a",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "AdverseEvent=\"419620001\"",
          "Condition=\"E10.9\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 270.6871032714844
    },
    {
      "task_id": "1efbc33e-6d3d-4578-a49f-d7deb2f0cc6a",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_simple_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 222.49102592468262
    },
    {
      "task_id": "0e9cffee-7da7-44cc-a62d-67d60fc91cce",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_simple_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.046511627906976744,
        "mapping_precision": 0.07692307692307693,
        "mapping_recall": 0.10526315789473684,
        "mapping_f1_score": 0.08888888888888889,
        "mapping_true_positives": 2,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 17,
        "gold_mappings_count": 23,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.8913043478260869,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "Patient=\"424144002\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\"",
          "CancerCondition=\"C1268991\""
        ],
        "false_negative_examples": [
          "StudyDesign=\"RANDOMIZED\"",
          "Treatment=\"372897005\"",
          "MedicationStatement=\"387207008\"",
          "CancerCondition=\"399068003\"",
          "ClinicalTrial=\"N/A\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 13.721942901611328
    },
    {
      "task_id": "603f16bd-4477-40d4-acc5-d5b6e3515710",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_simple_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 14.806985855102539
    },
    {
      "task_id": "2b15f0d1-f5b1-4264-b4a9-1447dbb723e9",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_simple_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0136986301369863,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.037037037037037035,
        "mapping_f1_score": 0.027027027027027025,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 26,
        "gold_mappings_count": 50,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.358,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Condition=\"E10.9\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\"",
          "Observation=\"33728-7\"",
          "Observation=\"2160-0\""
        ],
        "false_negative_examples": [
          "MedicalHistory=\"271681001\"",
          "TumorSize=\"408732007\"",
          "ObservationResult=\"unknown\"",
          "StudyDesign=\"NA\"",
          "ProcedureIntent=\"394701000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.9898738861084
    },
    {
      "task_id": "4e90b696-8b5b-49bf-80ee-90138ec29235",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_comprehensive_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06896551724137931,
        "mapping_precision": 0.10526315789473684,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.12903225806451615,
        "mapping_true_positives": 2,
        "mapping_false_positives": 17,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 17,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9029411764705882,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:3430\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "Observation=\"LP998223-8\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedication=\"L01XC01\"",
          "CancerCondition=\"C4872\"",
          "CancerRelatedMedication=\"763875007\"",
          "GenomicVariant=\"LA6576-8\"",
          "CancerCondition=\"C9115000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.614032745361328
    },
    {
      "task_id": "67306beb-e68f-408b-ae66-89635b720950",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_simple_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"50\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "ResearchStudy=\"research-study\"",
          "CancerRelatedSurgicalProcedure=\"236627004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 19.830703735351562
    },
    {
      "task_id": "aa036d4e-fc35-41b2-a1b1-a26fc4230edf",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_comprehensive_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.272804260253906
    },
    {
      "task_id": "d6760ae9-4a4d-4c21-a760-8863030437d8",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_comprehensive_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03571428571428571,
        "mapping_precision": 0.0425531914893617,
        "mapping_recall": 0.18181818181818182,
        "mapping_f1_score": 0.06896551724137931,
        "mapping_true_positives": 2,
        "mapping_false_positives": 45,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 14,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.9142857142857144,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerDiseaseStatus=\"268910001\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\"",
          "Observation=\"69453-9\""
        ],
        "false_negative_examples": [
          "TNMClinicalStageGroup=\"21908-9\"",
          "GenomicVariant=\"C1706430\"",
          "CancerCondition=\"C4872\"",
          "GenomicVariant=\"C1706426\"",
          "GenomicVariant=\"C1706428\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.982099533081055
    },
    {
      "task_id": "4e7cf3c0-5594-42cd-829e-8899b4812ccc",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_comprehensive_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "AdverseEvent=\"419620001\"",
          "Condition=\"E10.9\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.690752029418945
    },
    {
      "task_id": "46b07e53-da73-472c-9ce9-665057778133",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_comprehensive_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02702702702702703,
        "mapping_precision": 0.03571428571428571,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.05263157894736841,
        "mapping_true_positives": 1,
        "mapping_false_positives": 27,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 13,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9423076923076923,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"50\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"21894-1\"",
          "CancerCondition=\"C1290384\""
        ],
        "false_negative_examples": [
          "CancerRelatedProcedure=\"387713003\"",
          "CancerRelatedProcedure=\"108290001\"",
          "CancerRelatedProcedure=\"129286009\"",
          "GenomicVariant=\"UO:0001699\"",
          "CancerDiseaseStatus=\"260415000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 12.183904647827148
    },
    {
      "task_id": "64d3267a-33f3-491d-8c29-dd210bd22e9f",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_comprehensive_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03125,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.14285714285714285,
        "mapping_f1_score": 0.060606060606060615,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 6,
        "gold_mappings_count": 12,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9041666666666667,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\"",
          "CancerCondition=\"C1268991\""
        ],
        "false_negative_examples": [
          "CancerRelatedProcedure=\"387713003\"",
          "CancerRelatedMedication=\"367336001\"",
          "CancerRelatedMedication=\"387207008\"",
          "CancerDiseaseStatus=\"261665006\"",
          "CancerRelatedProcedure=\"448385000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 13.808727264404297
    },
    {
      "task_id": "eee658fc-9f48-41b7-935a-f276fe495b1e",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_comprehensive_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 13.273954391479492
    },
    {
      "task_id": "cbe99094-11c3-4e91-b5f6-d611d7ac1f01",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_comprehensive_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.018518518518518517,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.125,
        "mapping_f1_score": 0.03636363636363636,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 7,
        "gold_mappings_count": 9,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.8166666666666667,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\"",
          "Observation=\"69453-9\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"C4872\"",
          "GenomicVariant=\"HER2\"",
          "TNMClinicalStageGroup=\"C77.4\"",
          "GenomicVariant=\"PR\"",
          "GenomicVariant=\"ER\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.590139389038086
    },
    {
      "task_id": "a726b988-f605-46de-858a-3e21a34a8476",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_comprehensive_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.016666666666666666,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.07142857142857142,
        "mapping_f1_score": 0.032786885245901634,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 13,
        "gold_mappings_count": 59,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.6728813559322034,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Condition=\"E10.9\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\"",
          "Observation=\"33728-7\"",
          "Observation=\"2160-0\""
        ],
        "false_negative_examples": [
          "CancerRelatedProcedure=\"387713003\"",
          "ECOGPerformanceStatus=\"271674006\"",
          "CancerCondition=\"NA\"",
          "CancerRelatedProcedure=\"NA\"",
          "CancerCondition=\"363346000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.762184143066406
    },
    {
      "task_id": "9ba455b9-d6d0-4f47-bf55-8fa887a6ec16",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_comprehensive_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"50\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "ResearchStudy=\"research-study\"",
          "CancerRelatedSurgicalProcedure=\"236627004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 18.397808074951172
    },
    {
      "task_id": "e8ed2bb7-d59d-4222-86ed-3da791d04831",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_minimal_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06060606060606061,
        "mapping_precision": 0.10526315789473684,
        "mapping_recall": 0.125,
        "mapping_f1_score": 0.11428571428571428,
        "mapping_true_positives": 2,
        "mapping_false_positives": 17,
        "mapping_false_negatives": 14,
        "gold_mappings_count": 21,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.8500000000000001,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:3430\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "Observation=\"LP998223-8\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [
          "TNMClinicalStageGroup=\"C80.1\"",
          "CancerRelatedMedicationAdministration=\"386452007\"",
          "GenomicVariant=\"LA6576-8\"",
          "CancerRelatedSurgicalProcedure=\"236627004\"",
          "Comorbidity=\"I51.9\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.540838241577148
    },
    {
      "task_id": "679b165f-9dbc-43e4-9d70-3a34b866d052",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_minimal_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.047619047619047616,
        "mapping_precision": 0.0851063829787234,
        "mapping_recall": 0.0975609756097561,
        "mapping_f1_score": 0.09090909090909091,
        "mapping_true_positives": 4,
        "mapping_false_positives": 43,
        "mapping_false_negatives": 37,
        "gold_mappings_count": 43,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.7895348837209303,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"C50.919\"",
          "CancerCondition=\"C50.9\"",
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\"",
          "Observation=\"69453-9\""
        ],
        "false_negative_examples": [
          "RadiotherapyCourseSummary=\"LA10428-4\"",
          "CancerRelatedSurgicalProcedure=\"254837009\"",
          "GenomicVariant=\"C1705169\"",
          "Family member=\"72705000\"",
          "Geographic location=\"77983-7\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.222736358642578
    },
    {
      "task_id": "5e8a2bfb-5dac-4703-bf22-6a7ad5e0b188",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_minimal_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.629146575927734
    },
    {
      "task_id": "bb744252-b567-40a5-a28e-64a7d593288f",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_minimal_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06521739130434782,
        "mapping_precision": 0.10714285714285714,
        "mapping_recall": 0.14285714285714285,
        "mapping_f1_score": 0.12244897959183672,
        "mapping_true_positives": 3,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 18,
        "gold_mappings_count": 23,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9456521739130435,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "Condition=\"254837009\"",
          "CancerCondition=\"254837009\"",
          "Procedure=\"396487001\""
        ],
        "false_positive_examples": [
          "Patient=\"50\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"21894-1\"",
          "CancerCondition=\"C1290384\""
        ],
        "false_negative_examples": [
          "Procedure=\"443402002\"",
          "Observation=\"44662000\"",
          "Observation=\"405746006\"",
          "Observation=\"252416005\"",
          "Observation=\"161765003\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 14.484167098999023
    },
    {
      "task_id": "ffa49d21-8784-4ff2-ab62-710d80f9dd59",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_minimal_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0.0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 1,
        "gold_mappings_count": 1,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.9,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "AdverseEvent=\"419620001\"",
          "Condition=\"E10.9\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\""
        ],
        "false_negative_examples": [
          "PrimaryCancerCondition=\"254837009\""
        ],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 16.789913177490234
    },
    {
      "task_id": "68e2c4b1-4f4c-45fa-b568-395a52711e6c",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_minimal_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.005205154418945
    },
    {
      "task_id": "516d4f04-c55c-4ae6-b0a8-9301a2c8298f",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_minimal_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.021739130434782608,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.047619047619047616,
        "mapping_f1_score": 0.0425531914893617,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 20,
        "gold_mappings_count": 25,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.89,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\"",
          "CancerCondition=\"C1268991\""
        ],
        "false_negative_examples": [
          "Primary Purpose=\"C70820\"",
          "MedicationStatement=\"387517004\"",
          "ClinicalStatus=\"261665006\"",
          "PrimaryCancerCondition=\"254837009\"",
          "Treatment=\"367336001\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 16.365766525268555
    },
    {
      "task_id": "83ee5d98-8e95-4269-b092-e9e91656974c",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_minimal_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.010638297872340425,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.020833333333333332,
        "mapping_f1_score": 0.021052631578947368,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 47,
        "gold_mappings_count": 80,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "Observation=\"1975-2\""
        ],
        "false_positive_examples": [
          "Condition=\"E10.9\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\"",
          "Observation=\"33728-7\""
        ],
        "false_negative_examples": [
          "Reporting Status=\"399423001\"",
          "Region of Enrollment=\"21840-4\"",
          "Denominator Value=\"NA\"",
          "Outcome Measure Description=\"NA\"",
          "Ethnicity=\"69409-1\""
        ],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.266273498535156
    },
    {
      "task_id": "28e04bf7-64dc-45e9-95c0-76dad9d57334",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_minimal_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"50\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "ResearchStudy=\"research-study\"",
          "CancerRelatedSurgicalProcedure=\"236627004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 16.65520668029785
    },
    {
      "task_id": "d5fea534-a557-46a5-bf22-5ea8e2dbb5ba",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_minimal_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.668174743652344
    },
    {
      "task_id": "8e2757ae-81ed-4e01-b584-c63d1b2b6817",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_structured_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06153846153846154,
        "mapping_precision": 0.0851063829787234,
        "mapping_recall": 0.18181818181818182,
        "mapping_f1_score": 0.11594202898550723,
        "mapping_true_positives": 4,
        "mapping_false_positives": 43,
        "mapping_false_negatives": 18,
        "gold_mappings_count": 43,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.8976744186046512,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"C50.919\"",
          "CancerCondition=\"363346000\"",
          "CancerDiseaseStatus=\"385633008\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\"",
          "Observation=\"69453-9\""
        ],
        "false_negative_examples": [
          "CancerRelatedSurgicalProcedure=\"77461000\"",
          "Patient=\"116154003\"",
          "Patient=\"LA19536-9\"",
          "CancerDiseaseStatus=\"LOINC_PLACEHOLDER\"",
          "CancerRelatedSurgicalProcedure=\"SNOMED_CT_PLACEHOLDER\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.151926040649414
    },
    {
      "task_id": "bb8d8644-8e77-4b13-b149-8b7c95f5fadf",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_structured_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.045881271362305
    },
    {
      "task_id": "cdeb5713-e595-4003-90d5-d1ba4e929083",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_structured_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.17857142857142858,
        "mapping_precision": 0.2631578947368421,
        "mapping_recall": 0.35714285714285715,
        "mapping_f1_score": 0.30303030303030304,
        "mapping_true_positives": 5,
        "mapping_false_positives": 14,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 19,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9657894736842106,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "GenomicVariant=\"HGNC:3430\"",
          "MedicationStatement=\"763875007\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "Observation=\"LP998223-8\"",
          "Condition=\"I51.9\"",
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedicationAdministration=\"76314003\"",
          "GenomicVariant=\"LA14042-8\"",
          "GenomicVariant=\"LA6576-8\"",
          "CancerCondition=\"C50.919\"",
          "CancerCondition=\"C50.9\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 13.507843017578125
    },
    {
      "task_id": "7bee7112-3fcf-4d3c-956d-7e544c12028e",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_structured_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "AdverseEvent=\"419620001\"",
          "Condition=\"E10.9\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.5239315032959
    },
    {
      "task_id": "96b1814d-64a6-40e8-acbc-45b1c090baf7",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_structured_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.07894736842105263,
        "mapping_precision": 0.10714285714285714,
        "mapping_recall": 0.23076923076923078,
        "mapping_f1_score": 0.14634146341463414,
        "mapping_true_positives": 3,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 15,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:1100\"",
          "GenomicVariant=\"HGNC:1101\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"50\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"21894-1\"",
          "CancerCondition=\"C1290384\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"126906006\"",
          "BodySite=\"76752008\"",
          "CancerCondition=\"254848004\"",
          "CancerCondition=\"408643008\"",
          "TumorMarkerTest=\"85319-2\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 14.549016952514648
    },
    {
      "task_id": "1307c94c-31a5-484f-b08d-0b2712c712cf",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_structured_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.030303030303030304,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.125,
        "mapping_f1_score": 0.058823529411764705,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 7,
        "gold_mappings_count": 13,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9115384615384615,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\"",
          "CancerCondition=\"C1268991\""
        ],
        "false_negative_examples": [
          "CancerTreatment=\"372864008\"",
          "CancerTreatment=\"387207008\"",
          "CancerCondition=\"313217004\"",
          "CancerTreatment=\"372857005\"",
          "CancerCondition=\"C0006826\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 13.432979583740234
    },
    {
      "task_id": "5c1f2724-ec4b-44c0-8d8f-e0ff73fadc4f",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_structured_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.337228775024414
    },
    {
      "task_id": "c020d0d9-9913-40f5-9d9b-510047e7045a",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_structured_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 20.119905471801758
    },
    {
      "task_id": "4f479ac2-4aa6-45fb-8eec-0f47b3d5bb09",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_structured_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"50\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "ResearchStudy=\"research-study\"",
          "CancerRelatedSurgicalProcedure=\"236627004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 16.533851623535156
    },
    {
      "task_id": "69aec6a1-affe-449c-aac7-38043cf21d38",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_structured_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0196078431372549,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.2,
        "mapping_f1_score": 0.03846153846153846,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 4,
        "gold_mappings_count": 20,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "AdverseEvent=\"419620001\"",
          "Condition=\"E10.9\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\"",
          "Observation=\"33728-7\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"363346000\"",
          "ImagingStudy=\"394914008\"",
          "Device=\"700000000000\"",
          "Procedure=\"367336001\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.19300651550293
    },
    {
      "task_id": "e289a26f-a897-4488-bb4c-2a5973493104",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_optimization_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.08695652173913043,
        "mapping_precision": 0.1276595744680851,
        "mapping_recall": 0.21428571428571427,
        "mapping_f1_score": 0.16,
        "mapping_true_positives": 6,
        "mapping_false_positives": 41,
        "mapping_false_negatives": 22,
        "gold_mappings_count": 42,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.7845238095238096,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "Patient=\"305780008\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C50.919\"",
          "CancerCondition=\"363346000\"",
          "Patient=\"F\""
        ],
        "false_positive_examples": [
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\"",
          "Observation=\"69453-9\"",
          "ECOGPerformanceStatus=\"LA9623-5\""
        ],
        "false_negative_examples": [
          "Patient=\"413350009\"",
          "Patient=\"72892002\"",
          "Patient=\"442083009\"",
          "CancerCondition=\"108370007\"",
          "CancerDiseaseStatus=\"281647001\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.197940826416016
    },
    {
      "task_id": "fdb02b5a-e393-453b-ace8-761ba0a764f4",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_optimization_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 13.08298110961914
    },
    {
      "task_id": "a4f2d60b-31dd-44ad-b549-aa05a834095d",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_optimization_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.10344827586206896,
        "mapping_precision": 0.15789473684210525,
        "mapping_recall": 0.23076923076923078,
        "mapping_f1_score": 0.18749999999999997,
        "mapping_true_positives": 3,
        "mapping_false_positives": 16,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 21,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.8547619047619047,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"C50.911\"",
          "GenomicVariant=\"HGNC:3430\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "Observation=\"LP998223-8\"",
          "ResearchStudy=\"research-study\"",
          "Condition=\"I51.9\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedicationAdministration=\"76388\"",
          "MedicationStatement=\"XRP9881\"",
          "CancerRelatedMedicationContraindication=\"LA14006-8\"",
          "CancerCondition=\"C50.919\"",
          "CancerCondition=\"C1266163\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 13.749122619628906
    },
    {
      "task_id": "d79e0d9c-b885-46ba-83e2-4e755104af82",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_optimization_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.043478260869565216,
        "mapping_precision": 0.07142857142857142,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.08333333333333333,
        "mapping_true_positives": 2,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 18,
        "gold_mappings_count": 22,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.865909090909091,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "Procedure=\"396487001\""
        ],
        "false_positive_examples": [
          "Patient=\"50\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"21894-1\"",
          "CancerCondition=\"C1290384\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"126906006\"",
          "Observation=\"85337-4\"",
          "CancerCondition=\"109838007\"",
          "Observation=\"48694002\"",
          "Observation=\"405746006\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 14.306783676147461
    },
    {
      "task_id": "50751c9a-9a96-48ab-a8b9-898f814b8f94",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_optimization_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "AdverseEvent=\"419620001\"",
          "Condition=\"E10.9\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.07515525817871
    },
    {
      "task_id": "81acfabb-4bf7-42a5-86e3-50a921565b84",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_optimization_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02857142857142857,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.05555555555555555,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 13,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.8999999999999999,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\"",
          "CancerCondition=\"C1268991\""
        ],
        "false_negative_examples": [
          "ClinicalTrial=\"NCT00000000\"",
          "CancerCondition=\"433581000124108\"",
          "CancerCondition=\"373150008\"",
          "CancerTreatment=\"372876000\"",
          "CancerDiseaseStatus=\"373930000\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 13.555765151977539
    },
    {
      "task_id": "81f9e53e-7caa-4cf5-97ed-703bd2c7bb16",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_optimization_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 16.717910766601562
    },
    {
      "task_id": "cc69077d-12c2-4ccd-8428-8ba6980fe0e5",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_optimization_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.752979278564453
    },
    {
      "task_id": "3238ce14-b3bd-47f2-94cd-78f02bb2daff",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_optimization_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"50\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "ResearchStudy=\"research-study\"",
          "CancerRelatedSurgicalProcedure=\"236627004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 16.89314842224121
    },
    {
      "task_id": "98860541-73a1-491c-a268-d9e3a445a288",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_optimization_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.017857142857142856,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.03508771929824561,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 14,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "AdverseEvent=\"419620001\"",
          "Condition=\"E10.9\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\"",
          "Observation=\"33728-7\""
        ],
        "false_negative_examples": [
          "OutcomeMeasure=\"NA\"",
          "Device=\"123456789\"",
          "ECOGPerformanceStatus=\"255428009\"",
          "Observation=\"123456789\"",
          "PatientAge=\"424144002\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.99798011779785
    },
    {
      "task_id": "e5916d20-6a4e-4e27-80fe-cb152bd09f08",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_improved_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03508771929824561,
        "mapping_precision": 0.0425531914893617,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.06779661016949153,
        "mapping_true_positives": 2,
        "mapping_false_positives": 45,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 14,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.9357142857142857,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerDiseaseStatus=\"268910001\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\"",
          "Observation=\"69453-9\""
        ],
        "false_negative_examples": [
          "TNMClinicalStageGroup=\"21908-9\"",
          "GenomicVariant=\"C0205726\"",
          "GenomicVariant=\"C3665328\"",
          "GenomicVariant=\"C0205728\"",
          "GenomicVariant=\"C0205727\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 16.392230987548828
    },
    {
      "task_id": "f8b5e4d4-2952-4f28-bc04-b63e36e2a743",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_improved_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06896551724137931,
        "mapping_precision": 0.10526315789473684,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.12903225806451615,
        "mapping_true_positives": 2,
        "mapping_false_positives": 17,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 17,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9147058823529413,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:3430\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "Observation=\"LP998223-8\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [
          "GenomicVariant=\"70650003\"",
          "CancerRelatedMedication=\"763875007\"",
          "TNMClinicalStageGroup=\"LA26831-3\"",
          "CancerRelatedProcedure=\"252416005\"",
          "CancerRelatedMedication=\"763140\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 13.041973114013672
    },
    {
      "task_id": "c6191583-590c-4c37-bc70-b0d3e10500ae",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_improved_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.285015106201172
    },
    {
      "task_id": "0e439284-cfa9-4028-af16-f5d88481f70e",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_improved_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02564102564102564,
        "mapping_precision": 0.03571428571428571,
        "mapping_recall": 0.08333333333333333,
        "mapping_f1_score": 0.05,
        "mapping_true_positives": 1,
        "mapping_false_positives": 27,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 14,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9249999999999999,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"50\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"21894-1\"",
          "CancerCondition=\"C1290384\""
        ],
        "false_negative_examples": [
          "CancerRelatedProcedure=\"387713003\"",
          "CancerRelatedProcedure=\"108290001\"",
          "CancerRelatedProcedure=\"129286009\"",
          "CancerDiseaseStatus=\"260415000\"",
          "CancerRelatedProcedure=\"443402002\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 13.343095779418945
    },
    {
      "task_id": "dabafda0-ce49-4e4c-9099-08904aa06f31",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_improved_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "AdverseEvent=\"419620001\"",
          "Condition=\"E10.9\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.459869384765625
    },
    {
      "task_id": "08dec9da-894d-460a-a81f-843e97a17294",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_improved_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02857142857142857,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.05555555555555555,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 13,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.8807692307692307,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\"",
          "CancerCondition=\"C1268991\""
        ],
        "false_negative_examples": [
          "CancerRelatedProcedure=\"387713003\"",
          "CancerRelatedMedication=\"367336001\"",
          "CancerRelatedMedication=\"372756006\"",
          "CancerRelatedProcedure=\"108290001\"",
          "CancerCondition=\"128462008\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 12.007951736450195
    },
    {
      "task_id": "28b89bc3-6732-45a7-88be-306fca1ec82c",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_improved_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.1957950592041
    },
    {
      "task_id": "462bf83c-85ab-4525-b4e9-24a07e2c7b2c",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_improved_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.01818181818181818,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.1111111111111111,
        "mapping_f1_score": 0.03571428571428571,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 8,
        "gold_mappings_count": 40,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.8150000000000001,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "AdverseEvent=\"419620001\"",
          "Condition=\"E10.9\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\"",
          "Observation=\"33728-7\""
        ],
        "false_negative_examples": [
          "CancerRelatedProcedure=\"387713003\"",
          "ECOGPerformanceStatus=\"271674006\"",
          "CancerCondition=\"NA\"",
          "CancerRelatedProcedure=\"NA\"",
          "CancerCondition=\"363346000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.601728439331055
    },
    {
      "task_id": "7b0f7074-097d-4572-88ce-21f79a68cd04",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_improved_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.664836883544922
    },
    {
      "task_id": "b2b09446-939c-4074-ab84-ab85dff39feb",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.05970149253731343,
        "mapping_precision": 0.0851063829787234,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.11267605633802817,
        "mapping_true_positives": 4,
        "mapping_false_positives": 43,
        "mapping_false_negatives": 20,
        "gold_mappings_count": 44,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.9954545454545454,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "Observation=\"72826-1\"",
          "Patient=\"F\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\""
        ],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\"",
          "Observation=\"69453-9\"",
          "ECOGPerformanceStatus=\"LA9623-5\""
        ],
        "false_negative_examples": [
          "Observation=\"21840-4\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"8302-2\"",
          "ResearchStudy=\"clinical-research\"",
          "ResearchStudy=\"parental-cancer\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.613815307617188
    },
    {
      "task_id": "389e5805-3ec4-4ce1-8e5a-e5cd3a830e6f",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_improved_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"50\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "ResearchStudy=\"research-study\"",
          "CancerRelatedSurgicalProcedure=\"236627004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 19.899845123291016
    },
    {
      "task_id": "49d436e0-6ef7-4c05-8a71-2e1489a689b4",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.12121212121212122,
        "mapping_precision": 0.21052631578947367,
        "mapping_recall": 0.2222222222222222,
        "mapping_f1_score": 0.21621621621621623,
        "mapping_true_positives": 4,
        "mapping_false_positives": 15,
        "mapping_false_negatives": 14,
        "gold_mappings_count": 19,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "ResearchStudy=\"NCT00386685\"",
          "GenomicVariant=\"HGNC:3430\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "Observation=\"LP998223-8\"",
          "CancerCondition=\"C50.911\"",
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\""
        ],
        "false_negative_examples": [
          "ResearchStudy=\"SINGLE_GROUP\"",
          "CancerCondition=\"C4872\"",
          "CancerCondition=\"C0006142\"",
          "CancerRelatedMedication=\"trastuzumab\"",
          "ResearchStudy=\"NONE\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 14.939069747924805
    },
    {
      "task_id": "1a2efb08-e6d2-46ae-9020-cfaa93916800",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.04892921447754
    },
    {
      "task_id": "2bc786a6-c0d1-42e0-baf4-712edeee8c2c",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.1,
        "mapping_precision": 0.17857142857142858,
        "mapping_recall": 0.18518518518518517,
        "mapping_f1_score": 0.18181818181818182,
        "mapping_true_positives": 5,
        "mapping_false_positives": 23,
        "mapping_false_negatives": 22,
        "gold_mappings_count": 32,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:1100\"",
          "ResearchStudy=\"NCT05417516\"",
          "Condition=\"254837009\"",
          "Procedure=\"396487001\"",
          "GenomicVariant=\"HGNC:1101\""
        ],
        "false_positive_examples": [
          "Patient=\"50\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"21894-1\""
        ],
        "false_negative_examples": [
          "ResearchStudy=\"primaryPurpose\"",
          "Observation=\"77386006\"",
          "ResearchStudy=\"allocation\"",
          "Observation=\"252416005\"",
          "ResearchStudy=\"maskingDescription\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 14.716863632202148
    },
    {
      "task_id": "6a50ddf6-5062-4453-9fda-7898a1cbe0cd",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.08571428571428572,
        "mapping_precision": 0.11538461538461539,
        "mapping_recall": 0.25,
        "mapping_f1_score": 0.15789473684210525,
        "mapping_true_positives": 3,
        "mapping_false_positives": 23,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 19,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9894736842105264,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "ResearchStudy=\"NCT00286117\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\"",
          "CancerCondition=\"C1268991\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedication=\"387517004\"",
          "CancerCondition=\"C77.3\"",
          "Biomarker=\"ER\"",
          "CancerRelatedMedication=\"372906003\"",
          "ResearchStudy=\"N/A\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 12.990951538085938
    },
    {
      "task_id": "0de3c9d3-56b5-485c-abfa-6b7d3d231478",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "AdverseEvent=\"419620001\"",
          "Condition=\"E10.9\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 22.610902786254883
    },
    {
      "task_id": "5d98e3d2-3769-4ab4-8545-e32e3bec0f7d",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.38319206237793
    },
    {
      "task_id": "b9ad20f4-13f5-414a-b15a-62238aa69718",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.288923263549805
    },
    {
      "task_id": "60da4a51-d4a5-4ef9-a6ca-33680a429fb6",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.011363636363636364,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.023809523809523808,
        "mapping_f1_score": 0.022471910112359546,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 41,
        "gold_mappings_count": 102,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.9705882352941176,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Condition=\"E10.9\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\"",
          "Observation=\"33728-7\"",
          "Observation=\"2160-0\""
        ],
        "false_negative_examples": [
          "OutcomeMeasureType=\"NA\"",
          "OutcomeMeasureDescription=\"NA\"",
          "OutcomeMeasureParamType=\"NA\"",
          "OutcomeMeasureReportingStatus=\"NA\"",
          "Observation=\"363406005\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.922163009643555
    },
    {
      "task_id": "c65a1ada-99e2-478a-985a-83d19699c165",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"50\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "ResearchStudy=\"research-study\"",
          "CancerRelatedSurgicalProcedure=\"236627004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 17.49706268310547
    },
    {
      "task_id": "913c9157-0fd9-4315-b8af-175c39a7dcb8",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_concise_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.041666666666666664,
        "mapping_precision": 0.05263157894736842,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.08,
        "mapping_true_positives": 1,
        "mapping_false_positives": 18,
        "mapping_false_negatives": 5,
        "gold_mappings_count": 8,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "Observation=\"LP998223-8\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"108369006\"",
          "PatientDemographics=\"424144002\"",
          "CancerTreatment=\"387018007\"",
          "CancerTreatment=\"763875007\"",
          "CancerCondition=\"702971005\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 13.139963150024414
    },
    {
      "task_id": "8cb1d75f-b6d5-45c3-ac37-3bf31141197f",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_concise_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03773584905660377,
        "mapping_precision": 0.0425531914893617,
        "mapping_recall": 0.25,
        "mapping_f1_score": 0.07272727272727272,
        "mapping_true_positives": 2,
        "mapping_false_positives": 45,
        "mapping_false_negatives": 6,
        "gold_mappings_count": 16,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"363346000\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\"",
          "Observation=\"69453-9\""
        ],
        "false_negative_examples": [
          "PatientDemographics=\"372148003\"",
          "PatientDemographics=\"424144002\"",
          "PatientDemographics=\"184100006\"",
          "TNMStage=\"399518008\"",
          "PatientDemographics=\"248152002\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.467260360717773
    },
    {
      "task_id": "ea069a85-b8ea-4dc4-9c5a-cfb3b0a05d0c",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_concise_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.038461538461538464,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 1.0,
        "mapping_f1_score": 0.07407407407407407,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 1,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\"",
          "CancerCondition=\"C1268991\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 16.307830810546875
    },
    {
      "task_id": "ded2e924-0b8c-4091-bac0-5e0ae6291dff",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02564102564102564,
        "mapping_precision": 0.03571428571428571,
        "mapping_recall": 0.08333333333333333,
        "mapping_f1_score": 0.05,
        "mapping_true_positives": 1,
        "mapping_false_positives": 27,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 16,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9875,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"50\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"21894-1\"",
          "CancerCondition=\"C1290384\""
        ],
        "false_negative_examples": [
          "PatientDemographics=\"397669002\"",
          "ResearchSubject=\"Not Applicable\"",
          "CancerTreatment=\"387713003\"",
          "CancerTreatment=\"129286009\"",
          "CancerTreatment=\"23426006\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 13.011932373046875
    },
    {
      "task_id": "bbb3e3de-19b7-49f3-8520-1d185852c85d",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_concise_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "AdverseEvent=\"419620001\"",
          "Condition=\"E10.9\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 20.3399658203125
    },
    {
      "task_id": "6af6440d-88b7-42a6-b6ba-e6d8f35c4e68",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02631578947368421,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.07692307692307693,
        "mapping_f1_score": 0.05128205128205129,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 12,
        "gold_mappings_count": 16,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.99375,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\"",
          "CancerCondition=\"C1268991\""
        ],
        "false_negative_examples": [
          "PatientCharacteristic=\"365873007\"",
          "CancerTreatment=\"372756006\"",
          "StudyPurpose=\"N/A\"",
          "CancerCondition=\"128462008\"",
          "StudyDesign=\"N/A\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 13.506174087524414
    },
    {
      "task_id": "e848c31f-66de-4cca-a765-a7e30098365d",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.611120223999023
    },
    {
      "task_id": "ed975448-cafd-4459-9963-e0499db77df4",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.356250762939453
    },
    {
      "task_id": "8bc76b6b-1695-462d-9f25-c80bc0f39e3a",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.017543859649122806,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.09090909090909091,
        "mapping_f1_score": 0.034482758620689655,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 41,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Condition=\"E10.9\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\"",
          "Observation=\"33728-7\"",
          "Observation=\"2160-0\""
        ],
        "false_negative_examples": [
          "OutcomeMeasure=\"NA\"",
          "Study=\"NA\"",
          "CancerCondition=\"NA\"",
          "StudyDesign=\"NA\"",
          "StudyDesign=\"OTHER\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.137216567993164
    },
    {
      "task_id": "e5042b2e-59ca-473c-b1c5-cf3e78544154",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_concise_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"50\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "ResearchStudy=\"research-study\"",
          "CancerRelatedSurgicalProcedure=\"236627004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 18.82004737854004
    },
    {
      "task_id": "9845fd8d-2b95-47f5-ab60-6f5745ef3eab",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_with_codes_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.019230769230769232,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.03773584905660377,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 5,
        "gold_mappings_count": 20,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.985,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\"",
          "Observation=\"69453-9\""
        ],
        "false_negative_examples": [
          "PatientDemographics=\"248153007\"",
          "PatientDemographics=\"248152002\"",
          "CancerCondition=\"371494000\"",
          "TNMStage=\"399537006\"",
          "PatientDemographics=\"184099003\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.62676239013672
    },
    {
      "task_id": "62e9cd37-ad02-4f03-9d32-bbfbd7686800",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_with_codes_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.744209289550781
    },
    {
      "task_id": "47fff6fb-3264-4435-a81e-931878fad472",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_with_codes_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.04,
        "mapping_precision": 0.05263157894736842,
        "mapping_recall": 0.14285714285714285,
        "mapping_f1_score": 0.07692307692307693,
        "mapping_true_positives": 1,
        "mapping_false_positives": 18,
        "mapping_false_negatives": 6,
        "gold_mappings_count": 11,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.990909090909091,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "Observation=\"LP998223-8\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [
          "CancerTreatment=\"387018007\"",
          "PatientDemographic=\"184099003\"",
          "CancerCondition=\"706891004\"",
          "CancerTreatment=\"367336001\"",
          "CancerCondition=\"371494000\""
        ],
        "gold_compliance_score": 1.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 14.64390754699707
    },
    {
      "task_id": "b8ab10ca-1fc7-4325-993f-c599b25c8bed",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_with_codes_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "AdverseEvent=\"419620001\"",
          "Condition=\"E10.9\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 16.887187957763672
    },
    {
      "task_id": "8c9de362-e2a5-4966-a7c6-8d76f34cbf73",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.024390243902439025,
        "mapping_precision": 0.03571428571428571,
        "mapping_recall": 0.07142857142857142,
        "mapping_f1_score": 0.047619047619047616,
        "mapping_true_positives": 1,
        "mapping_false_positives": 27,
        "mapping_false_negatives": 13,
        "gold_mappings_count": 21,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"50\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"21894-1\"",
          "CancerCondition=\"C1290384\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"109356001\"",
          "TumorMarkers=\"371495004\"",
          "CancerCondition=\"372130007\"",
          "PatientDemographics=\"248153007\"",
          "TumorMarkers=\"371496003\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 13.090133666992188
    },
    {
      "task_id": "864efc7c-3e66-4d6a-8428-1b217eb116aa",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03125,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.14285714285714285,
        "mapping_f1_score": 0.060606060606060615,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 6,
        "gold_mappings_count": 14,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9928571428571429,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"366630004\"",
          "CancerCondition=\"C0006142\"",
          "Observation=\"LP212175-9\"",
          "Observation=\"82810-3\"",
          "CancerCondition=\"C1268991\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"432469009\"",
          "PatientDemographics=\"248153007\"",
          "PatientDemographics=\"289908002\"",
          "CancerTreatment=\"387136007\"",
          "CancerTreatment=\"386876001\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 11.759757995605469
    },
    {
      "task_id": "adf5ee84-ecd4-4e57-a2ca-58eae1fe64fe",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 12.293815612792969
    },
    {
      "task_id": "67db5b78-1f5f-4b62-a911-8d950cf4625e",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.018518518518518517,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.125,
        "mapping_f1_score": 0.03636363636363636,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 7,
        "gold_mappings_count": 13,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.9769230769230769,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"305780008\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72171-2\"",
          "Patient=\"BG001\"",
          "Observation=\"69453-9\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"432469009\"",
          "CancerCondition=\"432468001\"",
          "PatientDemographics=\"248153007\"",
          "PatientDemographics=\"248152002\"",
          "CancerCondition=\"371494000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.851974487304688
    },
    {
      "task_id": "3584b8dc-9508-4d89-9999-736c15b94a4d",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_with_codes_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"50\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C0006142\"",
          "ResearchStudy=\"research-study\"",
          "CancerRelatedSurgicalProcedure=\"236627004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 11.918067932128906
    },
    {
      "task_id": "b2fabcc0-0077-4b3a-9e9b-f44880c29b17",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.017241379310344827,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.08333333333333333,
        "mapping_f1_score": 0.03389830508474576,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 35,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.9799999999999999,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Condition=\"E10.9\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"8302-2\"",
          "Observation=\"33728-7\"",
          "Observation=\"2160-0\""
        ],
        "false_negative_examples": [
          "StudyDesign=\"OTHER\"",
          "StudyDesign=\"NA\"",
          "PatientDemographics=\"248153007\"",
          "Masking=\"NO\"",
          "StudyDesign=\"260299005\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 13.12112808227539
    }
  ],
  "analysis": {
    "summary": {
      "total_comparisons": 100,
      "successful_comparisons": 100,
      "success_rate": 1.0,
      "unique_config_pairs": 80
    },
    "configuration_analysis": {
      "direct_mcode_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.023255813953488372,
          "median": 0.023255813953488372,
          "stdev": 0.03288868749704872,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.038461538461538464,
          "median": 0.038461538461538464,
          "stdev": 0.05439282932204212,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0.07443229275647868,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.044444444444444446,
          "median": 0.044444444444444446,
          "stdev": 0.0628539361054709,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 1.4142135623730951,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 16.263455967290593,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 8.5,
          "median": 8.5,
          "stdev": 12.020815280171307,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 11.5,
          "median": 11.5,
          "stdev": 16.263455967290593,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.45108695652173914,
          "median": 0.45108695652173914,
          "stdev": 0.6379332917226461,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.28125,
          "median": 0.28125,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.47368421052631576,
          "median": 0.47368421052631576,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.4090909090909091,
          "median": 0.4090909090909091,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.43902439024390244,
          "median": 0.43902439024390244,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9107142857142857,
          "median": 0.9107142857142857,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.2857142857142857,
          "median": 0.2857142857142857,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.19047619047619047,
          "median": 0.19047619047619047,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9764705882352942,
          "median": 0.9764705882352942,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_deepseek-coder_vs_direct_mcode_deepseek-chat": {
        "mapping_jaccard_similarity": {
          "mean": 0.176056338028169,
          "median": 0.176056338028169,
          "stdev": 0.24898126098117868,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.25510204081632654,
          "median": 0.25510204081632654,
          "stdev": 0.36076876591150386,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.26595744680851063,
          "median": 0.26595744680851063,
          "stdev": 0.37612062829071674,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.2604166666666667,
          "median": 0.2604166666666667,
          "stdev": 0.3682847818679935,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 12.5,
          "median": 12.5,
          "stdev": 17.67766952966369,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 12,
          "median": 12.0,
          "stdev": 16.97056274847714,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 24,
          "median": 24.0,
          "stdev": 2.8284271247461903,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 27,
          "median": 27.0,
          "stdev": 38.18376618407357,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.4175925925925926,
          "median": 0.4175925925925926,
          "stdev": 0.5905651079909869,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        }
      },
      "direct_mcode_simple_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.07894736842105263,
          "median": 0.07894736842105263,
          "stdev": 0.11164843913471803,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.1276595744680851,
          "median": 0.1276595744680851,
          "stdev": 0.18053790157954402,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.14634146341463414,
          "median": 0.14634146341463414,
          "stdev": 0.2069580822985017,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.13636363636363635,
          "median": 0.13636363636363635,
          "stdev": 0.1928473039599675,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 6,
          "median": 6.0,
          "stdev": 8.48528137423857,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 30.5,
          "median": 30.5,
          "stdev": 6.363961030678928,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 14.5,
          "median": 14.5,
          "stdev": 20.506096654409877,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 26.5,
          "median": 26.5,
          "stdev": 37.476659402887016,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.43254716981132074,
          "median": 0.43254716981132074,
          "stdev": 0.6117140739132679,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.030303030303030304,
          "median": 0.030303030303030304,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.09523809523809523,
          "median": 0.09523809523809523,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.0588235294117647,
          "median": 0.0588235294117647,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 45,
          "median": 45,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 55,
          "median": 55,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.7354545454545455,
          "median": 0.7354545454545455,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.11904761904761904,
          "median": 0.11904761904761904,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.2631578947368421,
          "median": 0.2631578947368421,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.17857142857142858,
          "median": 0.17857142857142858,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.2127659574468085,
          "median": 0.2127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9352941176470588,
          "median": 0.9352941176470588,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.10256410256410256,
          "median": 0.10256410256410256,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.26666666666666666,
          "median": 0.26666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.18604651162790697,
          "median": 0.18604651162790697,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.023255813953488372,
          "median": 0.023255813953488372,
          "stdev": 0.03288868749704872,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.038461538461538464,
          "median": 0.038461538461538464,
          "stdev": 0.05439282932204212,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0.07443229275647868,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.044444444444444446,
          "median": 0.044444444444444446,
          "stdev": 0.0628539361054709,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 1.4142135623730951,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 16.263455967290593,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 8.5,
          "median": 8.5,
          "stdev": 12.020815280171307,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 11.5,
          "median": 11.5,
          "stdev": 16.263455967290593,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.44565217391304346,
          "median": 0.44565217391304346,
          "stdev": 0.6302473484488793,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_simple_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0136986301369863,
          "median": 0.0136986301369863,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.037037037037037035,
          "median": 0.037037037037037035,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.027027027027027025,
          "median": 0.027027027027027025,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 26,
          "median": 26,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 50,
          "median": 50,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.358,
          "median": 0.358,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06896551724137931,
          "median": 0.06896551724137931,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.12903225806451615,
          "median": 0.12903225806451615,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9029411764705882,
          "median": 0.9029411764705882,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017857142857142856,
          "median": 0.017857142857142856,
          "stdev": 0.025253813613805267,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0.030089650263257342,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.09090909090909091,
          "median": 0.09090909090909091,
          "stdev": 0.128564869306645,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.034482758620689655,
          "median": 0.034482758620689655,
          "stdev": 0.04876598490941707,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 1.4142135623730951,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 13.435028842544403,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 4.5,
          "median": 4.5,
          "stdev": 6.363961030678928,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 7,
          "median": 7.0,
          "stdev": 9.899494936611665,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4571428571428572,
          "median": 0.4571428571428572,
          "stdev": 0.646497628513415,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_comprehensive_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02702702702702703,
          "median": 0.02702702702702703,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.05263157894736841,
          "median": 0.05263157894736841,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9423076923076923,
          "median": 0.9423076923076923,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02488425925925926,
          "median": 0.02488425925925926,
          "stdev": 0.009002516890106508,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.02986906710310966,
          "median": 0.02986906710310966,
          "stdev": 0.01215158952939239,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.13392857142857142,
          "median": 0.13392857142857142,
          "stdev": 0.012626906806902628,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.04848484848484849,
          "median": 0.04848484848484849,
          "stdev": 0.017141982574219342,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 0.0,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 14.849242404917497,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 6.5,
          "median": 6.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 10.5,
          "median": 10.5,
          "stdev": 2.1213203435596424,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.8604166666666666,
          "median": 0.8604166666666666,
          "stdev": 0.061871843353822925,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_comprehensive_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.016666666666666666,
          "median": 0.016666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.07142857142857142,
          "median": 0.07142857142857142,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.032786885245901634,
          "median": 0.032786885245901634,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 59,
          "median": 59,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.6728813559322034,
          "median": 0.6728813559322034,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06060606060606061,
          "median": 0.06060606060606061,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.125,
          "median": 0.125,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.11428571428571428,
          "median": 0.11428571428571428,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 21,
          "median": 21,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8500000000000001,
          "median": 0.8500000000000001,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.023809523809523808,
          "median": 0.023809523809523808,
          "stdev": 0.03367175148507369,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0.060179300526514684,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.04878048780487805,
          "median": 0.04878048780487805,
          "stdev": 0.06898602743283391,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.045454545454545456,
          "median": 0.045454545454545456,
          "stdev": 0.0642824346533225,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2.0,
          "stdev": 2.8284271247461903,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 34.5,
          "median": 34.5,
          "stdev": 12.020815280171307,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 18.5,
          "median": 18.5,
          "stdev": 26.16295090390226,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 21.5,
          "median": 21.5,
          "stdev": 30.405591591021544,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.39476744186046514,
          "median": 0.39476744186046514,
          "stdev": 0.558285470262402,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.4714045207910317,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_minimal_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06521739130434782,
          "median": 0.06521739130434782,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10714285714285714,
          "median": 0.10714285714285714,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.12244897959183672,
          "median": 0.12244897959183672,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9456521739130435,
          "median": 0.9456521739130435,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9,
          "median": 0.9,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.010869565217391304,
          "median": 0.010869565217391304,
          "stdev": 0.015371886547533641,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.019230769230769232,
          "median": 0.019230769230769232,
          "stdev": 0.02719641466102106,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.023809523809523808,
          "median": 0.023809523809523808,
          "stdev": 0.03367175148507369,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0.030089650263257342,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 12.5,
          "median": 12.5,
          "stdev": 17.67766952966369,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.445,
          "median": 0.445,
          "stdev": 0.6293250352560273,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_minimal_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.010638297872340425,
          "median": 0.010638297872340425,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.020833333333333332,
          "median": 0.020833333333333332,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.021052631578947368,
          "median": 0.021052631578947368,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 80,
          "median": 80,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.03076923076923077,
          "median": 0.03076923076923077,
          "stdev": 0.0435142634576337,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0.060179300526514684,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.09090909090909091,
          "median": 0.09090909090909091,
          "stdev": 0.128564869306645,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.05797101449275362,
          "median": 0.05797101449275362,
          "stdev": 0.08198339492017942,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2.0,
          "stdev": 2.8284271247461903,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 34.5,
          "median": 34.5,
          "stdev": 12.020815280171307,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9.0,
          "stdev": 12.727922061357855,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 21.5,
          "median": 21.5,
          "stdev": 30.405591591021544,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4488372093023256,
          "median": 0.4488372093023256,
          "stdev": 0.6347516686930404,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_structured_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.17857142857142858,
          "median": 0.17857142857142858,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.2631578947368421,
          "median": 0.2631578947368421,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.35714285714285715,
          "median": 0.35714285714285715,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.30303030303030304,
          "median": 0.30303030303030304,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9657894736842106,
          "median": 0.9657894736842106,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.07894736842105263,
          "median": 0.07894736842105263,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10714285714285714,
          "median": 0.10714285714285714,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.23076923076923078,
          "median": 0.23076923076923078,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.14634146341463414,
          "median": 0.14634146341463414,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 15,
          "median": 15,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.015151515151515152,
          "median": 0.015151515151515152,
          "stdev": 0.021427478217774167,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.019230769230769232,
          "median": 0.019230769230769232,
          "stdev": 0.02719641466102106,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.0625,
          "median": 0.0625,
          "stdev": 0.08838834764831845,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.029411764705882353,
          "median": 0.029411764705882353,
          "stdev": 0.04159451654038515,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 3.5,
          "median": 3.5,
          "stdev": 4.949747468305833,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 6.5,
          "median": 6.5,
          "stdev": 9.192388155425117,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.45576923076923076,
          "median": 0.45576923076923076,
          "stdev": 0.6445550274661991,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.4714045207910317,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_structured_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0196078431372549,
          "median": 0.0196078431372549,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.2,
          "median": 0.2,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03846153846153846,
          "median": 0.03846153846153846,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 20,
          "median": 20,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.043478260869565216,
          "median": 0.043478260869565216,
          "stdev": 0.061487546190134565,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.06382978723404255,
          "median": 0.06382978723404255,
          "stdev": 0.09026895078977201,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.10714285714285714,
          "median": 0.10714285714285714,
          "stdev": 0.1515228816828316,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.08,
          "median": 0.08,
          "stdev": 0.1131370849898476,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3.0,
          "stdev": 4.242640687119285,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 33.5,
          "median": 33.5,
          "stdev": 10.606601717798213,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 21,
          "median": 21.0,
          "stdev": 29.698484809834994,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.3922619047619048,
          "median": 0.3922619047619048,
          "stdev": 0.5547421057165891,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_optimization_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.10344827586206896,
          "median": 0.10344827586206896,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.15789473684210525,
          "median": 0.15789473684210525,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.23076923076923078,
          "median": 0.23076923076923078,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.18749999999999997,
          "median": 0.18749999999999997,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 16,
          "median": 16,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 21,
          "median": 21,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8547619047619047,
          "median": 0.8547619047619047,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.043478260869565216,
          "median": 0.043478260869565216,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.07142857142857142,
          "median": 0.07142857142857142,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 26,
          "median": 26,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.865909090909091,
          "median": 0.865909090909091,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.014285714285714285,
          "median": 0.014285714285714285,
          "stdev": 0.020203050891044214,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.019230769230769232,
          "median": 0.019230769230769232,
          "stdev": 0.02719641466102106,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.05,
          "median": 0.05,
          "stdev": 0.07071067811865475,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.027777777777777776,
          "median": 0.027777777777777776,
          "stdev": 0.039283710065919304,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 4.5,
          "median": 4.5,
          "stdev": 6.363961030678928,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 6.5,
          "median": 6.5,
          "stdev": 9.192388155425117,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.44999999999999996,
          "median": 0.44999999999999996,
          "stdev": 0.6363961030678927,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.4714045207910317,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_optimization_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017857142857142856,
          "median": 0.017857142857142856,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03508771929824561,
          "median": 0.03508771929824561,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017543859649122806,
          "median": 0.017543859649122806,
          "stdev": 0.02481076425215956,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0.030089650263257342,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0.11785113019775792,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.03389830508474576,
          "median": 0.03389830508474576,
          "stdev": 0.04793944279230831,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 1.4142135623730951,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 13.435028842544403,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 5,
          "median": 5.0,
          "stdev": 7.0710678118654755,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 7,
          "median": 7.0,
          "stdev": 9.899494936611665,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.46785714285714286,
          "median": 0.46785714285714286,
          "stdev": 0.661649916681698,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_improved_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06896551724137931,
          "median": 0.06896551724137931,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.12903225806451615,
          "median": 0.12903225806451615,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9147058823529413,
          "median": 0.9147058823529413,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02564102564102564,
          "median": 0.02564102564102564,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.05,
          "median": 0.05,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9249999999999999,
          "median": 0.9249999999999999,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.014285714285714285,
          "median": 0.014285714285714285,
          "stdev": 0.020203050891044214,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.019230769230769232,
          "median": 0.019230769230769232,
          "stdev": 0.02719641466102106,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.05,
          "median": 0.05,
          "stdev": 0.07071067811865475,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.027777777777777776,
          "median": 0.027777777777777776,
          "stdev": 0.039283710065919304,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 4.5,
          "median": 4.5,
          "stdev": 6.363961030678928,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 6.5,
          "median": 6.5,
          "stdev": 9.192388155425117,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4403846153846154,
          "median": 0.4403846153846154,
          "stdev": 0.6227978957373822,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_improved_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.01818181818181818,
          "median": 0.01818181818181818,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1111111111111111,
          "median": 0.1111111111111111,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 8,
          "median": 8,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 40,
          "median": 40,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8150000000000001,
          "median": 0.8150000000000001,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.029850746268656716,
          "median": 0.029850746268656716,
          "stdev": 0.04221533022009239,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0.060179300526514684,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0.11785113019775792,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.056338028169014086,
          "median": 0.056338028169014086,
          "stdev": 0.07967400351397719,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2.0,
          "stdev": 2.8284271247461903,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 34.5,
          "median": 34.5,
          "stdev": 12.020815280171307,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 22,
          "median": 22.0,
          "stdev": 31.11269837220809,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4977272727272727,
          "median": 0.4977272727272727,
          "stdev": 0.7038926594538814,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_improved_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.12121212121212122,
          "median": 0.12121212121212122,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.21052631578947367,
          "median": 0.21052631578947367,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.2222222222222222,
          "median": 0.2222222222222222,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.21621621621621623,
          "median": 0.21621621621621623,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 15,
          "median": 15,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.17857142857142858,
          "median": 0.17857142857142858,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.18518518518518517,
          "median": 0.18518518518518517,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.18181818181818182,
          "median": 0.18181818181818182,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 32,
          "median": 32,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.04285714285714286,
          "median": 0.04285714285714286,
          "stdev": 0.060609152673132646,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.057692307692307696,
          "median": 0.057692307692307696,
          "stdev": 0.08158924398306318,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.125,
          "median": 0.125,
          "stdev": 0.1767766952966369,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.07894736842105263,
          "median": 0.07894736842105263,
          "stdev": 0.11164843913471803,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1.5,
          "median": 1.5,
          "stdev": 2.1213203435596424,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35,
          "median": 35.0,
          "stdev": 16.97056274847714,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 4.5,
          "median": 4.5,
          "stdev": 6.363961030678928,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 9.5,
          "median": 9.5,
          "stdev": 13.435028842544403,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4947368421052632,
          "median": 0.4947368421052632,
          "stdev": 0.6996635519108997,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_evidence_based_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.011363636363636364,
          "median": 0.011363636363636364,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.023809523809523808,
          "median": 0.023809523809523808,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.022471910112359546,
          "median": 0.022471910112359546,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 41,
          "median": 41,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 102,
          "median": 102,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9705882352941176,
          "median": 0.9705882352941176,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.041666666666666664,
          "median": 0.041666666666666664,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.08,
          "median": 0.08,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 8,
          "median": 8,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.038098693759071114,
          "median": 0.038098693759071114,
          "stdev": 0.0005131398992645508,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.040507364975450086,
          "median": 0.040507364975450086,
          "stdev": 0.0028932356022362805,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.625,
          "median": 0.625,
          "stdev": 0.5303300858899106,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.0734006734006734,
          "median": 0.0734006734006734,
          "stdev": 0.000952332365234407,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1.5,
          "median": 1.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35,
          "median": 35.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 3,
          "median": 3.0,
          "stdev": 4.242640687119285,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 8.5,
          "median": 8.5,
          "stdev": 10.606601717798213,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0.0,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_evidence_based_concise_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02564102564102564,
          "median": 0.02564102564102564,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.05,
          "median": 0.05,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 16,
          "median": 16,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9875,
          "median": 0.9875,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.013157894736842105,
          "median": 0.013157894736842105,
          "stdev": 0.01860807318911967,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.019230769230769232,
          "median": 0.019230769230769232,
          "stdev": 0.02719641466102106,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.038461538461538464,
          "median": 0.038461538461538464,
          "stdev": 0.05439282932204212,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.025641025641025644,
          "median": 0.025641025641025644,
          "stdev": 0.03626188621469475,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 6,
          "median": 6.0,
          "stdev": 8.48528137423857,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 8,
          "median": 8.0,
          "stdev": 11.313708498984761,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.496875,
          "median": 0.496875,
          "stdev": 0.7026873638041317,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.4714045207910317,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_evidence_based_concise_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017543859649122806,
          "median": 0.017543859649122806,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.09090909090909091,
          "median": 0.09090909090909091,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.034482758620689655,
          "median": 0.034482758620689655,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 41,
          "median": 41,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.009615384615384616,
          "median": 0.009615384615384616,
          "stdev": 0.01359820733051053,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.010638297872340425,
          "median": 0.010638297872340425,
          "stdev": 0.015044825131628671,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0.11785113019775792,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.018867924528301886,
          "median": 0.018867924528301886,
          "stdev": 0.02668327476175651,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 2.5,
          "median": 2.5,
          "stdev": 3.5355339059327378,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 10,
          "median": 10.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4925,
          "median": 0.4925,
          "stdev": 0.6965001794687493,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_evidence_based_with_codes_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.04,
          "median": 0.04,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.07692307692307693,
          "median": 0.07692307692307693,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 6,
          "median": 6,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.990909090909091,
          "median": 0.990909090909091,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.024390243902439025,
          "median": 0.024390243902439025,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.07142857142857142,
          "median": 0.07142857142857142,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.047619047619047616,
          "median": 0.047619047619047616,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 21,
          "median": 21,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02488425925925926,
          "median": 0.02488425925925926,
          "stdev": 0.009002516890106508,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.02986906710310966,
          "median": 0.02986906710310966,
          "stdev": 0.01215158952939239,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.13392857142857142,
          "median": 0.13392857142857142,
          "stdev": 0.012626906806902628,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.04848484848484849,
          "median": 0.04848484848484849,
          "stdev": 0.017141982574219342,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 0.0,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 14.849242404917497,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 6.5,
          "median": 6.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 13.5,
          "median": 13.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.9848901098901099,
          "median": 0.9848901098901099,
          "stdev": 0.01126708607385162,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017241379310344827,
          "median": 0.017241379310344827,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03389830508474576,
          "median": 0.03389830508474576,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 35,
          "median": 35,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9799999999999999,
          "median": 0.9799999999999999,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      }
    },
    "overall_metrics": {
      "mapping_jaccard_similarity": {
        "mean": 0.03200833598205859,
        "median": 0.015182648401826484,
        "stdev": 0.05545113346909122,
        "min": 0.0,
        "max": 0.352112676056338
      },
      "mapping_precision": {
        "mean": 0.04833287772857441,
        "median": 0.02127659574468085,
        "stdev": 0.08740679096799375,
        "min": 0.0,
        "max": 0.5102040816326531
      },
      "mapping_recall": {
        "mean": 0.09244505236165644,
        "median": 0.042328042328042326,
        "stdev": 0.139425172066122,
        "min": 0,
        "max": 1.0
      },
      "mapping_f1_score": {
        "mean": 0.057261009490746785,
        "median": 0.02990695613646433,
        "stdev": 0.0901414428783911,
        "min": 0,
        "max": 0.5208333333333334
      },
      "mapping_true_positives": {
        "mean": 1.49,
        "median": 1.0,
        "stdev": 3.076450138478674,
        "min": 0,
        "max": 25
      },
      "mapping_false_positives": {
        "mean": 31.67,
        "median": 27.0,
        "stdev": 12.116484305242668,
        "min": 0,
        "max": 47
      },
      "mapping_false_negatives": {
        "mean": 7.66,
        "median": 5.5,
        "stdev": 9.791998382517857,
        "min": 0,
        "max": 47
      },
      "gold_mappings_count": {
        "mean": 14.47,
        "median": 11.5,
        "stdev": 19.174612318786462,
        "min": 0,
        "max": 102
      },
      "comp_mappings_count": {
        "mean": 40.92,
        "median": 34.0,
        "stdev": 15.862209712700718,
        "min": 0,
        "max": 66
      },
      "gold_avg_confidence": {
        "mean": 0.47323710797218915,
        "median": 0.7041679506933745,
        "stdev": 0.46347564741063785,
        "min": 0,
        "max": 1.0
      },
      "comp_avg_confidence": {
        "mean": 0.8813384684926431,
        "median": 0.8770833333333333,
        "stdev": 0.09714976033991386,
        "min": 0,
        "max": 0.9617647058823531
      },
      "gold_compliance_score": {
        "mean": 0.22,
        "median": 0.3333333333333333,
        "stdev": 0.23792971639516422,
        "min": 0.0,
        "max": 1.0
      },
      "comp_compliance_score": {
        "mean": 0.39666666666666667,
        "median": 0.3333333333333333,
        "stdev": 0.13970467488263535,
        "min": 0.0,
        "max": 0.6666666666666666
      }
    }
  }
}