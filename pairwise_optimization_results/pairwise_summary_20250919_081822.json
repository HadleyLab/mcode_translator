{
  "summary": {
    "total_comparisons": 10,
    "successful_comparisons": 10,
    "success_rate": 1.0,
    "unique_config_pairs": 10
  },
  "configuration_analysis": {
    "direct_mcode_comprehensive_gpt-4-turbo_vs_direct_mcode_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.125,
        "median": 0.125,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.21428571428571427,
        "median": 0.21428571428571427,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.23076923076923078,
        "median": 0.23076923076923078,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.22222222222222224,
        "median": 0.22222222222222224,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 3,
        "median": 3,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 11,
        "median": 11,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 10,
        "median": 10,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 14,
        "median": 14,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 14,
        "median": 14,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 0.9535714285714285,
        "median": 0.9535714285714285,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.9857142857142858,
        "median": 0.9857142857142858,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_minimal_gpt-4-turbo_vs_direct_mcode_improved_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.0,
        "median": 0.0,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.0,
        "median": 0.0,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.0,
        "median": 0.0,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0,
        "median": 0,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 0,
        "median": 0,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 13,
        "median": 13,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 11,
        "median": 11,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 11,
        "median": 11,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 14,
        "median": 14,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 0.8954545454545454,
        "median": 0.8954545454545454,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.9500000000000001,
        "median": 0.9500000000000001,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_improved_gpt-4-turbo_vs_direct_mcode_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.05263157894736842,
        "median": 0.05263157894736842,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.09090909090909091,
        "median": 0.09090909090909091,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.1111111111111111,
        "median": 0.1111111111111111,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.09999999999999999,
        "median": 0.09999999999999999,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 1,
        "median": 1,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 10,
        "median": 10,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 8,
        "median": 8,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 9,
        "median": 9,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 11,
        "median": 11,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 0.9277777777777777,
        "median": 0.9277777777777777,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.859090909090909,
        "median": 0.859090909090909,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_structured_gpt-4-turbo_vs_direct_mcode_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.0967741935483871,
        "median": 0.0967741935483871,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.2,
        "median": 0.2,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.15789473684210525,
        "median": 0.15789473684210525,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.17647058823529413,
        "median": 0.17647058823529413,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 3,
        "median": 3,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 12,
        "median": 12,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 16,
        "median": 16,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 22,
        "median": 22,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 16,
        "median": 16,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 0.85,
        "median": 0.85,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.95,
        "median": 0.95,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_evidence_based_gpt-4-turbo_vs_direct_mcode_optimization_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.04878048780487805,
        "median": 0.04878048780487805,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.08695652173913043,
        "median": 0.08695652173913043,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.1,
        "median": 0.1,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.09302325581395349,
        "median": 0.09302325581395349,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 2,
        "median": 2,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 21,
        "median": 21,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 18,
        "median": 18,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 25,
        "median": 25,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 28,
        "median": 28,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 1.0,
        "median": 1.0,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.8410714285714286,
        "median": 0.8410714285714286,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_optimization_gpt-4-turbo_vs_direct_mcode_improved_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.08333333333333333,
        "median": 0.08333333333333333,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.17647058823529413,
        "median": 0.17647058823529413,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.13636363636363635,
        "median": 0.13636363636363635,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.15384615384615383,
        "median": 0.15384615384615383,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 3,
        "median": 3,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 14,
        "median": 14,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 19,
        "median": 19,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 24,
        "median": 24,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 20,
        "median": 20,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 0.875,
        "median": 0.875,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.9075,
        "median": 0.9075,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_gpt-4-turbo_vs_direct_mcode_simple_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.4642857142857143,
        "median": 0.4642857142857143,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.5652173913043478,
        "median": 0.5652173913043478,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.7222222222222222,
        "median": 0.7222222222222222,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.6341463414634146,
        "median": 0.6341463414634146,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 13,
        "median": 13,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 10,
        "median": 10,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 5,
        "median": 5,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 22,
        "median": 22,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 29,
        "median": 29,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 0.890909090909091,
        "median": 0.890909090909091,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.9655172413793104,
        "median": 0.9655172413793104,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_evidence_based_concise_gpt-4-turbo_vs_direct_mcode_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.023809523809523808,
        "median": 0.023809523809523808,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.041666666666666664,
        "median": 0.041666666666666664,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.05263157894736842,
        "median": 0.05263157894736842,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.04651162790697675,
        "median": 0.04651162790697675,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 1,
        "median": 1,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 23,
        "median": 23,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 18,
        "median": 18,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 22,
        "median": 22,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 26,
        "median": 26,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 0.9454545454545454,
        "median": 0.9454545454545454,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.9346153846153846,
        "median": 0.9346153846153846,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.6666666666666666,
        "median": 0.6666666666666666,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_evidence_based_with_codes_gpt-4-turbo_vs_direct_mcode_optimization_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.03571428571428571,
        "median": 0.03571428571428571,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.043478260869565216,
        "median": 0.043478260869565216,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.16666666666666666,
        "median": 0.16666666666666666,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.06896551724137931,
        "median": 0.06896551724137931,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 1,
        "median": 1,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 22,
        "median": 22,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 5,
        "median": 5,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 10,
        "median": 10,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 27,
        "median": 27,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 1.0,
        "median": 1.0,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.85,
        "median": 0.85,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.6666666666666666,
        "median": 0.6666666666666666,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_simple_gpt-4-turbo_vs_direct_mcode_improved_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.023809523809523808,
        "median": 0.023809523809523808,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.05,
        "median": 0.05,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.043478260869565216,
        "median": 0.043478260869565216,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.046511627906976744,
        "median": 0.046511627906976744,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 1,
        "median": 1,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 19,
        "median": 19,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 22,
        "median": 22,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 29,
        "median": 29,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 27,
        "median": 27,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 0.9655172413793104,
        "median": 0.9655172413793104,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.9407407407407407,
        "median": 0.9407407407407407,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    }
  },
  "overall_metrics": {
    "mapping_jaccard_similarity": {
      "mean": 0.09541386412530145,
      "median": 0.050706033376123234,
      "stdev": 0.13499661516048603,
      "min": 0.0,
      "max": 0.4642857142857143
    },
    "mapping_precision": {
      "mean": 0.14689842340098094,
      "median": 0.08893280632411067,
      "stdev": 0.16421254420795336,
      "min": 0.0,
      "max": 0.5652173913043478
    },
    "mapping_recall": {
      "mean": 0.1721137443791906,
      "median": 0.12373737373737373,
      "stdev": 0.20465082848728355,
      "min": 0.0,
      "max": 0.7222222222222222
    },
    "mapping_f1_score": {
      "mean": 0.1541697334636371,
      "median": 0.09651162790697673,
      "stdev": 0.18147175188668585,
      "min": 0,
      "max": 0.6341463414634146
    },
    "mapping_true_positives": {
      "mean": 2.8,
      "median": 1.5,
      "stdev": 3.73571352696584,
      "min": 0,
      "max": 13
    },
    "mapping_false_positives": {
      "mean": 15.5,
      "median": 13.5,
      "stdev": 5.190803834132479,
      "min": 10,
      "max": 23
    },
    "mapping_false_negatives": {
      "mean": 13.2,
      "median": 13.5,
      "stdev": 6.160808027812225,
      "min": 5,
      "max": 22
    },
    "gold_mappings_count": {
      "mean": 18.8,
      "median": 22.0,
      "stdev": 7.130529043797833,
      "min": 9,
      "max": 29
    },
    "comp_mappings_count": {
      "mean": 21.2,
      "median": 23.0,
      "stdev": 6.941021378570864,
      "min": 11,
      "max": 29
    },
    "gold_avg_confidence": {
      "mean": 0.9303684629546698,
      "median": 0.9366161616161616,
      "stdev": 0.05164623023859518,
      "min": 0.85,
      "max": 1.0
    },
    "comp_avg_confidence": {
      "mean": 0.9184249990112059,
      "median": 0.9376780626780626,
      "stdev": 0.05142962274974675,
      "min": 0.8410714285714286,
      "max": 0.9857142857142858
    },
    "gold_compliance_score": {
      "mean": 0.39999999999999997,
      "median": 0.3333333333333333,
      "stdev": 0.14054567378526128,
      "min": 0.3333333333333333,
      "max": 0.6666666666666666
    },
    "comp_compliance_score": {
      "mean": 0.3333333333333333,
      "median": 0.3333333333333333,
      "stdev": 0.0,
      "min": 0.3333333333333333,
      "max": 0.3333333333333333
    }
  }
}