{
  "metadata": {
    "timestamp": "2025-09-18T21:17:54.800966",
    "total_tasks": 100,
    "successful_tasks": 100
  },
  "results": [
    {
      "task_id": "decaef05-5610-4a0f-9359-c9f737b4058b",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.046511627906976744,
        "mapping_precision": 0.07692307692307693,
        "mapping_recall": 0.10526315789473684,
        "mapping_f1_score": 0.08888888888888889,
        "mapping_true_positives": 2,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 17,
        "gold_mappings_count": 23,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9021739130434783,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "Procedure=\"387713003\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Patient=\"248153007\"",
          "Observation=\"82810-3\"",
          "Patient=\"366630004\""
        ],
        "false_negative_examples": [
          "ResearchStudy=\"R-00319\"",
          "PatientCharacteristic=\"424144002\"",
          "CancerCondition=\"399211009\"",
          "Procedure=\"367336001\"",
          "PatientCharacteristic=\"263495000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.544984817504883
    },
    {
      "task_id": "2d030c96-3248-4839-b04e-fee1cff9e894",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.28125,
        "mapping_precision": 0.47368421052631576,
        "mapping_recall": 0.4090909090909091,
        "mapping_f1_score": 0.43902439024390244,
        "mapping_true_positives": 9,
        "mapping_false_positives": 10,
        "mapping_false_negatives": 13,
        "gold_mappings_count": 28,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9107142857142857,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "Patient=\"30525-0\"",
          "ResearchStudy=\"NCT00386685\"",
          "Observation=\"LP212175-6\"",
          "GenomicVariant=\"HGNC:3430\"",
          "MedicationStatement=\"763875007\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "GenomicVariant=\"LA14042-1\"",
          "MedicationStatement=\"C94413\"",
          "ResearchSubject=\"LA30165-3\"",
          "Observation=\"21908-9\""
        ],
        "false_negative_examples": [
          "Observation=\"LA6576-8\"",
          "CancerCondition=\"C9115000\"",
          "Patient=\"72826-1\"",
          "ResearchStudy=\"secondary\"",
          "MedicationStatement=\"XRP9881\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 29.393911361694336
    },
    {
      "task_id": "7da476d6-f1a8-4525-a8d3-2c7de38de33a",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.10526315789473684,
        "mapping_precision": 0.14285714285714285,
        "mapping_recall": 0.2857142857142857,
        "mapping_f1_score": 0.19047619047619047,
        "mapping_true_positives": 4,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 17,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9764705882352942,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:1101\"",
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:1100\"",
          "Procedure=\"396487001\""
        ],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "Procedure=\"169359004\"",
          "Observation=\"21894-1\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"126906006\"",
          "CancerCondition=\"260385009\"",
          "CancerDiseaseStatus=\"260385009\"",
          "Observation=\"21907-1\"",
          "TumorMarkerTest=\"4464-0\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 31.7230224609375
    },
    {
      "task_id": "204fbb0a-1be3-41a7-9879-6f9b6a05a450",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-chat",
      "metrics": {
        "mapping_jaccard_similarity": 0.352112676056338,
        "mapping_precision": 0.5102040816326531,
        "mapping_recall": 0.5319148936170213,
        "mapping_f1_score": 0.5208333333333334,
        "mapping_true_positives": 25,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 22,
        "gold_mappings_count": 51,
        "comp_mappings_count": 54,
        "gold_avg_confidence": 0.85,
        "comp_avg_confidence": 0.8351851851851853,
        "true_positive_examples": [
          "Patient=\"BG000\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\"",
          "CancerRelatedSurgicalProcedure=\"LA28873-6\""
        ],
        "false_positive_examples": [
          "TNMStaging=\"LA26831-0\"",
          "Observation=\"44255-8\"",
          "ResearchStudy=\"single-group\"",
          "ResearchStudy=\"supportive-care\"",
          "CancerRelatedSurgicalProcedure=\"446551000124108\""
        ],
        "false_negative_examples": [
          "Comorbidity=\"702927005\"",
          "Observation=\"72171-2\"",
          "CancerRelatedRadiationProcedure=\"LA28873-6\"",
          "CancerCondition=\"C126879\"",
          "CancerRelatedComorbidities=\"72892002\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 32.814979553222656
    },
    {
      "task_id": "975dfa53-b621-4f68-bff3-c2adeff46061",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_simple_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.15789473684210525,
        "mapping_precision": 0.2553191489361702,
        "mapping_recall": 0.2926829268292683,
        "mapping_f1_score": 0.2727272727272727,
        "mapping_true_positives": 12,
        "mapping_false_positives": 35,
        "mapping_false_negatives": 29,
        "gold_mappings_count": 53,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.8650943396226415,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"C50.919\"",
          "CancerCondition=\"C50.9\"",
          "CancerDiseaseStatus=\"385633008\"",
          "CancerCondition=\"254837009\"",
          "CancerRelatedSurgicalProcedure=\"LA28873-6\""
        ],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [
          "GenomicVariant=\"LA26610-2\"",
          "Patient=\"442083009\"",
          "Patient=\"372148003\"",
          "CancerRelatedSurgicalProcedure=\"77477000\"",
          "Patient=\"248153007\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.732070922851562
    },
    {
      "task_id": "9306d456-c571-45c8-80d5-c9a68388f219",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.030303030303030304,
        "mapping_precision": 0.0425531914893617,
        "mapping_recall": 0.09523809523809523,
        "mapping_f1_score": 0.0588235294117647,
        "mapping_true_positives": 2,
        "mapping_false_positives": 45,
        "mapping_false_negatives": 19,
        "gold_mappings_count": 55,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.7354545454545455,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "Procedure=\"387713003\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [
          "ResearchStudy.officialTitle=\"NA\"",
          "Procedure=\"367336001\"",
          "Observation=\"unknown\"",
          "StudyDesign=\"OTHER\"",
          "StudyDesign=\"NONE\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 33.55693817138672
    },
    {
      "task_id": "8c9f36a4-05e9-45ca-bcb1-924d8ad3c54c",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_simple_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.11904761904761904,
        "mapping_precision": 0.2631578947368421,
        "mapping_recall": 0.17857142857142858,
        "mapping_f1_score": 0.2127659574468085,
        "mapping_true_positives": 5,
        "mapping_false_positives": 14,
        "mapping_false_negatives": 23,
        "gold_mappings_count": 34,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9352941176470588,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "ResearchStudy=\"NCT00386685\"",
          "GenomicVariant=\"HGNC:3430\"",
          "CancerCondition=\"C50.911\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\""
        ],
        "false_positive_examples": [
          "Patient=\"30525-0\"",
          "MedicationStatement=\"763140\"",
          "GenomicVariant=\"LA14042-1\"",
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP212175-6\""
        ],
        "false_negative_examples": [
          "Patient=\"LA10402-1\"",
          "GenomicVariant=\"LA26421-1\"",
          "ResearchStudy=\"secondary\"",
          "ResearchStudy.design.interventionModel=\"SINGLE_GROUP\"",
          "ResearchStudy=\"safety\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 9.209871292114258
    },
    {
      "task_id": "f11e5714-1e70-428e-8239-2117b1428a41",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_simple_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.10256410256410256,
        "mapping_precision": 0.14285714285714285,
        "mapping_recall": 0.26666666666666666,
        "mapping_f1_score": 0.18604651162790697,
        "mapping_true_positives": 4,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 17,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9617647058823531,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:1101\"",
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:1100\"",
          "Procedure=\"396487001\""
        ],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "Procedure=\"169359004\"",
          "Observation=\"21894-1\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "CancerStageGroup=\"cM0\"",
          "Treatment=\"108290001\"",
          "Observation=\"21907-1\"",
          "TumorMarkerTest=\"4464-0\"",
          "CancerCondition=\"109355002\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 4.736900329589844
    },
    {
      "task_id": "a6d0f2c5-b97d-4731-8c4e-a52f42665114",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "MedicationStatement=\"C94413\"",
          "ResearchSubject=\"LA30165-3\"",
          "GenomicVariant=\"HGNC:3430\"",
          "MedicationStatement=\"763875007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 196.29192352294922
    },
    {
      "task_id": "4886448b-8762-4a68-8833-3ee1ecfe418f",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-chat",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0,
        "mapping_recall": 0.0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 0,
        "mapping_false_negatives": 26,
        "gold_mappings_count": 31,
        "comp_mappings_count": 0,
        "gold_avg_confidence": 0.8951612903225806,
        "comp_avg_confidence": 0,
        "true_positive_examples": [],
        "false_positive_examples": [],
        "false_negative_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"C50.9\"",
          "Patient=\"248153007\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.0
      },
      "status": "Success",
      "duration_ms": 197.8459358215332
    },
    {
      "task_id": "65965af7-66a4-42c4-bc90-e9e40c31b274",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_simple_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"C50.9\"",
          "Patient=\"248153007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 165.36784172058105
    },
    {
      "task_id": "5aa482d2-24f3-45f2-b9d8-cc0d0387eac9",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "GenomicVariant=\"HGNC:1101\"",
          "Procedure=\"236269005\"",
          "Procedure=\"396330004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 168.88976097106934
    },
    {
      "task_id": "01fb51cb-a7f4-43fb-97b5-bf2d8e599f85",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 200.98400115966797
    },
    {
      "task_id": "7b5fa9da-89c7-4f56-9d4c-4b7adbe1c258",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 200.61612129211426
    },
    {
      "task_id": "c92ce809-1ae4-4ea7-9e10-a7727f4d827b",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_simple_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 149.72186088562012
    },
    {
      "task_id": "838a3faa-6234-4eb5-b197-33147c3c207c",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_simple_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 137.8939151763916
    },
    {
      "task_id": "f7cd6b1c-ec9f-4a87-b3dd-a5ae01171e9c",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_simple_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.046511627906976744,
        "mapping_precision": 0.07692307692307693,
        "mapping_recall": 0.10526315789473684,
        "mapping_f1_score": 0.08888888888888889,
        "mapping_true_positives": 2,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 17,
        "gold_mappings_count": 23,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.8913043478260869,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "Patient=\"424144002\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Patient=\"248153007\"",
          "Observation=\"82810-3\"",
          "Patient=\"366630004\""
        ],
        "false_negative_examples": [
          "Treatment=\"372897005\"",
          "Masking=\"NONE\"",
          "Treatment=\"385798007\"",
          "StudyDesign=\"RANDOMIZED\"",
          "MedicationStatement=\"387207008\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 11.703014373779297
    },
    {
      "task_id": "39273ce4-83be-41c4-b531-1c5c56c94ec9",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_simple_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "MedicationStatement=\"C94413\"",
          "ResearchSubject=\"LA30165-3\"",
          "GenomicVariant=\"HGNC:3430\"",
          "MedicationStatement=\"763875007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.302896499633789
    },
    {
      "task_id": "0c24c67f-6260-4a1c-bea8-26804e763a9d",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_simple_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "GenomicVariant=\"HGNC:1101\"",
          "Procedure=\"236269005\"",
          "Procedure=\"396330004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 15.323162078857422
    },
    {
      "task_id": "d931adb1-9a3e-47fe-8de8-50cc6b0456e0",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_comprehensive_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06896551724137931,
        "mapping_precision": 0.10526315789473684,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.12903225806451615,
        "mapping_true_positives": 2,
        "mapping_false_positives": 17,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 17,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9029411764705882,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "Patient=\"30525-0\"",
          "MedicationStatement=\"763140\"",
          "ResearchStudy=\"NCT00386685\"",
          "GenomicVariant=\"LA14042-1\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedication=\"L01XC01\"",
          "CancerDiseaseStatus=\"LA9621-1\"",
          "CancerCondition=\"C9115000\"",
          "GenomicVariant=\"LA6576-8\"",
          "CancerRelatedMedication=\"763875007\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.22684097290039
    },
    {
      "task_id": "78844431-f818-4bc5-b519-778e0542fc8f",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_simple_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0136986301369863,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.037037037037037035,
        "mapping_f1_score": 0.027027027027027025,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 26,
        "gold_mappings_count": 50,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.358,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [
          "ResearchStudy.officialTitle=\"NA\"",
          "AgeAtDiagnosis=\"248152002\"",
          "MenopausalStatus=\"263347007\"",
          "StudyDesign=\"OTHER\"",
          "ProcedureIndicated=\"385763009\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 20.060300827026367
    },
    {
      "task_id": "8339e5e1-eb40-4444-8769-287092bd30eb",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_comprehensive_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"C50.9\"",
          "Patient=\"248153007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.78101921081543
    },
    {
      "task_id": "b3426850-b4c0-436e-a02d-ee51691bd329",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_comprehensive_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03571428571428571,
        "mapping_precision": 0.0425531914893617,
        "mapping_recall": 0.18181818181818182,
        "mapping_f1_score": 0.06896551724137931,
        "mapping_true_positives": 2,
        "mapping_false_positives": 45,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 14,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.9142857142857144,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerDiseaseStatus=\"268910001\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [
          "GenomicVariant=\"C1706427\"",
          "GenomicVariant=\"C1706426\"",
          "TNMClinicalStageGroup=\"21908-9\"",
          "GenomicVariant=\"C1706428\"",
          "CancerDiseaseStatus=\"55561003\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 20.867109298706055
    },
    {
      "task_id": "49ec491d-c203-41b0-b6e9-7cc5e7ea1358",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_comprehensive_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 21.976947784423828
    },
    {
      "task_id": "ddb7d313-2769-4948-b052-becacb07b348",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_comprehensive_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02702702702702703,
        "mapping_precision": 0.03571428571428571,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.05263157894736841,
        "mapping_true_positives": 1,
        "mapping_false_positives": 27,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 13,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9423076923076923,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "Procedure=\"169359004\"",
          "Observation=\"21894-1\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "CancerRelatedProcedure=\"387713003\"",
          "CancerRelatedProcedure=\"129286009\"",
          "GenomicVariant=\"UO:0001699\"",
          "GenomicVariant=\"UO:0001700\"",
          "CancerRelatedProcedure=\"108290001\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 22.127151489257812
    },
    {
      "task_id": "7478c305-b733-413f-bc1f-ed6b0ed04aba",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_comprehensive_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "MedicationStatement=\"C94413\"",
          "ResearchSubject=\"LA30165-3\"",
          "GenomicVariant=\"HGNC:3430\"",
          "MedicationStatement=\"763875007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.210960388183594
    },
    {
      "task_id": "66fc0bde-a299-4c3d-a990-baf13146473c",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_comprehensive_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "GenomicVariant=\"HGNC:1101\"",
          "Procedure=\"236269005\"",
          "Procedure=\"396330004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 15.4571533203125
    },
    {
      "task_id": "b80bc3c4-29e6-4c20-8368-d5846aa566e2",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_comprehensive_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03125,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.14285714285714285,
        "mapping_f1_score": 0.060606060606060615,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 6,
        "gold_mappings_count": 12,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9041666666666667,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Patient=\"248153007\"",
          "Observation=\"82810-3\"",
          "Patient=\"366630004\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedication=\"387207008\"",
          "CancerRelatedProcedure=\"448385000\"",
          "CancerRelatedProcedure=\"387713003\"",
          "CancerRelatedMedication=\"372897005\"",
          "CancerDiseaseStatus=\"261665006\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 21.95000648498535
    },
    {
      "task_id": "68f4e587-9492-4d15-916a-4b2ab2fab5c7",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_comprehensive_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.018518518518518517,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.125,
        "mapping_f1_score": 0.03636363636363636,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 7,
        "gold_mappings_count": 9,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.8166666666666667,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [
          "TNMClinicalStageGroup=\"C77.4\"",
          "GenomicVariant=\"PR\"",
          "CancerDiseaseStatus=\"271299001\"",
          "CancerCondition=\"C4872\"",
          "GenomicVariant=\"HER2\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 25.348901748657227
    },
    {
      "task_id": "69e0774b-3554-4abe-b8f2-f0ce76946e29",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_minimal_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"C50.9\"",
          "Patient=\"248153007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.232086181640625
    },
    {
      "task_id": "f26f5a58-ebe7-432a-8f40-aa1596f7204f",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_comprehensive_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.016666666666666666,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.07142857142857142,
        "mapping_f1_score": 0.032786885245901634,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 13,
        "gold_mappings_count": 59,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.6728813559322034,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [
          "KarnofskyPerformanceStatus=\"NA\"",
          "CancerDiseaseStatus=\"NA\"",
          "CancerRelatedProcedure=\"387713003\"",
          "CancerCondition=\"NA\"",
          "CancerRelatedProcedure=\"NA\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 23.468971252441406
    },
    {
      "task_id": "e8ec10d0-7dfe-404c-abd6-5dde35970032",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_minimal_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.047619047619047616,
        "mapping_precision": 0.0851063829787234,
        "mapping_recall": 0.0975609756097561,
        "mapping_f1_score": 0.09090909090909091,
        "mapping_true_positives": 4,
        "mapping_false_positives": 43,
        "mapping_false_negatives": 37,
        "gold_mappings_count": 43,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.7895348837209303,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"C50.919\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C50.9\"",
          "CancerRelatedComorbidities=\"72892002\""
        ],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedicationAdministration=\"Z51.12\"",
          "CancerRelatedSurgicalProcedure=\"108290001\"",
          "ECOGPerformanceStatus=\"LA9625-5\"",
          "Comorbidity=\"F43.23\"",
          "CancerRelatedMedicationRequest=\"LA10426-8\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 20.524024963378906
    },
    {
      "task_id": "fa80f65f-289b-4789-ba5c-8f52dd7b37a7",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_minimal_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06521739130434782,
        "mapping_precision": 0.10714285714285714,
        "mapping_recall": 0.14285714285714285,
        "mapping_f1_score": 0.12244897959183672,
        "mapping_true_positives": 3,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 18,
        "gold_mappings_count": 23,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9456521739130435,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "Condition=\"254837009\"",
          "CancerCondition=\"254837009\"",
          "Procedure=\"396487001\""
        ],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Procedure=\"169359004\"",
          "Observation=\"21894-1\"",
          "Patient=\"F\"",
          "CancerCondition=\"92546004\""
        ],
        "false_negative_examples": [
          "Observation=\"44662000\"",
          "Patient=\"365645007\"",
          "Observation=\"44662006\"",
          "Observation=\"165816005\"",
          "CancerCondition=\"260385009\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 14.946937561035156
    },
    {
      "task_id": "f30fc6a4-b8a1-47d5-9ffc-c3b557bafaf9",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_minimal_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0.0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 1,
        "gold_mappings_count": 1,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.9,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [
          "PrimaryCancerCondition=\"254837009\""
        ],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.04518699645996
    },
    {
      "task_id": "afed41b2-a9cb-4907-86f8-7d8c2d58a656",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_minimal_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 16.829967498779297
    },
    {
      "task_id": "2c8341ff-b8de-496c-bbef-16184da4eb04",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_minimal_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06060606060606061,
        "mapping_precision": 0.10526315789473684,
        "mapping_recall": 0.125,
        "mapping_f1_score": 0.11428571428571428,
        "mapping_true_positives": 2,
        "mapping_false_positives": 17,
        "mapping_false_negatives": 14,
        "gold_mappings_count": 21,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.8500000000000001,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "Patient=\"30525-0\"",
          "MedicationStatement=\"763140\"",
          "ResearchStudy=\"NCT00386685\"",
          "GenomicVariant=\"LA14042-1\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedicationAdministration=\"C1234\"",
          "GenomicVariant=\"LA6576-8\"",
          "ECOGPerformanceStatus=\"LA9622-4\"",
          "PrimaryCancerCondition=\"254837009\"",
          "CancerCondition=\"C50.9\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 23.25296401977539
    },
    {
      "task_id": "46445d15-9a3c-4462-9f32-e75a97c9f509",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_minimal_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "MedicationStatement=\"C94413\"",
          "ResearchSubject=\"LA30165-3\"",
          "GenomicVariant=\"HGNC:3430\"",
          "MedicationStatement=\"763875007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.323162078857422
    },
    {
      "task_id": "b58c18b9-4716-4b4a-a9ef-5634c0f55cc0",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_minimal_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.021739130434782608,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.047619047619047616,
        "mapping_f1_score": 0.0425531914893617,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 20,
        "gold_mappings_count": 25,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.89,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Patient=\"248153007\"",
          "Observation=\"82810-3\"",
          "Patient=\"366630004\""
        ],
        "false_negative_examples": [
          "Masking=\"C70830\"",
          "CancerStage=\"C77.3\"",
          "TreatmentChange=\"16076005\"",
          "HormoneReceptorStatus=\"373147003\"",
          "MedicationStatement=\"372897005\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.941951751708984
    },
    {
      "task_id": "d0c47b94-ccf8-405b-ab70-b50a53df0435",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_minimal_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "GenomicVariant=\"HGNC:1101\"",
          "Procedure=\"236269005\"",
          "Procedure=\"396330004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 16.885995864868164
    },
    {
      "task_id": "a84c3400-bfe3-468e-835d-02fa0a8d6b27",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_minimal_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.010638297872340425,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.020833333333333332,
        "mapping_f1_score": 0.021052631578947368,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 47,
        "gold_mappings_count": 80,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "Observation=\"1975-2\""
        ],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [
          "Condition=\"254837009\"",
          "Unit of Measure=\"NA\"",
          "Mammographic Breast Density=\"363680008\"",
          "Procedure=\"367336001\"",
          "Outcome Measure Title=\"NA\""
        ],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 21.67510986328125
    },
    {
      "task_id": "8b7d1da2-45d6-4942-bec1-4e061ff5f319",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_structured_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"C50.9\"",
          "Patient=\"248153007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 13.746976852416992
    },
    {
      "task_id": "78f2cf1a-85f5-4252-913a-bdff78e4b6e5",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_structured_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.48204231262207
    },
    {
      "task_id": "b7c16f0a-a5de-4611-b362-779e26c84f28",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_structured_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06153846153846154,
        "mapping_precision": 0.0851063829787234,
        "mapping_recall": 0.18181818181818182,
        "mapping_f1_score": 0.11594202898550723,
        "mapping_true_positives": 4,
        "mapping_false_positives": 43,
        "mapping_false_negatives": 18,
        "gold_mappings_count": 43,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.8976744186046512,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"C50.919\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"363346000\"",
          "CancerDiseaseStatus=\"385633008\""
        ],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"C79.51\"",
          "CancerRelatedMedicationAdministration=\"LA19536-9\"",
          "CancerRelatedSurgicalProcedure=\"SNOMED_CT_PLACEHOLDER\"",
          "GenomicVariant=\"HGNC:9446\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 25.47311782836914
    },
    {
      "task_id": "463137af-bd69-41b6-b218-091c787a2752",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_structured_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.17857142857142858,
        "mapping_precision": 0.2631578947368421,
        "mapping_recall": 0.35714285714285715,
        "mapping_f1_score": 0.30303030303030304,
        "mapping_true_positives": 5,
        "mapping_false_positives": 14,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 19,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9657894736842106,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:3430\"",
          "MedicationStatement=\"763875007\"",
          "CancerCondition=\"C50.911\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\""
        ],
        "false_positive_examples": [
          "Patient=\"30525-0\"",
          "MedicationStatement=\"763140\"",
          "ResearchStudy=\"NCT00386685\"",
          "GenomicVariant=\"LA14042-1\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [
          "GenomicVariant=\"HGNC:6018\"",
          "CancerRelatedMedicationContraindication=\"LA19544-7\"",
          "GenomicVariant=\"LA6576-8\"",
          "CancerCondition=\"C50.919\"",
          "CancerCondition=\"C50.9\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 22.671937942504883
    },
    {
      "task_id": "a398db9d-9318-458c-9ee4-d858f1ac4f57",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_structured_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.332170486450195
    },
    {
      "task_id": "181abeb9-4bc7-40d1-9112-2c4a3482e904",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_structured_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.07894736842105263,
        "mapping_precision": 0.10714285714285714,
        "mapping_recall": 0.23076923076923078,
        "mapping_f1_score": 0.14634146341463414,
        "mapping_true_positives": 3,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 15,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:1101\"",
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:1100\""
        ],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "Procedure=\"169359004\"",
          "Observation=\"21894-1\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"126906006\"",
          "Treatment=\"108290001\"",
          "CancerCondition=\"260385009\"",
          "CancerCondition=\"254848004\"",
          "CancerCondition=\"109355002\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 21.628856658935547
    },
    {
      "task_id": "48d24e3b-0586-4d30-a62a-4419e513b502",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_structured_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.030303030303030304,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.125,
        "mapping_f1_score": 0.058823529411764705,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 7,
        "gold_mappings_count": 13,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9115384615384615,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Patient=\"248153007\"",
          "Observation=\"82810-3\"",
          "Patient=\"366630004\""
        ],
        "false_negative_examples": [
          "CancerTreatment=\"372856001\"",
          "CancerTreatment=\"372864008\"",
          "CancerCondition=\"C0006826\"",
          "CancerTreatment=\"372857005\"",
          "CancerCondition=\"313217004\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 20.151138305664062
    },
    {
      "task_id": "6792db80-b7da-48f0-ac89-a81f9b5c87ad",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_structured_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "MedicationStatement=\"C94413\"",
          "ResearchSubject=\"LA30165-3\"",
          "GenomicVariant=\"HGNC:3430\"",
          "MedicationStatement=\"763875007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.022371292114258
    },
    {
      "task_id": "e684cfd9-d636-46cf-95b7-d1cd4d35b838",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_structured_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0196078431372549,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.2,
        "mapping_f1_score": 0.03846153846153846,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 4,
        "gold_mappings_count": 20,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [
          "Device=\"700000000000\"",
          "Procedure=\"367336001\"",
          "CancerCondition=\"363346000\"",
          "ImagingStudy=\"394914008\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 22.21512794494629
    },
    {
      "task_id": "802dd15e-7dd1-4298-8e6d-ead879441662",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_optimization_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"C50.9\"",
          "Patient=\"248153007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.049934387207031
    },
    {
      "task_id": "6af847f6-89bd-478c-a5eb-986cdb03172d",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_structured_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "GenomicVariant=\"HGNC:1101\"",
          "Procedure=\"236269005\"",
          "Procedure=\"396330004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 19.15597915649414
    },
    {
      "task_id": "f6754b34-5191-4c1d-b71c-d464a7b2c5ef",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_optimization_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 16.74795150756836
    },
    {
      "task_id": "6dbd4c0b-0e08-4c75-99db-64869ec2b095",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_optimization_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.10344827586206896,
        "mapping_precision": 0.15789473684210525,
        "mapping_recall": 0.23076923076923078,
        "mapping_f1_score": 0.18749999999999997,
        "mapping_true_positives": 3,
        "mapping_false_positives": 16,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 21,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.8547619047619047,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C50.911\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "Patient=\"30525-0\"",
          "MedicationStatement=\"763140\"",
          "ResearchStudy=\"NCT00386685\"",
          "GenomicVariant=\"LA14042-1\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [
          "Patient=\"LA14006-8\"",
          "CancerDiseaseStatus=\"LA14006-8\"",
          "CancerCondition=\"C50.919\"",
          "CancerRelatedMedicationAdministration=\"XRP9881\"",
          "CancerCondition=\"C1266163\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.55325698852539
    },
    {
      "task_id": "1133b3ca-390c-4687-b9b0-b8c015065429",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_optimization_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.840147018432617
    },
    {
      "task_id": "581c5d41-203f-42c3-995f-acf74877826c",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_optimization_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.08695652173913043,
        "mapping_precision": 0.1276595744680851,
        "mapping_recall": 0.21428571428571427,
        "mapping_f1_score": 0.16,
        "mapping_true_positives": 6,
        "mapping_false_positives": 41,
        "mapping_false_negatives": 22,
        "gold_mappings_count": 42,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.7845238095238096,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"C50.919\"",
          "Patient=\"305780008\"",
          "CancerDiseaseStatus=\"385633008\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"363346000\""
        ],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [
          "Patient=\"442083009\"",
          "CancerCondition=\"108369006\"",
          "Patient=\"413350009\"",
          "CancerDiseaseStatus=\"28163009\"",
          "GenomicVariant=\"LA26831-8\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 23.59914779663086
    },
    {
      "task_id": "8856bd5b-f1c0-451d-8727-eed21775907e",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_optimization_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.043478260869565216,
        "mapping_precision": 0.07142857142857142,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.08333333333333333,
        "mapping_true_positives": 2,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 18,
        "gold_mappings_count": 22,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.865909090909091,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "Procedure=\"396487001\""
        ],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "Procedure=\"169359004\"",
          "Observation=\"21894-1\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"126906006\"",
          "GenomicVariant=\"429358007\"",
          "CancerCondition=\"260385009\"",
          "CancerDiseaseStatus=\"260385009\"",
          "Observation=\"48694002\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 21.504878997802734
    },
    {
      "task_id": "388b931b-37fa-4708-b9c5-4af9e0b73f30",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_optimization_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02857142857142857,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.05555555555555555,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 13,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.8999999999999999,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Patient=\"248153007\"",
          "Observation=\"82810-3\"",
          "Patient=\"366630004\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"433581000124108\"",
          "ClinicalTrial=\"NCT00000000\"",
          "CancerDiseaseStatus=\"373930000\"",
          "CancerCondition=\"161646007\"",
          "CancerTreatment=\"372876000\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.170045852661133
    },
    {
      "task_id": "00e2fc00-5c1f-44c0-970c-f258566dab7c",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_optimization_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "MedicationStatement=\"C94413\"",
          "ResearchSubject=\"LA30165-3\"",
          "GenomicVariant=\"HGNC:3430\"",
          "MedicationStatement=\"763875007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.049955368041992
    },
    {
      "task_id": "3d26237f-15d8-4b7d-883f-d9c6b0d7a306",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_optimization_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "GenomicVariant=\"HGNC:1101\"",
          "Procedure=\"236269005\"",
          "Procedure=\"396330004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 15.859127044677734
    },
    {
      "task_id": "626d3afd-fcd1-4bfb-b36e-3d5ea0c262b2",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_optimization_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.017857142857142856,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.03508771929824561,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 14,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [
          "ECOGPerformanceStatus=\"255428009\"",
          "PatientAge=\"424144002\"",
          "Procedure=\"367336001\"",
          "Observation=\"246090004\"",
          "Procedure=\"385763009\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 21.831035614013672
    },
    {
      "task_id": "51496c7a-d91c-43a9-8709-c160df891433",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_improved_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03508771929824561,
        "mapping_precision": 0.0425531914893617,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.06779661016949153,
        "mapping_true_positives": 2,
        "mapping_false_positives": 45,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 14,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.9357142857142857,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerDiseaseStatus=\"268910001\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [
          "TNMClinicalStageGroup=\"21908-9\"",
          "GenomicVariant=\"C0205729\"",
          "CancerCondition=\"C91150\"",
          "GenomicVariant=\"C0205728\"",
          "CancerDiseaseStatus=\"55561003\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 21.420955657958984
    },
    {
      "task_id": "acba0a5b-e82b-409c-b1b5-a39da5a14e0f",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_improved_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"C50.9\"",
          "Patient=\"248153007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.011735916137695
    },
    {
      "task_id": "9f3bf214-f36b-4acb-b03a-450dff27bafd",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_improved_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06896551724137931,
        "mapping_precision": 0.10526315789473684,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.12903225806451615,
        "mapping_true_positives": 2,
        "mapping_false_positives": 17,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 17,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9147058823529413,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "Patient=\"30525-0\"",
          "MedicationStatement=\"763140\"",
          "ResearchStudy=\"NCT00386685\"",
          "GenomicVariant=\"LA14042-1\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedication=\"763875007\"",
          "CancerRelatedProcedure=\"252416005\"",
          "CancerRelatedMedication=\"372687004\"",
          "CancerCondition=\"C50.9\"",
          "CancerRelatedMedication=\"N/A\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.96071434020996
    },
    {
      "task_id": "3b94383c-18e8-475f-b1f5-c96ced9365b8",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_improved_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.292903900146484
    },
    {
      "task_id": "83d75ba8-982d-4b65-99ba-02c5bbca6009",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_improved_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.038034439086914
    },
    {
      "task_id": "4b625985-b4b5-4c61-8d54-22d103a13962",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_improved_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02857142857142857,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.05555555555555555,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 13,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.8807692307692307,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Patient=\"248153007\"",
          "Observation=\"82810-3\"",
          "Patient=\"366630004\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedication=\"372756006\"",
          "CancerRelatedMedication=\"387207008\"",
          "CancerRelatedProcedure=\"387713003\"",
          "CancerRelatedMedication=\"387458008\"",
          "CancerRelatedMedication=\"372897005\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 16.968965530395508
    },
    {
      "task_id": "48405ab4-7bfb-4595-9c1b-7ca1ba094ba7",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_improved_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "MedicationStatement=\"C94413\"",
          "ResearchSubject=\"LA30165-3\"",
          "GenomicVariant=\"HGNC:3430\"",
          "MedicationStatement=\"763875007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.277624130249023
    },
    {
      "task_id": "9b21e8d6-694e-4fef-80b8-b23fa95fdaaa",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_improved_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02564102564102564,
        "mapping_precision": 0.03571428571428571,
        "mapping_recall": 0.08333333333333333,
        "mapping_f1_score": 0.05,
        "mapping_true_positives": 1,
        "mapping_false_positives": 27,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 14,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9249999999999999,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "Procedure=\"169359004\"",
          "Observation=\"21894-1\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "CancerRelatedProcedure=\"10374003\"",
          "CancerRelatedProcedure=\"180325003\"",
          "CancerRelatedProcedure=\"387713003\"",
          "CancerRelatedProcedure=\"129286009\"",
          "GenomicVariant=\"BRCA2\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 20.914793014526367
    },
    {
      "task_id": "ebf41f31-fec0-493f-b18d-cc79e4ce0641",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"C50.9\"",
          "Patient=\"248153007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 14.939069747924805
    },
    {
      "task_id": "a8b58050-1ea6-4682-a0a1-4e01dab25225",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_improved_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "GenomicVariant=\"HGNC:1101\"",
          "Procedure=\"236269005\"",
          "Procedure=\"396330004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 18.350839614868164
    },
    {
      "task_id": "458771f0-1513-4188-895f-82980b4b6948",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_improved_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.01818181818181818,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.1111111111111111,
        "mapping_f1_score": 0.03571428571428571,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 8,
        "gold_mappings_count": 40,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.8150000000000001,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [
          "CancerRelatedProcedure=\"387713003\"",
          "CancerCondition=\"NA\"",
          "CancerRelatedProcedure=\"NA\"",
          "CancerRelatedMedication=\"372098003\"",
          "CancerDiseaseStatus=\"55561003\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 22.50385284423828
    },
    {
      "task_id": "8ed356fe-b2e2-4ca8-bbf2-9906b78e3ecb",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.05970149253731343,
        "mapping_precision": 0.0851063829787234,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.11267605633802817,
        "mapping_true_positives": 4,
        "mapping_false_positives": 43,
        "mapping_false_negatives": 20,
        "gold_mappings_count": 44,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.9954545454545454,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "Observation=\"72826-1\"",
          "Patient=\"F\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"research-study\""
        ],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [
          "GenomicVariant=\"HGNC:3430\"",
          "ResearchStudy=\"LA28874-4\"",
          "GenomicVariant=\"HGNC:9446\"",
          "CancerCondition=\"1224566008\"",
          "ResearchStudy=\"LA28873-6\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 23.112058639526367
    },
    {
      "task_id": "db9ac896-b575-47ec-a58a-6fca33f1eb1c",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.12121212121212122,
        "mapping_precision": 0.21052631578947367,
        "mapping_recall": 0.2222222222222222,
        "mapping_f1_score": 0.21621621621621623,
        "mapping_true_positives": 4,
        "mapping_false_positives": 15,
        "mapping_false_negatives": 14,
        "gold_mappings_count": 19,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"NCT00386685\"",
          "ResearchStudy=\"research-study\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "Patient=\"30525-0\"",
          "MedicationStatement=\"763140\"",
          "GenomicVariant=\"LA14042-1\"",
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP212175-6\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedication=\"trastuzumab\"",
          "CancerRelatedMedication=\"L01XC03\"",
          "ResearchStudy=\"NONE\"",
          "ResearchStudy=\"SINGLE_GROUP\"",
          "ResearchStudy=\"NON_RANDOMIZED\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.618106842041016
    },
    {
      "task_id": "496ec47c-01ca-41e2-bf0a-ce95485973fe",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 21.311044692993164
    },
    {
      "task_id": "b1a6dc7e-a560-4a5e-a4ae-c08a75e101ea",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 20.816802978515625
    },
    {
      "task_id": "ea15d7ca-a0a4-4554-b0f3-a399561693d7",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.1,
        "mapping_precision": 0.17857142857142858,
        "mapping_recall": 0.18518518518518517,
        "mapping_f1_score": 0.18181818181818182,
        "mapping_true_positives": 5,
        "mapping_false_positives": 23,
        "mapping_false_negatives": 22,
        "gold_mappings_count": 32,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:1101\"",
          "Condition=\"254837009\"",
          "GenomicVariant=\"HGNC:1100\"",
          "Procedure=\"396487001\"",
          "ResearchStudy=\"NCT05417516\""
        ],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Procedure=\"169359004\"",
          "Observation=\"21894-1\"",
          "Patient=\"F\"",
          "CancerCondition=\"92546004\""
        ],
        "false_negative_examples": [
          "RadiationProcedure=\"385798007\"",
          "Procedure=\"44301000119101\"",
          "ResearchStudy=\"primaryPurpose\"",
          "Observation=\"77386006\"",
          "ResearchStudy=\"allocation\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 21.991252899169922
    },
    {
      "task_id": "c216e925-e0de-4d14-94ac-c2b8a1755698",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "MedicationStatement=\"C94413\"",
          "ResearchSubject=\"LA30165-3\"",
          "GenomicVariant=\"HGNC:3430\"",
          "MedicationStatement=\"763875007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.017053604125977
    },
    {
      "task_id": "20c43c97-2d66-4691-9fa2-ab518664b077",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.08571428571428572,
        "mapping_precision": 0.11538461538461539,
        "mapping_recall": 0.25,
        "mapping_f1_score": 0.15789473684210525,
        "mapping_true_positives": 3,
        "mapping_false_positives": 23,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 19,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9894736842105264,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C50.9\"",
          "ResearchStudy=\"NCT00286117\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Patient=\"248153007\"",
          "Observation=\"82810-3\"",
          "Patient=\"366630004\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"C77.3\"",
          "Biomarker=\"ER\"",
          "CancerRelatedMedication=\"387458008\"",
          "CancerRelatedMedication=\"372906003\"",
          "CancerRelatedMedication=\"372897005\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.733905792236328
    },
    {
      "task_id": "3f6f55ef-e083-48c9-8ff8-83574162e047",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "GenomicVariant=\"HGNC:1101\"",
          "Procedure=\"236269005\"",
          "Procedure=\"396330004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 19.97089385986328
    },
    {
      "task_id": "01e1f2e0-aa48-451f-8775-f3a657834910",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.011363636363636364,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.023809523809523808,
        "mapping_f1_score": 0.022471910112359546,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 41,
        "gold_mappings_count": 102,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.9705882352941176,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [
          "OutcomeMeasureUnitOfMeasure=\"NA\"",
          "OutcomeMeasureDenominator=\"NA\"",
          "LaboratoryTest=\"165889000119104\"",
          "OutcomeMeasureParamType=\"NA\"",
          "OutcomeMeasureGroupID=\"NA\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 23.164033889770508
    },
    {
      "task_id": "00bb6dc8-f394-40f1-9400-5d99de587d23",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_concise_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.038461538461538464,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 1.0,
        "mapping_f1_score": 0.07407407407407407,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 1,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"C50.9\"",
          "Patient=\"248153007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.127918243408203
    },
    {
      "task_id": "37a69732-4ad2-4d85-af1f-b483f1eeb695",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_concise_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03773584905660377,
        "mapping_precision": 0.0425531914893617,
        "mapping_recall": 0.25,
        "mapping_f1_score": 0.07272727272727272,
        "mapping_true_positives": 2,
        "mapping_false_positives": 45,
        "mapping_false_negatives": 6,
        "gold_mappings_count": 16,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"363346000\""
        ],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [
          "PatientDemographics=\"424144002\"",
          "PatientDemographics=\"184099003\"",
          "TNMStage=\"399518008\"",
          "PatientDemographics=\"184100006\"",
          "PatientDemographics=\"248152002\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 21.8808650970459
    },
    {
      "task_id": "f6ff6149-88ca-4145-a59f-7bc105f2fa1c",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_concise_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.041666666666666664,
        "mapping_precision": 0.05263157894736842,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.08,
        "mapping_true_positives": 1,
        "mapping_false_positives": 18,
        "mapping_false_negatives": 5,
        "gold_mappings_count": 8,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"30525-0\"",
          "MedicationStatement=\"763140\"",
          "ResearchStudy=\"NCT00386685\"",
          "GenomicVariant=\"LA14042-1\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [
          "PatientDemographics=\"424144002\"",
          "CancerCondition=\"108369006\"",
          "CancerTreatment=\"387018007\"",
          "CancerCondition=\"702971005\"",
          "CancerTreatment=\"763875007\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.55413818359375
    },
    {
      "task_id": "6a4ade1f-5e4f-4bf0-a7ca-133f5ced6445",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_concise_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.23823356628418
    },
    {
      "task_id": "09a80f4d-1e47-4d92-bed6-fae8875610ff",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02564102564102564,
        "mapping_precision": 0.03571428571428571,
        "mapping_recall": 0.08333333333333333,
        "mapping_f1_score": 0.05,
        "mapping_true_positives": 1,
        "mapping_false_positives": 27,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 16,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9875,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "Procedure=\"169359004\"",
          "Observation=\"21894-1\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "TNMStage=\"80003\"",
          "ResearchSubject=\"Not Applicable\"",
          "ResearchStudy=\"Not Applicable\"",
          "CancerTreatment=\"387713003\"",
          "CancerTreatment=\"385798007\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 18.44477653503418
    },
    {
      "task_id": "c34ebfc1-6d08-4167-979b-1176d09071ae",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 21.56376838684082
    },
    {
      "task_id": "dd5358d5-d18a-4fea-95eb-dea76e1128d1",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "MedicationStatement=\"C94413\"",
          "ResearchSubject=\"LA30165-3\"",
          "GenomicVariant=\"HGNC:3430\"",
          "MedicationStatement=\"763875007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.872001647949219
    },
    {
      "task_id": "cbbf83e9-1085-4b68-98dc-c9a11f659389",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02631578947368421,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.07692307692307693,
        "mapping_f1_score": 0.05128205128205129,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 12,
        "gold_mappings_count": 16,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.99375,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Patient=\"248153007\"",
          "Observation=\"82810-3\"",
          "Patient=\"366630004\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"128462008\"",
          "PatientCharacteristic=\"424144002\"",
          "Masking=\"N/A\"",
          "CancerCondition=\"161646007\"",
          "StudyPurpose=\"N/A\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 22.853851318359375
    },
    {
      "task_id": "e280930e-86d8-4597-9e52-728424975732",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_with_codes_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"C50.9\"",
          "Patient=\"248153007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 14.586925506591797
    },
    {
      "task_id": "af63ea7c-f97b-4b77-81fc-619c0240c67b",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_concise_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "GenomicVariant=\"HGNC:1101\"",
          "Procedure=\"236269005\"",
          "Procedure=\"396330004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 17.51089096069336
    },
    {
      "task_id": "69b1a1a5-ac96-49cc-b2b8-779fce3c7b16",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.017543859649122806,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.09090909090909091,
        "mapping_f1_score": 0.034482758620689655,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 41,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [
          "StudyDesign=\"NONE\"",
          "CancerCondition=\"NA\"",
          "OutcomeMeasure=\"NA\"",
          "CancerTreatment=\"NA\"",
          "StudyDesign=\"SINGLE_GROUP\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 22.9189395904541
    },
    {
      "task_id": "f8113818-d3d0-4201-9ff9-7e0f45290140",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_with_codes_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.04,
        "mapping_precision": 0.05263157894736842,
        "mapping_recall": 0.14285714285714285,
        "mapping_f1_score": 0.07692307692307693,
        "mapping_true_positives": 1,
        "mapping_false_positives": 18,
        "mapping_false_negatives": 6,
        "gold_mappings_count": 11,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.990909090909091,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"30525-0\"",
          "MedicationStatement=\"763140\"",
          "ResearchStudy=\"NCT00386685\"",
          "GenomicVariant=\"LA14042-1\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [
          "TumorMarker=\"371494000\"",
          "CancerCondition=\"371494000\"",
          "CancerCondition=\"706891004\"",
          "PatientDemographic=\"184099003\"",
          "CancerTreatment=\"367336001\""
        ],
        "gold_compliance_score": 1.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.576860427856445
    },
    {
      "task_id": "1683bf28-fe10-4c1b-beed-3b0768e210b7",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_with_codes_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.019230769230769232,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.03773584905660377,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 5,
        "gold_mappings_count": 20,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.985,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [
          "TNMStage=\"399537006\"",
          "PatientDemographics=\"184099003\"",
          "CancerCondition=\"371494000\"",
          "PatientDemographics=\"248152002\"",
          "PatientDemographics=\"248153007\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 25.941848754882812
    },
    {
      "task_id": "3a87c58d-9997-49fd-a36f-d92b3e3b07f8",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_with_codes_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 20.102262496948242
    },
    {
      "task_id": "0d694646-e60b-4a21-8d1a-c33bac31525b",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.024390243902439025,
        "mapping_precision": 0.03571428571428571,
        "mapping_recall": 0.07142857142857142,
        "mapping_f1_score": 0.047619047619047616,
        "mapping_true_positives": 1,
        "mapping_false_positives": 27,
        "mapping_false_negatives": 13,
        "gold_mappings_count": 21,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "Procedure=\"169359004\"",
          "Observation=\"21894-1\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "TumorMarkers=\"371497007\"",
          "PatientDemographics=\"184099003\"",
          "CancerCondition=\"371494000\"",
          "CancerCondition=\"109356001\"",
          "CancerCondition=\"109355002\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 19.999980926513672
    },
    {
      "task_id": "06973077-1deb-4709-81e0-d044e4068c96",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"763140\"",
          "MedicationStatement=\"C94413\"",
          "ResearchSubject=\"LA30165-3\"",
          "GenomicVariant=\"HGNC:3430\"",
          "MedicationStatement=\"763875007\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 14.577150344848633
    },
    {
      "task_id": "ab71a3c7-5b52-42a1-ab11-9fed04bf09ce",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.018518518518518517,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.125,
        "mapping_f1_score": 0.03636363636363636,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 7,
        "gold_mappings_count": 13,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.9769230769230769,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Patient=\"BG000\"",
          "Comorbidity=\"702927005\"",
          "Observation=\"72110-0\"",
          "GenomicVariant=\"LA26608-7\"",
          "Observation=\"30525-0\""
        ],
        "false_negative_examples": [
          "PatientDemographics=\"184099003\"",
          "CancerCondition=\"371494000\"",
          "TNMStage=\"399537006\"",
          "CancerCondition=\"432469009\"",
          "CancerCondition=\"432468001\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 16.885042190551758
    },
    {
      "task_id": "b9e2de82-8be4-4adf-9768-abb7e5901324",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03125,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.14285714285714285,
        "mapping_f1_score": 0.060606060606060615,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 6,
        "gold_mappings_count": 14,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9928571428571429,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"108369006\"",
          "Patient=\"2186007\"",
          "Patient=\"248153007\"",
          "Observation=\"82810-3\"",
          "Patient=\"366630004\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"371494000\"",
          "CancerTreatment=\"386876001\"",
          "CancerTreatment=\"387136007\"",
          "CancerCondition=\"432469009\"",
          "PatientDemographics=\"289908002\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.678260803222656
    },
    {
      "task_id": "b5e79ba8-6676-48a1-be1e-091ee625b9b1",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_with_codes_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"281985006\"",
          "Condition=\"254837009\"",
          "GenomicVariant=\"HGNC:1101\"",
          "Procedure=\"236269005\"",
          "Procedure=\"396330004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 12.121200561523438
    },
    {
      "task_id": "aac206e9-42c6-40e2-bae1-170544c2a753",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.017241379310344827,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.08333333333333333,
        "mapping_f1_score": 0.03389830508474576,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 35,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.9799999999999999,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"2160-0\"",
          "Observation=\"777-3\"",
          "BodyStructure=\"442083009\"",
          "Observation=\"88040-1\"",
          "Condition=\"B20\""
        ],
        "false_negative_examples": [
          "PatientDemographics=\"184099003\"",
          "CancerCondition=\"371494000\"",
          "TNMStage=\"399537006\"",
          "StudyDesign=\"260299005\"",
          "StudyDesign=\"SINGLE_GROUP\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.061616897583008
    }
  ],
  "analysis": {
    "summary": {
      "total_comparisons": 100,
      "successful_comparisons": 100,
      "success_rate": 1.0,
      "unique_config_pairs": 80
    },
    "configuration_analysis": {
      "direct_mcode_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.023255813953488372,
          "median": 0.023255813953488372,
          "stdev": 0.03288868749704872,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.038461538461538464,
          "median": 0.038461538461538464,
          "stdev": 0.05439282932204212,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0.07443229275647868,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.044444444444444446,
          "median": 0.044444444444444446,
          "stdev": 0.0628539361054709,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 1.4142135623730951,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 16.263455967290593,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 8.5,
          "median": 8.5,
          "stdev": 12.020815280171307,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 11.5,
          "median": 11.5,
          "stdev": 16.263455967290593,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.45108695652173914,
          "median": 0.45108695652173914,
          "stdev": 0.6379332917226461,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.28125,
          "median": 0.28125,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.47368421052631576,
          "median": 0.47368421052631576,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.4090909090909091,
          "median": 0.4090909090909091,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.43902439024390244,
          "median": 0.43902439024390244,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9107142857142857,
          "median": 0.9107142857142857,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.2857142857142857,
          "median": 0.2857142857142857,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.19047619047619047,
          "median": 0.19047619047619047,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9764705882352942,
          "median": 0.9764705882352942,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_deepseek-coder_vs_direct_mcode_deepseek-chat": {
        "mapping_jaccard_similarity": {
          "mean": 0.176056338028169,
          "median": 0.176056338028169,
          "stdev": 0.24898126098117868,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.25510204081632654,
          "median": 0.25510204081632654,
          "stdev": 0.36076876591150386,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.26595744680851063,
          "median": 0.26595744680851063,
          "stdev": 0.37612062829071674,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.2604166666666667,
          "median": 0.2604166666666667,
          "stdev": 0.3682847818679935,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 12.5,
          "median": 12.5,
          "stdev": 17.67766952966369,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 12,
          "median": 12.0,
          "stdev": 16.97056274847714,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 24,
          "median": 24.0,
          "stdev": 2.8284271247461903,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 27,
          "median": 27.0,
          "stdev": 38.18376618407357,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.4175925925925926,
          "median": 0.4175925925925926,
          "stdev": 0.5905651079909869,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        }
      },
      "direct_mcode_simple_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.07894736842105263,
          "median": 0.07894736842105263,
          "stdev": 0.11164843913471803,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.1276595744680851,
          "median": 0.1276595744680851,
          "stdev": 0.18053790157954402,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.14634146341463414,
          "median": 0.14634146341463414,
          "stdev": 0.2069580822985017,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.13636363636363635,
          "median": 0.13636363636363635,
          "stdev": 0.1928473039599675,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 6,
          "median": 6.0,
          "stdev": 8.48528137423857,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 30.5,
          "median": 30.5,
          "stdev": 6.363961030678928,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 14.5,
          "median": 14.5,
          "stdev": 20.506096654409877,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 26.5,
          "median": 26.5,
          "stdev": 37.476659402887016,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.43254716981132074,
          "median": 0.43254716981132074,
          "stdev": 0.6117140739132679,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.030303030303030304,
          "median": 0.030303030303030304,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.09523809523809523,
          "median": 0.09523809523809523,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.0588235294117647,
          "median": 0.0588235294117647,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 45,
          "median": 45,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 55,
          "median": 55,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.7354545454545455,
          "median": 0.7354545454545455,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.11904761904761904,
          "median": 0.11904761904761904,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.2631578947368421,
          "median": 0.2631578947368421,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.17857142857142858,
          "median": 0.17857142857142858,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.2127659574468085,
          "median": 0.2127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9352941176470588,
          "median": 0.9352941176470588,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.10256410256410256,
          "median": 0.10256410256410256,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.26666666666666666,
          "median": 0.26666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.18604651162790697,
          "median": 0.18604651162790697,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.023255813953488372,
          "median": 0.023255813953488372,
          "stdev": 0.03288868749704872,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.038461538461538464,
          "median": 0.038461538461538464,
          "stdev": 0.05439282932204212,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0.07443229275647868,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.044444444444444446,
          "median": 0.044444444444444446,
          "stdev": 0.0628539361054709,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 1.4142135623730951,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 16.263455967290593,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 8.5,
          "median": 8.5,
          "stdev": 12.020815280171307,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 11.5,
          "median": 11.5,
          "stdev": 16.263455967290593,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.44565217391304346,
          "median": 0.44565217391304346,
          "stdev": 0.6302473484488793,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_simple_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06896551724137931,
          "median": 0.06896551724137931,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.12903225806451615,
          "median": 0.12903225806451615,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9029411764705882,
          "median": 0.9029411764705882,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0136986301369863,
          "median": 0.0136986301369863,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.037037037037037035,
          "median": 0.037037037037037035,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.027027027027027025,
          "median": 0.027027027027027025,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 26,
          "median": 26,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 50,
          "median": 50,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.358,
          "median": 0.358,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017857142857142856,
          "median": 0.017857142857142856,
          "stdev": 0.025253813613805267,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0.030089650263257342,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.09090909090909091,
          "median": 0.09090909090909091,
          "stdev": 0.128564869306645,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.034482758620689655,
          "median": 0.034482758620689655,
          "stdev": 0.04876598490941707,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 1.4142135623730951,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 13.435028842544403,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 4.5,
          "median": 4.5,
          "stdev": 6.363961030678928,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 7,
          "median": 7.0,
          "stdev": 9.899494936611665,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4571428571428572,
          "median": 0.4571428571428572,
          "stdev": 0.646497628513415,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_comprehensive_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02702702702702703,
          "median": 0.02702702702702703,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.05263157894736841,
          "median": 0.05263157894736841,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9423076923076923,
          "median": 0.9423076923076923,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02488425925925926,
          "median": 0.02488425925925926,
          "stdev": 0.009002516890106508,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.02986906710310966,
          "median": 0.02986906710310966,
          "stdev": 0.01215158952939239,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.13392857142857142,
          "median": 0.13392857142857142,
          "stdev": 0.012626906806902628,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.04848484848484849,
          "median": 0.04848484848484849,
          "stdev": 0.017141982574219342,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 0.0,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 14.849242404917497,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 6.5,
          "median": 6.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 10.5,
          "median": 10.5,
          "stdev": 2.1213203435596424,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.8604166666666666,
          "median": 0.8604166666666666,
          "stdev": 0.061871843353822925,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_minimal_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.023809523809523808,
          "median": 0.023809523809523808,
          "stdev": 0.03367175148507369,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0.060179300526514684,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.04878048780487805,
          "median": 0.04878048780487805,
          "stdev": 0.06898602743283391,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.045454545454545456,
          "median": 0.045454545454545456,
          "stdev": 0.0642824346533225,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2.0,
          "stdev": 2.8284271247461903,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 34.5,
          "median": 34.5,
          "stdev": 12.020815280171307,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 18.5,
          "median": 18.5,
          "stdev": 26.16295090390226,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 21.5,
          "median": 21.5,
          "stdev": 30.405591591021544,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.39476744186046514,
          "median": 0.39476744186046514,
          "stdev": 0.558285470262402,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.4714045207910317,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_comprehensive_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.016666666666666666,
          "median": 0.016666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.07142857142857142,
          "median": 0.07142857142857142,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.032786885245901634,
          "median": 0.032786885245901634,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 59,
          "median": 59,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.6728813559322034,
          "median": 0.6728813559322034,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06521739130434782,
          "median": 0.06521739130434782,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10714285714285714,
          "median": 0.10714285714285714,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.12244897959183672,
          "median": 0.12244897959183672,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9456521739130435,
          "median": 0.9456521739130435,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9,
          "median": 0.9,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.010869565217391304,
          "median": 0.010869565217391304,
          "stdev": 0.015371886547533641,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.019230769230769232,
          "median": 0.019230769230769232,
          "stdev": 0.02719641466102106,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.023809523809523808,
          "median": 0.023809523809523808,
          "stdev": 0.03367175148507369,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0.030089650263257342,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 12.5,
          "median": 12.5,
          "stdev": 17.67766952966369,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.445,
          "median": 0.445,
          "stdev": 0.6293250352560273,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_minimal_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06060606060606061,
          "median": 0.06060606060606061,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.125,
          "median": 0.125,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.11428571428571428,
          "median": 0.11428571428571428,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 21,
          "median": 21,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8500000000000001,
          "median": 0.8500000000000001,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.010638297872340425,
          "median": 0.010638297872340425,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.020833333333333332,
          "median": 0.020833333333333332,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.021052631578947368,
          "median": 0.021052631578947368,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 80,
          "median": 80,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.03076923076923077,
          "median": 0.03076923076923077,
          "stdev": 0.0435142634576337,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0.060179300526514684,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.09090909090909091,
          "median": 0.09090909090909091,
          "stdev": 0.128564869306645,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.05797101449275362,
          "median": 0.05797101449275362,
          "stdev": 0.08198339492017942,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2.0,
          "stdev": 2.8284271247461903,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 34.5,
          "median": 34.5,
          "stdev": 12.020815280171307,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9.0,
          "stdev": 12.727922061357855,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 21.5,
          "median": 21.5,
          "stdev": 30.405591591021544,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4488372093023256,
          "median": 0.4488372093023256,
          "stdev": 0.6347516686930404,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_structured_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.17857142857142858,
          "median": 0.17857142857142858,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.2631578947368421,
          "median": 0.2631578947368421,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.35714285714285715,
          "median": 0.35714285714285715,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.30303030303030304,
          "median": 0.30303030303030304,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9657894736842106,
          "median": 0.9657894736842106,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.015151515151515152,
          "median": 0.015151515151515152,
          "stdev": 0.021427478217774167,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.019230769230769232,
          "median": 0.019230769230769232,
          "stdev": 0.02719641466102106,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.0625,
          "median": 0.0625,
          "stdev": 0.08838834764831845,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.029411764705882353,
          "median": 0.029411764705882353,
          "stdev": 0.04159451654038515,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 3.5,
          "median": 3.5,
          "stdev": 4.949747468305833,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 6.5,
          "median": 6.5,
          "stdev": 9.192388155425117,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.45576923076923076,
          "median": 0.45576923076923076,
          "stdev": 0.6445550274661991,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.4714045207910317,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_structured_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.07894736842105263,
          "median": 0.07894736842105263,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10714285714285714,
          "median": 0.10714285714285714,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.23076923076923078,
          "median": 0.23076923076923078,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.14634146341463414,
          "median": 0.14634146341463414,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 15,
          "median": 15,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0196078431372549,
          "median": 0.0196078431372549,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.2,
          "median": 0.2,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03846153846153846,
          "median": 0.03846153846153846,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 20,
          "median": 20,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.043478260869565216,
          "median": 0.043478260869565216,
          "stdev": 0.061487546190134565,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.06382978723404255,
          "median": 0.06382978723404255,
          "stdev": 0.09026895078977201,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.10714285714285714,
          "median": 0.10714285714285714,
          "stdev": 0.1515228816828316,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.08,
          "median": 0.08,
          "stdev": 0.1131370849898476,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3.0,
          "stdev": 4.242640687119285,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 33.5,
          "median": 33.5,
          "stdev": 10.606601717798213,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 21,
          "median": 21.0,
          "stdev": 29.698484809834994,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.3922619047619048,
          "median": 0.3922619047619048,
          "stdev": 0.5547421057165891,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_structured_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.10344827586206896,
          "median": 0.10344827586206896,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.15789473684210525,
          "median": 0.15789473684210525,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.23076923076923078,
          "median": 0.23076923076923078,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.18749999999999997,
          "median": 0.18749999999999997,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 16,
          "median": 16,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 21,
          "median": 21,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8547619047619047,
          "median": 0.8547619047619047,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.014285714285714285,
          "median": 0.014285714285714285,
          "stdev": 0.020203050891044214,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.019230769230769232,
          "median": 0.019230769230769232,
          "stdev": 0.02719641466102106,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.05,
          "median": 0.05,
          "stdev": 0.07071067811865475,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.027777777777777776,
          "median": 0.027777777777777776,
          "stdev": 0.039283710065919304,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 4.5,
          "median": 4.5,
          "stdev": 6.363961030678928,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 6.5,
          "median": 6.5,
          "stdev": 9.192388155425117,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.44999999999999996,
          "median": 0.44999999999999996,
          "stdev": 0.6363961030678927,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.4714045207910317,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_optimization_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.043478260869565216,
          "median": 0.043478260869565216,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.07142857142857142,
          "median": 0.07142857142857142,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 26,
          "median": 26,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.865909090909091,
          "median": 0.865909090909091,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017857142857142856,
          "median": 0.017857142857142856,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03508771929824561,
          "median": 0.03508771929824561,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017543859649122806,
          "median": 0.017543859649122806,
          "stdev": 0.02481076425215956,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0.030089650263257342,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0.11785113019775792,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.03389830508474576,
          "median": 0.03389830508474576,
          "stdev": 0.04793944279230831,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 1.4142135623730951,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 13.435028842544403,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 5,
          "median": 5.0,
          "stdev": 7.0710678118654755,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 7,
          "median": 7.0,
          "stdev": 9.899494936611665,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.46785714285714286,
          "median": 0.46785714285714286,
          "stdev": 0.661649916681698,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_improved_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06896551724137931,
          "median": 0.06896551724137931,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.12903225806451615,
          "median": 0.12903225806451615,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9147058823529413,
          "median": 0.9147058823529413,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.014285714285714285,
          "median": 0.014285714285714285,
          "stdev": 0.020203050891044214,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.019230769230769232,
          "median": 0.019230769230769232,
          "stdev": 0.02719641466102106,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.05,
          "median": 0.05,
          "stdev": 0.07071067811865475,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.027777777777777776,
          "median": 0.027777777777777776,
          "stdev": 0.039283710065919304,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 4.5,
          "median": 4.5,
          "stdev": 6.363961030678928,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 6.5,
          "median": 6.5,
          "stdev": 9.192388155425117,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4403846153846154,
          "median": 0.4403846153846154,
          "stdev": 0.6227978957373822,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_improved_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02564102564102564,
          "median": 0.02564102564102564,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.05,
          "median": 0.05,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9249999999999999,
          "median": 0.9249999999999999,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.029850746268656716,
          "median": 0.029850746268656716,
          "stdev": 0.04221533022009239,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0.060179300526514684,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0.11785113019775792,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.056338028169014086,
          "median": 0.056338028169014086,
          "stdev": 0.07967400351397719,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2.0,
          "stdev": 2.8284271247461903,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 34.5,
          "median": 34.5,
          "stdev": 12.020815280171307,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 22,
          "median": 22.0,
          "stdev": 31.11269837220809,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4977272727272727,
          "median": 0.4977272727272727,
          "stdev": 0.7038926594538814,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_improved_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.01818181818181818,
          "median": 0.01818181818181818,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1111111111111111,
          "median": 0.1111111111111111,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 8,
          "median": 8,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 40,
          "median": 40,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8150000000000001,
          "median": 0.8150000000000001,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.12121212121212122,
          "median": 0.12121212121212122,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.21052631578947367,
          "median": 0.21052631578947367,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.2222222222222222,
          "median": 0.2222222222222222,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.21621621621621623,
          "median": 0.21621621621621623,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 15,
          "median": 15,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.04285714285714286,
          "median": 0.04285714285714286,
          "stdev": 0.060609152673132646,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.057692307692307696,
          "median": 0.057692307692307696,
          "stdev": 0.08158924398306318,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.125,
          "median": 0.125,
          "stdev": 0.1767766952966369,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.07894736842105263,
          "median": 0.07894736842105263,
          "stdev": 0.11164843913471803,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1.5,
          "median": 1.5,
          "stdev": 2.1213203435596424,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35,
          "median": 35.0,
          "stdev": 16.97056274847714,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 4.5,
          "median": 4.5,
          "stdev": 6.363961030678928,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 9.5,
          "median": 9.5,
          "stdev": 13.435028842544403,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4947368421052632,
          "median": 0.4947368421052632,
          "stdev": 0.6996635519108997,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_evidence_based_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.17857142857142858,
          "median": 0.17857142857142858,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.18518518518518517,
          "median": 0.18518518518518517,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.18181818181818182,
          "median": 0.18181818181818182,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 32,
          "median": 32,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.011363636363636364,
          "median": 0.011363636363636364,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.023809523809523808,
          "median": 0.023809523809523808,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.022471910112359546,
          "median": 0.022471910112359546,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 41,
          "median": 41,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 102,
          "median": 102,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9705882352941176,
          "median": 0.9705882352941176,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.038098693759071114,
          "median": 0.038098693759071114,
          "stdev": 0.0005131398992645508,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.040507364975450086,
          "median": 0.040507364975450086,
          "stdev": 0.0028932356022362805,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.625,
          "median": 0.625,
          "stdev": 0.5303300858899106,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.0734006734006734,
          "median": 0.0734006734006734,
          "stdev": 0.000952332365234407,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1.5,
          "median": 1.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35,
          "median": 35.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 3,
          "median": 3.0,
          "stdev": 4.242640687119285,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 8.5,
          "median": 8.5,
          "stdev": 10.606601717798213,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0.0,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_evidence_based_concise_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.041666666666666664,
          "median": 0.041666666666666664,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.08,
          "median": 0.08,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 8,
          "median": 8,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02564102564102564,
          "median": 0.02564102564102564,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.05,
          "median": 0.05,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 16,
          "median": 16,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9875,
          "median": 0.9875,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.013157894736842105,
          "median": 0.013157894736842105,
          "stdev": 0.01860807318911967,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.019230769230769232,
          "median": 0.019230769230769232,
          "stdev": 0.02719641466102106,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.038461538461538464,
          "median": 0.038461538461538464,
          "stdev": 0.05439282932204212,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.025641025641025644,
          "median": 0.025641025641025644,
          "stdev": 0.03626188621469475,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 6,
          "median": 6.0,
          "stdev": 8.48528137423857,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 8,
          "median": 8.0,
          "stdev": 11.313708498984761,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.496875,
          "median": 0.496875,
          "stdev": 0.7026873638041317,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.4714045207910317,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_evidence_based_concise_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.009615384615384616,
          "median": 0.009615384615384616,
          "stdev": 0.01359820733051053,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.010638297872340425,
          "median": 0.010638297872340425,
          "stdev": 0.015044825131628671,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0.11785113019775792,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.018867924528301886,
          "median": 0.018867924528301886,
          "stdev": 0.02668327476175651,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 2.5,
          "median": 2.5,
          "stdev": 3.5355339059327378,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 10,
          "median": 10.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4925,
          "median": 0.4925,
          "stdev": 0.6965001794687493,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_evidence_based_concise_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017543859649122806,
          "median": 0.017543859649122806,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.09090909090909091,
          "median": 0.09090909090909091,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.034482758620689655,
          "median": 0.034482758620689655,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 41,
          "median": 41,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.04,
          "median": 0.04,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.07692307692307693,
          "median": 0.07692307692307693,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 6,
          "median": 6,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.990909090909091,
          "median": 0.990909090909091,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.024390243902439025,
          "median": 0.024390243902439025,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.07142857142857142,
          "median": 0.07142857142857142,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.047619047619047616,
          "median": 0.047619047619047616,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 21,
          "median": 21,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02488425925925926,
          "median": 0.02488425925925926,
          "stdev": 0.009002516890106508,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.02986906710310966,
          "median": 0.02986906710310966,
          "stdev": 0.01215158952939239,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.13392857142857142,
          "median": 0.13392857142857142,
          "stdev": 0.012626906806902628,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.04848484848484849,
          "median": 0.04848484848484849,
          "stdev": 0.017141982574219342,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 0.0,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 14.849242404917497,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 6.5,
          "median": 6.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 13.5,
          "median": 13.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.9848901098901099,
          "median": 0.9848901098901099,
          "stdev": 0.01126708607385162,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_evidence_based_with_codes_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017241379310344827,
          "median": 0.017241379310344827,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03389830508474576,
          "median": 0.03389830508474576,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 35,
          "median": 35,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9799999999999999,
          "median": 0.9799999999999999,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      }
    },
    "overall_metrics": {
      "mapping_jaccard_similarity": {
        "mean": 0.03200833598205859,
        "median": 0.015182648401826484,
        "stdev": 0.05545113346909122,
        "min": 0.0,
        "max": 0.352112676056338
      },
      "mapping_precision": {
        "mean": 0.04833287772857441,
        "median": 0.02127659574468085,
        "stdev": 0.08740679096799375,
        "min": 0.0,
        "max": 0.5102040816326531
      },
      "mapping_recall": {
        "mean": 0.09244505236165644,
        "median": 0.042328042328042326,
        "stdev": 0.139425172066122,
        "min": 0,
        "max": 1.0
      },
      "mapping_f1_score": {
        "mean": 0.057261009490746785,
        "median": 0.02990695613646433,
        "stdev": 0.0901414428783911,
        "min": 0,
        "max": 0.5208333333333334
      },
      "mapping_true_positives": {
        "mean": 1.49,
        "median": 1.0,
        "stdev": 3.076450138478674,
        "min": 0,
        "max": 25
      },
      "mapping_false_positives": {
        "mean": 31.67,
        "median": 27.0,
        "stdev": 12.116484305242668,
        "min": 0,
        "max": 47
      },
      "mapping_false_negatives": {
        "mean": 7.66,
        "median": 5.5,
        "stdev": 9.791998382517857,
        "min": 0,
        "max": 47
      },
      "gold_mappings_count": {
        "mean": 14.47,
        "median": 11.5,
        "stdev": 19.174612318786462,
        "min": 0,
        "max": 102
      },
      "comp_mappings_count": {
        "mean": 40.92,
        "median": 34.0,
        "stdev": 15.862209712700718,
        "min": 0,
        "max": 66
      },
      "gold_avg_confidence": {
        "mean": 0.47323710797218915,
        "median": 0.7041679506933745,
        "stdev": 0.46347564741063785,
        "min": 0,
        "max": 1.0
      },
      "comp_avg_confidence": {
        "mean": 0.8813384684926431,
        "median": 0.8770833333333333,
        "stdev": 0.09714976033991386,
        "min": 0,
        "max": 0.9617647058823531
      },
      "gold_compliance_score": {
        "mean": 0.22,
        "median": 0.3333333333333333,
        "stdev": 0.23792971639516422,
        "min": 0.0,
        "max": 1.0
      },
      "comp_compliance_score": {
        "mean": 0.39666666666666667,
        "median": 0.3333333333333333,
        "stdev": 0.13970467488263535,
        "min": 0.0,
        "max": 0.6666666666666666
      }
    }
  }
}