{
  "metadata": {
    "timestamp": "2025-09-18T21:17:29.174475",
    "total_tasks": 100,
    "successful_tasks": 100
  },
  "results": [
    {
      "task_id": "d27538c1-6cfc-4266-a033-403c9ebc87b6",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.046511627906976744,
        "mapping_precision": 0.07692307692307693,
        "mapping_recall": 0.10526315789473684,
        "mapping_f1_score": 0.08888888888888889,
        "mapping_true_positives": 2,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 17,
        "gold_mappings_count": 23,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9021739130434783,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "Procedure=\"387713003\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"108369006\"",
          "ResearchStudy=\"NCT00286117\"",
          "Procedure=\"392247006\""
        ],
        "false_negative_examples": [
          "MedicationStatement=\"387458008\"",
          "ClinicalTrial=\"NCT00286117\"",
          "ClinicalTrial=\"n/a\"",
          "MedicationStatement=\"387517004\"",
          "ResearchStudy=\"R-00319\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 16.51287078857422
    },
    {
      "task_id": "8a290917-016e-45c2-a0f4-ac2b1991bed1",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.28125,
        "mapping_precision": 0.47368421052631576,
        "mapping_recall": 0.4090909090909091,
        "mapping_f1_score": 0.43902439024390244,
        "mapping_true_positives": 9,
        "mapping_false_positives": 10,
        "mapping_false_negatives": 13,
        "gold_mappings_count": 28,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9107142857142857,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:3430\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"LP212175-6\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "CancerDiseaseStatus=\"LA6677-6\"",
          "ResearchSubject=\"LA30165-3\"",
          "MedicationStatement=\"N/A\""
        ],
        "false_negative_examples": [
          "Patient=\"72826-1\"",
          "MedicationStatement=\"L01XC03\"",
          "Observation=\"79385-9\"",
          "MedicationStatement=\"L01XC01\"",
          "ResearchStudy=\"primary\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 30.66706657409668
    },
    {
      "task_id": "7849da33-a8c0-4b61-94d8-8a35d758cc94",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.10526315789473684,
        "mapping_precision": 0.14285714285714285,
        "mapping_recall": 0.2857142857142857,
        "mapping_f1_score": 0.19047619047619047,
        "mapping_true_positives": 4,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 17,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9764705882352942,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "Procedure=\"396487001\"",
          "GenomicVariant=\"HGNC:1100\"",
          "GenomicVariant=\"HGNC:1101\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "Procedure=\"169359004\"",
          "Procedure=\"236269005\"",
          "Observation=\"LP99722-8\""
        ],
        "false_negative_examples": [
          "TumorMarkerTest=\"4464-0\"",
          "CancerCondition=\"93761005\"",
          "CancerDiseaseStatus=\"260385009\"",
          "CancerCondition=\"109838007\"",
          "CancerCondition=\"126906006\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 33.904075622558594
    },
    {
      "task_id": "f0b7c0e6-32b8-4869-8ec0-75d9988597a6",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-chat",
      "metrics": {
        "mapping_jaccard_similarity": 0.352112676056338,
        "mapping_precision": 0.5102040816326531,
        "mapping_recall": 0.5319148936170213,
        "mapping_f1_score": 0.5208333333333334,
        "mapping_true_positives": 25,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 22,
        "gold_mappings_count": 51,
        "comp_mappings_count": 54,
        "gold_avg_confidence": 0.85,
        "comp_avg_confidence": 0.8351851851851853,
        "true_positive_examples": [
          "CancerCondition=\"363346000\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72108-4\"",
          "GenomicVariant=\"LA26611-1\"",
          "Patient=\"BG000\""
        ],
        "false_positive_examples": [
          "Patient=\"BG002\"",
          "Observation=\"LOINC_PLACEHOLDER\"",
          "ResearchStudy=\"single-group\"",
          "Patient=\"2186-5\"",
          "Patient=\"PATIENT_PLACEHOLDER\""
        ],
        "false_negative_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "Observation=\"72111-8\"",
          "Patient=\"305780008\"",
          "ResearchStudy.masking=\"none\"",
          "GenomicVariant=\"LA26612-9\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 35.26568412780762
    },
    {
      "task_id": "3e1950e9-ade9-40e2-b9b8-11175ff4c5a0",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.030303030303030304,
        "mapping_precision": 0.0425531914893617,
        "mapping_recall": 0.09523809523809523,
        "mapping_f1_score": 0.0588235294117647,
        "mapping_true_positives": 2,
        "mapping_false_positives": 45,
        "mapping_false_negatives": 19,
        "gold_mappings_count": 55,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.7354545454545455,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "Procedure=\"387713003\""
        ],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"363346000\"",
          "Observation=\"363346000\"",
          "StudyDesign=\"SINGLE_GROUP\"",
          "Demographic=\"258707000\"",
          "StudyDesign=\"NONE\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 32.19199180603027
    },
    {
      "task_id": "dba81259-c541-478d-9412-ce2c3d2a4028",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_simple_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.15789473684210525,
        "mapping_precision": 0.2553191489361702,
        "mapping_recall": 0.2926829268292683,
        "mapping_f1_score": 0.2727272727272727,
        "mapping_true_positives": 12,
        "mapping_false_positives": 35,
        "mapping_false_negatives": 29,
        "gold_mappings_count": 53,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.8650943396226415,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerDiseaseStatus=\"385633008\"",
          "CancerCondition=\"363346000\"",
          "CancerCondition=\"254837009\"",
          "Patient=\"F\"",
          "ResearchStudy=\"research-study\""
        ],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\"",
          "GenomicVariant=\"LA26611-1\""
        ],
        "false_negative_examples": [
          "Patient=\"103579009\"",
          "TNMStaging=\"LA9622-7\"",
          "GenomicVariant=\"LA26610-2\"",
          "ResearchStudy=\"SUPPORTIVE_CARE\"",
          "CancerGeneticVariant=\"LA28873-6\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.0051326751709
    },
    {
      "task_id": "92f68f20-926f-4c74-aa31-f69dbf0049bc",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_simple_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.11904761904761904,
        "mapping_precision": 0.2631578947368421,
        "mapping_recall": 0.17857142857142858,
        "mapping_f1_score": 0.2127659574468085,
        "mapping_true_positives": 5,
        "mapping_false_positives": 14,
        "mapping_false_negatives": 23,
        "gold_mappings_count": 34,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9352941176470588,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:3430\"",
          "ResearchStudy=\"research-study\"",
          "ResearchStudy=\"NCT00386685\"",
          "CancerCondition=\"C50.911\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "CancerDiseaseStatus=\"LA6677-6\"",
          "ResearchSubject=\"LA30165-3\""
        ],
        "false_negative_examples": [
          "ResearchStudy.design.allocation=\"NON_RANDOMIZED\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"safety\"",
          "ResearchStudy.design.masking=\"NONE\"",
          "ECOGPerformanceStatus=\"LA9622-7\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 9.179115295410156
    },
    {
      "task_id": "8242dcf9-167b-4e37-adab-f3f947474ee9",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_simple_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.10256410256410256,
        "mapping_precision": 0.14285714285714285,
        "mapping_recall": 0.26666666666666666,
        "mapping_f1_score": 0.18604651162790697,
        "mapping_true_positives": 4,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 17,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9617647058823531,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "Procedure=\"396487001\"",
          "GenomicVariant=\"HGNC:1100\"",
          "GenomicVariant=\"HGNC:1101\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "Procedure=\"169359004\"",
          "Procedure=\"236269005\"",
          "Observation=\"LP99722-8\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"254982004\"",
          "TumorMarkerTest=\"4464-0\"",
          "CancerCondition=\"109355002\"",
          "CancerCondition=\"93761005\"",
          "Observation=\"385432009\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 4.716157913208008
    },
    {
      "task_id": "d0519197-4950-410d-a26d-d2d9e9b60919",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_simple_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedMedicationAdministration=\"58848005\"",
          "MedicationStatement=\"387561004\"",
          "Patient=\"F\"",
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 158.88500213623047
    },
    {
      "task_id": "b97bff92-9f27-412e-89e7-36b565c586ec",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "CancerDiseaseStatus=\"LA6677-6\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 193.8800811767578
    },
    {
      "task_id": "0eebc28f-a17d-4727-9560-21076a87725c",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-chat",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0,
        "mapping_recall": 0.0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 0,
        "mapping_false_negatives": 26,
        "gold_mappings_count": 31,
        "comp_mappings_count": 0,
        "gold_avg_confidence": 0.8951612903225806,
        "comp_avg_confidence": 0,
        "true_positive_examples": [],
        "false_positive_examples": [],
        "false_negative_examples": [
          "CancerRelatedMedicationAdministration=\"58848005\"",
          "MedicationStatement=\"387561004\"",
          "Patient=\"F\"",
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.0
      },
      "status": "Success",
      "duration_ms": 195.33109664916992
    },
    {
      "task_id": "a83c66ad-336f-4724-bc0b-190484858570",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "GenomicVariant=\"HGNC:1100\"",
          "Patient=\"F\"",
          "Procedure=\"169359004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 166.19014739990234
    },
    {
      "task_id": "575d435b-20af-492d-b2d2-2f43ccb6867f",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_simple_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"363346000\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 134.39083099365234
    },
    {
      "task_id": "67f5b11f-e670-4ab4-9dae-4d95ba88332a",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"363346000\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 197.5862979888916
    },
    {
      "task_id": "93841395-4c4f-433b-a170-3015fa6ab817",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_simple_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 146.11411094665527
    },
    {
      "task_id": "34c5b7f9-b4dc-4c13-928c-bdacfe63e43f",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 198.7009048461914
    },
    {
      "task_id": "6677dd87-b37a-462d-9ada-407330272f9f",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_simple_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "GenomicVariant=\"HGNC:1100\"",
          "Patient=\"F\"",
          "Procedure=\"169359004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 11.597871780395508
    },
    {
      "task_id": "5cc32062-d747-4938-b036-621a9eec8dff",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_simple_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "CancerDiseaseStatus=\"LA6677-6\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 14.840126037597656
    },
    {
      "task_id": "23ea7bf9-c7a2-47ab-a48d-87e143aaf460",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_comprehensive_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedMedicationAdministration=\"58848005\"",
          "MedicationStatement=\"387561004\"",
          "Patient=\"F\"",
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 14.744997024536133
    },
    {
      "task_id": "cd55cf32-1165-474a-a98b-36e3fdc0a155",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_simple_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.046511627906976744,
        "mapping_precision": 0.07692307692307693,
        "mapping_recall": 0.10526315789473684,
        "mapping_f1_score": 0.08888888888888889,
        "mapping_true_positives": 2,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 17,
        "gold_mappings_count": 23,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.8913043478260869,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "Patient=\"424144002\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"108369006\"",
          "ResearchStudy=\"NCT00286117\"",
          "Procedure=\"392247006\""
        ],
        "false_negative_examples": [
          "Treatment=\"372897005\"",
          "ClinicalTrial=\"NCT00286117\"",
          "CancerDiseaseStatus=\"373150007\"",
          "Treatment=\"373873005\"",
          "StudyPurpose=\"TREATMENT\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.446849822998047
    },
    {
      "task_id": "f76527e0-2387-42af-9a14-ebda1cef4de0",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_comprehensive_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06896551724137931,
        "mapping_precision": 0.10526315789473684,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.12903225806451615,
        "mapping_true_positives": 2,
        "mapping_false_positives": 17,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 17,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9029411764705882,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "CancerDiseaseStatus=\"LA6677-6\""
        ],
        "false_negative_examples": [
          "GenomicVariant=\"LA6576-8\"",
          "CancerRelatedMedication=\"L01XC01\"",
          "CancerRelatedMedication=\"NOC\"",
          "CancerCondition=\"C4872\"",
          "CancerDiseaseStatus=\"LA9621-1\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.530057907104492
    },
    {
      "task_id": "c9a0726a-df6a-4e27-b148-0ad42830c3ed",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_comprehensive_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.6530818939209
    },
    {
      "task_id": "353d212f-a4c0-4933-953f-9410e16956d7",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_simple_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0136986301369863,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.037037037037037035,
        "mapping_f1_score": 0.027027027027027025,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 26,
        "gold_mappings_count": 50,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.358,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"363346000\"",
          "MedicalHistory=\"271681001\"",
          "ObservationResult=\"unknown\"",
          "StudyDesign=\"SINGLE_GROUP\"",
          "ProcedureIndicated=\"363346000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 23.819923400878906
    },
    {
      "task_id": "1ca397d1-e2fe-454d-9148-552203ef772f",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_comprehensive_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03571428571428571,
        "mapping_precision": 0.0425531914893617,
        "mapping_recall": 0.18181818181818182,
        "mapping_f1_score": 0.06896551724137931,
        "mapping_true_positives": 2,
        "mapping_false_positives": 45,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 14,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.9142857142857144,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerDiseaseStatus=\"268910001\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"363346000\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\""
        ],
        "false_negative_examples": [
          "GenomicVariant=\"C1706425\"",
          "GenomicVariant=\"C1706429\"",
          "CancerDiseaseStatus=\"55561003\"",
          "CancerCondition=\"C4872\"",
          "GenomicVariant=\"C1706430\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 23.411989212036133
    },
    {
      "task_id": "9cf2a131-2c29-44c5-870d-1dab0ac050d8",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_comprehensive_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "CancerDiseaseStatus=\"LA6677-6\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 13.55290412902832
    },
    {
      "task_id": "697edfb0-a237-490b-af85-69191360b97f",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_comprehensive_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02702702702702703,
        "mapping_precision": 0.03571428571428571,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.05263157894736841,
        "mapping_true_positives": 1,
        "mapping_false_positives": 27,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 13,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9423076923076923,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "Procedure=\"169359004\"",
          "Procedure=\"236269005\"",
          "GenomicVariant=\"HGNC:1101\""
        ],
        "false_negative_examples": [
          "CancerRelatedProcedure=\"387713003\"",
          "GenomicVariant=\"UO:0001700\"",
          "CancerRelatedProcedure=\"108290001\"",
          "CancerRelatedProcedure=\"396487001\"",
          "CancerRelatedProcedure=\"103693007\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 19.162893295288086
    },
    {
      "task_id": "eada85a7-2323-4a8f-ad0a-c5cdd46ba772",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_comprehensive_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03125,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.14285714285714285,
        "mapping_f1_score": 0.060606060606060615,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 6,
        "gold_mappings_count": 12,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9041666666666667,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"108369006\"",
          "ResearchStudy=\"NCT00286117\"",
          "Procedure=\"392247006\""
        ],
        "false_negative_examples": [
          "CancerRelatedProcedure=\"387713003\"",
          "CancerDiseaseStatus=\"261665006\"",
          "CancerRelatedMedication=\"372897005\"",
          "CancerRelatedMedication=\"387207008\"",
          "CancerRelatedProcedure=\"448385000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.904924392700195
    },
    {
      "task_id": "14264f5f-4136-4263-a257-af51b766d128",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_comprehensive_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.018518518518518517,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.125,
        "mapping_f1_score": 0.03636363636363636,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 7,
        "gold_mappings_count": 9,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.8166666666666667,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"363346000\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\""
        ],
        "false_negative_examples": [
          "GenomicVariant=\"PR\"",
          "CancerCondition=\"C4872\"",
          "CancerDiseaseStatus=\"271299001\"",
          "CancerCondition=\"C34.9\"",
          "TNMClinicalStageGroup=\"C77.4\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 23.00095558166504
    },
    {
      "task_id": "d24cb95c-98db-4cbe-b9db-66f1c8d72982",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_comprehensive_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "GenomicVariant=\"HGNC:1100\"",
          "Patient=\"F\"",
          "Procedure=\"169359004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 15.599250793457031
    },
    {
      "task_id": "8f35b47a-88be-4d04-b5af-f7e97c926247",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_minimal_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedMedicationAdministration=\"58848005\"",
          "MedicationStatement=\"387561004\"",
          "Patient=\"F\"",
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.221357345581055
    },
    {
      "task_id": "b9f6560b-015d-41aa-be52-142800b3d0eb",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_minimal_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.047619047619047616,
        "mapping_precision": 0.0851063829787234,
        "mapping_recall": 0.0975609756097561,
        "mapping_f1_score": 0.09090909090909091,
        "mapping_true_positives": 4,
        "mapping_false_positives": 43,
        "mapping_false_negatives": 37,
        "gold_mappings_count": 43,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.7895348837209303,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"C50.919\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"C50.9\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"363346000\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\"",
          "GenomicVariant=\"LA26611-1\""
        ],
        "false_negative_examples": [
          "Sex=\"76689-9\"",
          "CancerRelatedMedicationRequest=\"LA10426-8\"",
          "CancerRelatedSurgicalProcedure=\"LA10429-2\"",
          "Family member=\"72705000\"",
          "GenomicVariant=\"LA26683-5\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 21.423816680908203
    },
    {
      "task_id": "f8e61feb-21d0-40f2-85f8-85228a1179be",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_comprehensive_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.016666666666666666,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.07142857142857142,
        "mapping_f1_score": 0.032786885245901634,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 13,
        "gold_mappings_count": 59,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.6728813559322034,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [
          "CancerRelatedProcedure=\"387713003\"",
          "CancerCondition=\"363346000\"",
          "ECOGPerformanceStatus=\"NA\"",
          "TNMClinicalStageGroup=\"NA\"",
          "CancerRelatedProcedure=\"NA\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 24.637937545776367
    },
    {
      "task_id": "684ae38d-ebef-46c0-a6c6-0df11dcacffa",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_minimal_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0.0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 1,
        "gold_mappings_count": 1,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.9,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [
          "PrimaryCancerCondition=\"254837009\""
        ],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.76995849609375
    },
    {
      "task_id": "b6f62598-e517-4a74-983a-a308d01d15c5",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_minimal_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06521739130434782,
        "mapping_precision": 0.10714285714285714,
        "mapping_recall": 0.14285714285714285,
        "mapping_f1_score": 0.12244897959183672,
        "mapping_true_positives": 3,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 18,
        "gold_mappings_count": 23,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9456521739130435,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "Procedure=\"396487001\"",
          "Condition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "Procedure=\"169359004\"",
          "Procedure=\"236269005\"",
          "GenomicVariant=\"HGNC:1101\""
        ],
        "false_negative_examples": [
          "Patient=\"365645007\"",
          "Procedure=\"108290001\"",
          "Procedure=\"173170007\"",
          "CancerDiseaseStatus=\"260415000\"",
          "Observation=\"44662000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 17.599105834960938
    },
    {
      "task_id": "cdd70574-924b-4e20-97f9-a5c9d967b5f2",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_minimal_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06060606060606061,
        "mapping_precision": 0.10526315789473684,
        "mapping_recall": 0.125,
        "mapping_f1_score": 0.11428571428571428,
        "mapping_true_positives": 2,
        "mapping_false_positives": 17,
        "mapping_false_negatives": 14,
        "gold_mappings_count": 21,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.8500000000000001,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "CancerDiseaseStatus=\"LA6677-6\""
        ],
        "false_negative_examples": [
          "CancerRelatedSurgicalProcedure=\"LA14042-8\"",
          "GenomicVariant=\"LA6576-8\"",
          "CancerRelatedMedicationAdministration=\"C1234\"",
          "CancerRelatedSurgicalProcedure=\"236627004\"",
          "PrimaryCancerCondition=\"254837009\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 22.721052169799805
    },
    {
      "task_id": "f901f03e-8bbd-4fe4-ac5e-d9b739a83f04",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_minimal_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"363346000\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 21.292686462402344
    },
    {
      "task_id": "246643aa-ba13-4350-80b2-b05e2103dc89",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_minimal_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.021739130434782608,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.047619047619047616,
        "mapping_f1_score": 0.0425531914893617,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 20,
        "gold_mappings_count": 25,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.89,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"108369006\"",
          "ResearchStudy=\"NCT00286117\"",
          "Procedure=\"392247006\""
        ],
        "false_negative_examples": [
          "Intervention Model=\"C70810\"",
          "TreatmentChange=\"16076005\"",
          "Treatment=\"385798007\"",
          "Treatment=\"367336001\"",
          "Age=\"30525-0\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 20.109891891479492
    },
    {
      "task_id": "f3b13928-8376-4257-bb1a-2249ee47f28d",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_minimal_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "CancerDiseaseStatus=\"LA6677-6\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 20.00594139099121
    },
    {
      "task_id": "82919aca-8a5c-4d9a-a122-810bbd14df08",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_minimal_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "GenomicVariant=\"HGNC:1100\"",
          "Patient=\"F\"",
          "Procedure=\"169359004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 14.299869537353516
    },
    {
      "task_id": "5113cc9b-62be-4d0b-acb4-eba0dd100982",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_minimal_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.010638297872340425,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.020833333333333332,
        "mapping_f1_score": 0.021052631578947368,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 47,
        "gold_mappings_count": 80,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "Observation=\"1975-2\""
        ],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [
          "Sex=\"76689-9\"",
          "Node Positive Disease=\"363346000\"",
          "Age at Diagnosis=\"21612-7\"",
          "Dispersion Type=\"NA\"",
          "masking=\"NONE\""
        ],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 22.523880004882812
    },
    {
      "task_id": "5a074c41-cb9d-48bd-bab2-439980efcd6d",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_structured_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06153846153846154,
        "mapping_precision": 0.0851063829787234,
        "mapping_recall": 0.18181818181818182,
        "mapping_f1_score": 0.11594202898550723,
        "mapping_true_positives": 4,
        "mapping_false_positives": 43,
        "mapping_false_negatives": 18,
        "gold_mappings_count": 43,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.8976744186046512,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "CancerDiseaseStatus=\"385633008\"",
          "CancerCondition=\"363346000\"",
          "CancerCondition=\"C50.919\""
        ],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\"",
          "GenomicVariant=\"LA26611-1\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"C80.1\"",
          "GenomicVariant=\"HGNC:3467\"",
          "CancerCondition=\"C79.31\"",
          "CancerRelatedSurgicalProcedure=\"SNOMED_CT_PLACEHOLDER\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 21.22783660888672
    },
    {
      "task_id": "7c36c40a-1ae3-4ca3-91cc-081b5daa27c9",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_structured_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedMedicationAdministration=\"58848005\"",
          "MedicationStatement=\"387561004\"",
          "Patient=\"F\"",
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 16.5860652923584
    },
    {
      "task_id": "eb46a416-ffae-475e-8f9b-f9b971bd59e3",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_structured_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.17857142857142858,
        "mapping_precision": 0.2631578947368421,
        "mapping_recall": 0.35714285714285715,
        "mapping_f1_score": 0.30303030303030304,
        "mapping_true_positives": 5,
        "mapping_false_positives": 14,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 19,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9657894736842106,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:3430\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"C50.911\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "CancerDiseaseStatus=\"LA6677-6\"",
          "ResearchSubject=\"LA30165-3\"",
          "MedicationStatement=\"N/A\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedicationContraindication=\"LA19544-7\"",
          "GenomicVariant=\"LA6576-8\"",
          "GenomicVariant=\"HGNC:6018\"",
          "CancerRelatedMedicationAdministration=\"76314003\"",
          "CancerCondition=\"C50.919\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.548011779785156
    },
    {
      "task_id": "b4f1c23c-f677-4efd-b569-4c2217ab49bf",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_structured_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.377946853637695
    },
    {
      "task_id": "0aad7874-0225-416c-ac41-9ebed7469cc7",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_structured_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.07894736842105263,
        "mapping_precision": 0.10714285714285714,
        "mapping_recall": 0.23076923076923078,
        "mapping_f1_score": 0.14634146341463414,
        "mapping_true_positives": 3,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 15,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:1100\"",
          "GenomicVariant=\"HGNC:1101\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "Procedure=\"169359004\"",
          "Procedure=\"236269005\"",
          "Observation=\"LP99722-8\""
        ],
        "false_negative_examples": [
          "BodySite=\"76752008\"",
          "CancerCondition=\"109355002\"",
          "CancerCondition=\"93761005\"",
          "CancerCondition=\"126906006\"",
          "CancerCondition=\"260385009\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 21.16703987121582
    },
    {
      "task_id": "e56bf689-1446-4005-99cf-cc25c43416a3",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_structured_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"363346000\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.398927688598633
    },
    {
      "task_id": "0141a069-5fda-401f-9bf6-ee639497b233",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_structured_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.030303030303030304,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.125,
        "mapping_f1_score": 0.058823529411764705,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 7,
        "gold_mappings_count": 13,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9115384615384615,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"108369006\"",
          "ResearchStudy=\"NCT00286117\"",
          "Procedure=\"392247006\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"313217004\"",
          "CancerTreatment=\"372857005\"",
          "CancerDiseaseStatus=\"261665006\"",
          "CancerTreatment=\"387207008\"",
          "CancerCondition=\"C0006826\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.07491683959961
    },
    {
      "task_id": "2bafd787-0520-49ed-a393-981ffdac84d0",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_structured_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "CancerDiseaseStatus=\"LA6677-6\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.006065368652344
    },
    {
      "task_id": "5ae873ef-3a2a-46c8-87b1-329e2a8251c4",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_structured_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "GenomicVariant=\"HGNC:1100\"",
          "Patient=\"F\"",
          "Procedure=\"169359004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 16.05820655822754
    },
    {
      "task_id": "22df9f62-cf20-4730-90ff-c97d5b192dd2",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_structured_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0196078431372549,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.2,
        "mapping_f1_score": 0.03846153846153846,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 4,
        "gold_mappings_count": 20,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [
          "ImagingStudy=\"394914008\"",
          "CancerCondition=\"363346000\"",
          "Procedure=\"367336001\"",
          "Device=\"700000000000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 24.71017837524414
    },
    {
      "task_id": "73d16dd1-f841-4307-858f-b5093e63206b",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_optimization_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedMedicationAdministration=\"58848005\"",
          "MedicationStatement=\"387561004\"",
          "Patient=\"F\"",
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.750978469848633
    },
    {
      "task_id": "fc64e4eb-8a29-46da-80ec-405c391ce08b",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_optimization_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.08695652173913043,
        "mapping_precision": 0.1276595744680851,
        "mapping_recall": 0.21428571428571427,
        "mapping_f1_score": 0.16,
        "mapping_true_positives": 6,
        "mapping_false_positives": 41,
        "mapping_false_negatives": 22,
        "gold_mappings_count": 42,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.7845238095238096,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerDiseaseStatus=\"385633008\"",
          "Patient=\"305780008\"",
          "CancerCondition=\"363346000\"",
          "Patient=\"F\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\"",
          "GenomicVariant=\"LA26611-1\""
        ],
        "false_negative_examples": [
          "CancerDiseaseStatus=\"28163009\"",
          "Patient=\"413350009\"",
          "GenomicVariant=\"LA26831-8\"",
          "CancerRelatedSurgicalProcedure=\"78868004\"",
          "CancerRelatedMedicationAdministration=\"373942005\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 23.463010787963867
    },
    {
      "task_id": "689377ae-f72a-47f4-9312-313da12c011a",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_optimization_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.043478260869565216,
        "mapping_precision": 0.07142857142857142,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.08333333333333333,
        "mapping_true_positives": 2,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 18,
        "gold_mappings_count": 22,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.865909090909091,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "Procedure=\"396487001\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "Procedure=\"169359004\"",
          "Procedure=\"236269005\"",
          "GenomicVariant=\"HGNC:1101\""
        ],
        "false_negative_examples": [
          "Observation=\"161891005\"",
          "CancerDiseaseStatus=\"260385009\"",
          "GenomicVariant=\"429357003\"",
          "CancerCondition=\"109838007\"",
          "Observation=\"405746006\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 17.32492446899414
    },
    {
      "task_id": "0629af5a-3efe-4d3a-b07b-113866d36bc3",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_optimization_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.770217895507812
    },
    {
      "task_id": "8f479aff-926a-4c4c-8ef5-83046e811ee2",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_optimization_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"363346000\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.06609535217285
    },
    {
      "task_id": "69d04a0a-c445-4fe1-8602-86d49fe00f2f",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_optimization_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02857142857142857,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.05555555555555555,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 13,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.8999999999999999,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"108369006\"",
          "ResearchStudy=\"NCT00286117\"",
          "Procedure=\"392247006\""
        ],
        "false_negative_examples": [
          "CancerTreatment=\"372876000\"",
          "CancerTreatment=\"373994007\"",
          "ClinicalTrial=\"NCT00000000\"",
          "MedicationStatement=\"386864001\"",
          "CancerCondition=\"161646007\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 16.85619354248047
    },
    {
      "task_id": "38db25da-6f6b-4828-bf4e-00aaecd432ec",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_optimization_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.10344827586206896,
        "mapping_precision": 0.15789473684210525,
        "mapping_recall": 0.23076923076923078,
        "mapping_f1_score": 0.18749999999999997,
        "mapping_true_positives": 3,
        "mapping_false_positives": 16,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 21,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.8547619047619047,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"C50.911\"",
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "CancerDiseaseStatus=\"LA6677-6\""
        ],
        "false_negative_examples": [
          "Patient=\"LA14006-8\"",
          "CancerRelatedMedicationAdministration=\"XRP9881\"",
          "CancerCondition=\"C50.919\"",
          "CancerRelatedMedicationContraindication=\"LA14006-8\"",
          "CancerCondition=\"C1266163\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 23.701906204223633
    },
    {
      "task_id": "34d991d8-9010-4c71-b7c1-8edbcff06106",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_optimization_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "CancerDiseaseStatus=\"LA6677-6\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.007112503051758
    },
    {
      "task_id": "d937d991-ff9b-4b6c-8230-db8341f4dff7",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_optimization_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "GenomicVariant=\"HGNC:1100\"",
          "Patient=\"F\"",
          "Procedure=\"169359004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 15.337944030761719
    },
    {
      "task_id": "a29a2264-15f3-4da8-9a62-88682c63a3f4",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_improved_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedMedicationAdministration=\"58848005\"",
          "MedicationStatement=\"387561004\"",
          "Patient=\"F\"",
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 14.731168746948242
    },
    {
      "task_id": "f91cb5fc-2e0b-4a0b-aab8-04ba1ed5d416",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_optimization_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.017857142857142856,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.03508771929824561,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 14,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [
          "Observation=\"246090004\"",
          "PatientAge=\"424144002\"",
          "Procedure=\"123456789\"",
          "Device=\"123456789\"",
          "Procedure=\"367336001\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 20.055055618286133
    },
    {
      "task_id": "0d2f8108-9862-49f6-9f93-2e933d2bcf4c",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_improved_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03508771929824561,
        "mapping_precision": 0.0425531914893617,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.06779661016949153,
        "mapping_true_positives": 2,
        "mapping_false_positives": 45,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 14,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.9357142857142857,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerDiseaseStatus=\"268910001\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"363346000\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\""
        ],
        "false_negative_examples": [
          "TNMClinicalStageGroup=\"21905-5\"",
          "GenomicVariant=\"C0205726\"",
          "GenomicVariant=\"C3665327\"",
          "CancerDiseaseStatus=\"55561003\"",
          "GenomicVariant=\"C0205729\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 21.663665771484375
    },
    {
      "task_id": "22d289b3-e4b9-4b96-b813-dbcacf0ba14b",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_improved_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06896551724137931,
        "mapping_precision": 0.10526315789473684,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.12903225806451615,
        "mapping_true_positives": 2,
        "mapping_false_positives": 17,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 17,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9147058823529413,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "CancerDiseaseStatus=\"LA6677-6\""
        ],
        "false_negative_examples": [
          "TNMClinicalStageGroup=\"LA26831-3\"",
          "CancerRelatedMedication=\"N/A\"",
          "CancerRelatedProcedure=\"252416005\"",
          "CancerRelatedMedication=\"763140\"",
          "GenomicVariant=\"70650003\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.580841064453125
    },
    {
      "task_id": "a6a5e753-55fa-4301-a731-780a083f013b",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_improved_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02564102564102564,
        "mapping_precision": 0.03571428571428571,
        "mapping_recall": 0.08333333333333333,
        "mapping_f1_score": 0.05,
        "mapping_true_positives": 1,
        "mapping_false_positives": 27,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 14,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9249999999999999,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "Procedure=\"169359004\"",
          "Procedure=\"236269005\"",
          "GenomicVariant=\"HGNC:1101\""
        ],
        "false_negative_examples": [
          "GenomicVariant=\"BRCA2\"",
          "CancerRelatedProcedure=\"387713003\"",
          "CancerRelatedProcedure=\"108290001\"",
          "CancerRelatedMedication=\"unknown\"",
          "CancerRelatedProcedure=\"10374003\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 17.956018447875977
    },
    {
      "task_id": "62111d52-db3b-44ee-bfa7-6fd75652768e",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_improved_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.39590072631836
    },
    {
      "task_id": "4e8b4891-98c8-4dc7-acfc-3ac1d08eabb7",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_improved_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"363346000\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.883228302001953
    },
    {
      "task_id": "b0ccb793-7e1f-4d31-a877-8832620c45b2",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_improved_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02857142857142857,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.05555555555555555,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 13,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.8807692307692307,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"108369006\"",
          "ResearchStudy=\"NCT00286117\"",
          "Procedure=\"392247006\""
        ],
        "false_negative_examples": [
          "CancerRelatedProcedure=\"387713003\"",
          "CancerDiseaseStatus=\"261665006\"",
          "CancerRelatedMedication=\"372897005\"",
          "CancerRelatedMedication=\"387458008\"",
          "CancerRelatedMedication=\"387207008\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.19722557067871
    },
    {
      "task_id": "e20b07fb-9489-49bd-9aa6-0be6a0ba8560",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_improved_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "CancerDiseaseStatus=\"LA6677-6\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.526792526245117
    },
    {
      "task_id": "03fdaa18-6425-4f80-bcc2-f70a694464f3",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_improved_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "GenomicVariant=\"HGNC:1100\"",
          "Patient=\"F\"",
          "Procedure=\"169359004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 14.95814323425293
    },
    {
      "task_id": "d217b35b-45c0-4196-b480-077bd275e257",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_improved_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.01818181818181818,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.1111111111111111,
        "mapping_f1_score": 0.03571428571428571,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 8,
        "gold_mappings_count": 40,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.8150000000000001,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [
          "CancerRelatedProcedure=\"387713003\"",
          "CancerCondition=\"363346000\"",
          "CancerDiseaseStatus=\"55561003\"",
          "CancerRelatedProcedure=\"NA\"",
          "CancerRelatedMedication=\"372098003\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 22.996902465820312
    },
    {
      "task_id": "d69c43f1-a1cc-408b-b435-41888e36643a",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedMedicationAdministration=\"58848005\"",
          "MedicationStatement=\"387561004\"",
          "Patient=\"F\"",
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.00394058227539
    },
    {
      "task_id": "090b4957-effb-452b-b49f-cd9b3abf7c18",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.12121212121212122,
        "mapping_precision": 0.21052631578947367,
        "mapping_recall": 0.2222222222222222,
        "mapping_f1_score": 0.21621621621621623,
        "mapping_true_positives": 4,
        "mapping_false_positives": 15,
        "mapping_false_negatives": 14,
        "gold_mappings_count": 19,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"NCT00386685\"",
          "ResearchStudy=\"research-study\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "CancerDiseaseStatus=\"LA6677-6\"",
          "ResearchSubject=\"LA30165-3\""
        ],
        "false_negative_examples": [
          "ResearchStudy=\"TREATMENT\"",
          "CancerRelatedMedication=\"trastuzumab\"",
          "ResearchStudy=\"SINGLE_GROUP\"",
          "CancerRelatedMedication=\"XRP9881\"",
          "CancerCondition=\"C4872\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 20.505905151367188
    },
    {
      "task_id": "9051f487-d72c-4897-8390-fc221c555b0e",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.05970149253731343,
        "mapping_precision": 0.0851063829787234,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.11267605633802817,
        "mapping_true_positives": 4,
        "mapping_false_positives": 43,
        "mapping_false_negatives": 20,
        "gold_mappings_count": 44,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.9954545454545454,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "Patient=\"F\"",
          "ResearchStudy=\"research-study\"",
          "Observation=\"72826-1\""
        ],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"363346000\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\""
        ],
        "false_negative_examples": [
          "Observation=\"76689-9\"",
          "Observation=\"8302-2\"",
          "Patient=\"LA33-6\"",
          "ResearchStudy=\"LA28874-4\"",
          "ResearchStudy=\"SUPPORTIVE_CARE\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 23.18596839904785
    },
    {
      "task_id": "480afd81-1ffd-409f-aef1-33c3af3e3c23",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 22.526025772094727
    },
    {
      "task_id": "29f726f1-4ebf-426b-896f-340a2bf53f60",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "CancerDiseaseStatus=\"LA6677-6\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 24.259090423583984
    },
    {
      "task_id": "537ee008-8c9b-4b05-ab10-3505948b5e35",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"363346000\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 37.51993179321289
    },
    {
      "task_id": "4296d127-b340-473b-97eb-cc23f29c9902",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.1,
        "mapping_precision": 0.17857142857142858,
        "mapping_recall": 0.18518518518518517,
        "mapping_f1_score": 0.18181818181818182,
        "mapping_true_positives": 5,
        "mapping_false_positives": 23,
        "mapping_false_negatives": 22,
        "gold_mappings_count": 32,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:1100\"",
          "ResearchStudy=\"NCT05417516\"",
          "Procedure=\"396487001\"",
          "Condition=\"254837009\"",
          "GenomicVariant=\"HGNC:1101\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "Procedure=\"169359004\"",
          "Procedure=\"236269005\"",
          "Observation=\"LP99722-8\""
        ],
        "false_negative_examples": [
          "ResearchStudyDesign=\"N/A\"",
          "CancerCondition=\"86049000\"",
          "RadiationProcedure=\"385798007\"",
          "TreatmentIntent=\"373808002\"",
          "Observation=\"252416005\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 39.26205635070801
    },
    {
      "task_id": "b80e5372-263f-4238-aa5d-b3d449ae9a41",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "GenomicVariant=\"HGNC:1100\"",
          "Patient=\"F\"",
          "Procedure=\"169359004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 32.3641300201416
    },
    {
      "task_id": "6b1f56b8-ae90-4184-a66f-af9cea91ca57",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.08571428571428572,
        "mapping_precision": 0.11538461538461539,
        "mapping_recall": 0.25,
        "mapping_f1_score": 0.15789473684210525,
        "mapping_true_positives": 3,
        "mapping_false_positives": 23,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 19,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9894736842105264,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"NCT00286117\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"108369006\"",
          "Procedure=\"392247006\"",
          "CancerDiseaseStatus=\"268910001\""
        ],
        "false_negative_examples": [
          "PatientDemographics=\"post-menopausal\"",
          "CancerRelatedMedication=\"372897005\"",
          "ResearchStudy=\"N/A\"",
          "CancerRelatedMedication=\"387458008\"",
          "PatientDemographics=\"age\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 41.69607162475586
    },
    {
      "task_id": "20099356-9aae-4c3e-89e0-f59332ca0b2a",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_concise_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.038461538461538464,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 1.0,
        "mapping_f1_score": 0.07407407407407407,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 1,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerRelatedMedicationAdministration=\"58848005\"",
          "MedicationStatement=\"387561004\"",
          "Patient=\"F\"",
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 31.916141510009766
    },
    {
      "task_id": "746e7335-dd19-46f9-a6d4-fc0015822983",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.011363636363636364,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.023809523809523808,
        "mapping_f1_score": 0.022471910112359546,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 41,
        "gold_mappings_count": 102,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.9705882352941176,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [
          "GenomicVariant=\"30766002\"",
          "OutcomeMeasureTitle=\"NA\"",
          "Procedure=\"445528004\"",
          "OutcomeMeasureGroupDescription=\"NA\"",
          "ResearchStudyDesign=\"open-label\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 52.03700065612793
    },
    {
      "task_id": "244e8ec2-c066-453a-b05a-5bc9cc57c92b",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_concise_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.041666666666666664,
        "mapping_precision": 0.05263157894736842,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.08,
        "mapping_true_positives": 1,
        "mapping_false_positives": 18,
        "mapping_false_negatives": 5,
        "gold_mappings_count": 8,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "GenomicVariant=\"HGNC:3430\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\""
        ],
        "false_negative_examples": [
          "PatientDemographics=\"424144002\"",
          "CancerCondition=\"702971005\"",
          "CancerTreatment=\"387018007\"",
          "CancerTreatment=\"763875007\"",
          "CancerCondition=\"108369006\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 36.1638069152832
    },
    {
      "task_id": "a6cc465a-ec3d-4a82-be04-dddda49b4835",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_concise_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 32.92202949523926
    },
    {
      "task_id": "97116d56-29b2-48f0-b6ee-fafcd459fcd1",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_concise_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03773584905660377,
        "mapping_precision": 0.0425531914893617,
        "mapping_recall": 0.25,
        "mapping_f1_score": 0.07272727272727272,
        "mapping_true_positives": 2,
        "mapping_false_positives": 45,
        "mapping_false_negatives": 6,
        "gold_mappings_count": 16,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"363346000\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\"",
          "GenomicVariant=\"LA26611-1\""
        ],
        "false_negative_examples": [
          "PatientDemographics=\"424144002\"",
          "PatientDemographics=\"184100006\"",
          "TNMStage=\"399518008\"",
          "PatientDemographics=\"248152002\"",
          "PatientDemographics=\"372148003\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 64.09788131713867
    },
    {
      "task_id": "1b6a498f-5aa9-480d-8bd1-f2775014b244",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "CancerDiseaseStatus=\"LA6677-6\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 30.278921127319336
    },
    {
      "task_id": "2b33705b-a0cb-4f7c-b613-d6e6e59d8bbb",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02631578947368421,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.07692307692307693,
        "mapping_f1_score": 0.05128205128205129,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 12,
        "gold_mappings_count": 16,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.99375,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"108369006\"",
          "ResearchStudy=\"NCT00286117\"",
          "Procedure=\"392247006\""
        ],
        "false_negative_examples": [
          "CancerTreatment=\"372864004\"",
          "CancerTreatment=\"372857005\"",
          "StudyDesign=\"N/A\"",
          "PatientCharacteristic=\"365873007\"",
          "CancerTreatment=\"372756006\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 42.25635528564453
    },
    {
      "task_id": "bb81522b-9aa1-41a0-8c11-8485ca3f43c5",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02564102564102564,
        "mapping_precision": 0.03571428571428571,
        "mapping_recall": 0.08333333333333333,
        "mapping_f1_score": 0.05,
        "mapping_true_positives": 1,
        "mapping_false_positives": 27,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 16,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9875,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "Procedure=\"169359004\"",
          "Procedure=\"236269005\"",
          "GenomicVariant=\"HGNC:1101\""
        ],
        "false_negative_examples": [
          "TNMStage=\"80003\"",
          "CancerTreatment=\"387713003\"",
          "ResearchStudy=\"Not Applicable\"",
          "PatientDemographics=\"397669002\"",
          "ResearchSubject=\"Not Applicable\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 50.98128318786621
    },
    {
      "task_id": "e0cc40af-e76f-49c1-b184-608a3ea9e887",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"363346000\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 50.35591125488281
    },
    {
      "task_id": "860b2fca-d7df-4918-8e64-7aa1e64764a0",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_concise_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "GenomicVariant=\"HGNC:1100\"",
          "Patient=\"F\"",
          "Procedure=\"169359004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 32.028913497924805
    },
    {
      "task_id": "b088dbdd-e1ac-445b-9dcf-7d7561c709db",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_with_codes_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedMedicationAdministration=\"58848005\"",
          "MedicationStatement=\"387561004\"",
          "Patient=\"F\"",
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 28.28192710876465
    },
    {
      "task_id": "fca974e2-3b37-474a-9a2c-c7c329f9c1c5",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_with_codes_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.019230769230769232,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.03773584905660377,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 5,
        "gold_mappings_count": 20,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.985,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"363346000\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\""
        ],
        "false_negative_examples": [
          "PatientDemographics=\"184099003\"",
          "PatientDemographics=\"248152002\"",
          "TNMStage=\"399537006\"",
          "PatientDemographics=\"248153007\"",
          "CancerCondition=\"371494000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 35.906076431274414
    },
    {
      "task_id": "e527bdd7-0e2f-4c06-be1e-aefd2487b896",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.017543859649122806,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.09090909090909091,
        "mapping_f1_score": 0.034482758620689655,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 41,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [
          "Demographics=\"NA\"",
          "CancerCondition=\"363346000\"",
          "StudyDesign=\"OTHER\"",
          "Study=\"NA\"",
          "StudyDesign=\"NONE\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 53.423166275024414
    },
    {
      "task_id": "edec250d-7e1c-4a2c-815f-8e3c0c00e386",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_with_codes_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.04,
        "mapping_precision": 0.05263157894736842,
        "mapping_recall": 0.14285714285714285,
        "mapping_f1_score": 0.07692307692307693,
        "mapping_true_positives": 1,
        "mapping_false_positives": 18,
        "mapping_false_negatives": 6,
        "gold_mappings_count": 11,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.990909090909091,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "GenomicVariant=\"HGNC:3430\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"706891004\"",
          "CancerTreatment=\"367336001\"",
          "CancerTreatment=\"387018007\"",
          "TumorMarker=\"371494000\"",
          "PatientDemographic=\"184099003\""
        ],
        "gold_compliance_score": 1.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 37.08481788635254
    },
    {
      "task_id": "d08dcc82-708b-4fb7-bf33-6abc32aded29",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_with_codes_deepseek-reasoner",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 47,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 35.762786865234375
    },
    {
      "task_id": "0de9be18-bd59-4b17-b105-a3950ad0561f",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.024390243902439025,
        "mapping_precision": 0.03571428571428571,
        "mapping_recall": 0.07142857142857142,
        "mapping_f1_score": 0.047619047619047616,
        "mapping_true_positives": 1,
        "mapping_false_positives": 27,
        "mapping_false_negatives": 13,
        "gold_mappings_count": 21,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "Procedure=\"169359004\"",
          "Procedure=\"236269005\"",
          "GenomicVariant=\"HGNC:1101\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"372130007\"",
          "PatientDemographics=\"248153007\"",
          "CancerCondition=\"109355002\"",
          "TumorMarkers=\"371496003\"",
          "CancerTreatment=\"367336001\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 36.73100471496582
    },
    {
      "task_id": "f0200dba-4004-4f92-aa38-a33185e92dd9",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.018518518518518517,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.125,
        "mapping_f1_score": 0.03636363636363636,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 7,
        "gold_mappings_count": 13,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.9769230769230769,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"363346000\"",
          "GenomicVariant=\"LA26610-3\"",
          "Observation=\"72111-8\"",
          "Observation=\"72108-4\""
        ],
        "false_negative_examples": [
          "PatientDemographics=\"248153007\"",
          "PatientDemographics=\"248152002\"",
          "CancerCondition=\"432468001\"",
          "TNMStage=\"399537006\"",
          "CancerCondition=\"432469009\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 37.77599334716797
    },
    {
      "task_id": "f1560cd3-ebb6-45c8-ab93-a5344408e68a",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_with_codes_claude-3",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 28,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "Observation=\"21894-1\"",
          "GenomicVariant=\"HGNC:1100\"",
          "Patient=\"F\"",
          "Procedure=\"169359004\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 19.700050354003906
    },
    {
      "task_id": "a9626951-52f0-45d3-ae05-ba39ada866da",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03125,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.14285714285714285,
        "mapping_f1_score": 0.060606060606060615,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 6,
        "gold_mappings_count": 14,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9928571428571429,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C4872\"",
          "Observation=\"LP212175-9\"",
          "CancerCondition=\"108369006\"",
          "ResearchStudy=\"NCT00286117\"",
          "Procedure=\"392247006\""
        ],
        "false_negative_examples": [
          "PatientDemographics=\"289908002\"",
          "CancerTreatment=\"386876001\"",
          "CancerCondition=\"432469009\"",
          "CancerTreatment=\"387136007\"",
          "PatientDemographics=\"248153007\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 36.015987396240234
    },
    {
      "task_id": "60729429-efe1-42a7-ad26-bd4068760087",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-4o-mini",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 0,
        "gold_mappings_count": 0,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [],
        "false_positive_examples": [
          "MedicationStatement=\"C94413\"",
          "Observation=\"LP417571-6\"",
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "CancerDiseaseStatus=\"LA6677-6\""
        ],
        "false_negative_examples": [],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 30.49015998840332
    },
    {
      "task_id": "78fbe344-bfcf-430c-9a2b-f28c58bd6261",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.017241379310344827,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.08333333333333333,
        "mapping_f1_score": 0.03389830508474576,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 35,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.9799999999999999,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"777-3\"",
          "CancerRelatedMedicationAdministration=\"C1762400\"",
          "Condition=\"C0006142\"",
          "CancerCondition=\"C4872\"",
          "ResearchStudy=\"NCT02438358\""
        ],
        "false_negative_examples": [
          "PatientDemographics=\"248153007\"",
          "Masking=\"NO\"",
          "CancerTreatment=\"387713003\"",
          "StudyDesign=\"OTHER\"",
          "StudyDesign=\"NA\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 29.947996139526367
    }
  ],
  "analysis": {
    "summary": {
      "total_comparisons": 100,
      "successful_comparisons": 100,
      "success_rate": 1.0,
      "unique_config_pairs": 80
    },
    "configuration_analysis": {
      "direct_mcode_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.023255813953488372,
          "median": 0.023255813953488372,
          "stdev": 0.03288868749704872,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.038461538461538464,
          "median": 0.038461538461538464,
          "stdev": 0.05439282932204212,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0.07443229275647868,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.044444444444444446,
          "median": 0.044444444444444446,
          "stdev": 0.0628539361054709,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 1.4142135623730951,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 16.263455967290593,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 8.5,
          "median": 8.5,
          "stdev": 12.020815280171307,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 11.5,
          "median": 11.5,
          "stdev": 16.263455967290593,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.45108695652173914,
          "median": 0.45108695652173914,
          "stdev": 0.6379332917226461,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.28125,
          "median": 0.28125,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.47368421052631576,
          "median": 0.47368421052631576,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.4090909090909091,
          "median": 0.4090909090909091,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.43902439024390244,
          "median": 0.43902439024390244,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9107142857142857,
          "median": 0.9107142857142857,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.2857142857142857,
          "median": 0.2857142857142857,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.19047619047619047,
          "median": 0.19047619047619047,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9764705882352942,
          "median": 0.9764705882352942,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_deepseek-coder_vs_direct_mcode_deepseek-chat": {
        "mapping_jaccard_similarity": {
          "mean": 0.176056338028169,
          "median": 0.176056338028169,
          "stdev": 0.24898126098117868,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.25510204081632654,
          "median": 0.25510204081632654,
          "stdev": 0.36076876591150386,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.26595744680851063,
          "median": 0.26595744680851063,
          "stdev": 0.37612062829071674,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.2604166666666667,
          "median": 0.2604166666666667,
          "stdev": 0.3682847818679935,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 12.5,
          "median": 12.5,
          "stdev": 17.67766952966369,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 12,
          "median": 12.0,
          "stdev": 16.97056274847714,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 24,
          "median": 24.0,
          "stdev": 2.8284271247461903,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 27,
          "median": 27.0,
          "stdev": 38.18376618407357,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.4175925925925926,
          "median": 0.4175925925925926,
          "stdev": 0.5905651079909869,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        }
      },
      "direct_mcode_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.030303030303030304,
          "median": 0.030303030303030304,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.09523809523809523,
          "median": 0.09523809523809523,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.0588235294117647,
          "median": 0.0588235294117647,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 45,
          "median": 45,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 55,
          "median": 55,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.7354545454545455,
          "median": 0.7354545454545455,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.07894736842105263,
          "median": 0.07894736842105263,
          "stdev": 0.11164843913471803,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.1276595744680851,
          "median": 0.1276595744680851,
          "stdev": 0.18053790157954402,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.14634146341463414,
          "median": 0.14634146341463414,
          "stdev": 0.2069580822985017,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.13636363636363635,
          "median": 0.13636363636363635,
          "stdev": 0.1928473039599675,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 6,
          "median": 6.0,
          "stdev": 8.48528137423857,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 30.5,
          "median": 30.5,
          "stdev": 6.363961030678928,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 14.5,
          "median": 14.5,
          "stdev": 20.506096654409877,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 26.5,
          "median": 26.5,
          "stdev": 37.476659402887016,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.43254716981132074,
          "median": 0.43254716981132074,
          "stdev": 0.6117140739132679,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_simple_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.11904761904761904,
          "median": 0.11904761904761904,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.2631578947368421,
          "median": 0.2631578947368421,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.17857142857142858,
          "median": 0.17857142857142858,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.2127659574468085,
          "median": 0.2127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9352941176470588,
          "median": 0.9352941176470588,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.10256410256410256,
          "median": 0.10256410256410256,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.26666666666666666,
          "median": 0.26666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.18604651162790697,
          "median": 0.18604651162790697,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.023255813953488372,
          "median": 0.023255813953488372,
          "stdev": 0.03288868749704872,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.038461538461538464,
          "median": 0.038461538461538464,
          "stdev": 0.05439282932204212,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0.07443229275647868,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.044444444444444446,
          "median": 0.044444444444444446,
          "stdev": 0.0628539361054709,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 1.4142135623730951,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 16.263455967290593,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 8.5,
          "median": 8.5,
          "stdev": 12.020815280171307,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 11.5,
          "median": 11.5,
          "stdev": 16.263455967290593,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.44565217391304346,
          "median": 0.44565217391304346,
          "stdev": 0.6302473484488793,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_simple_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017857142857142856,
          "median": 0.017857142857142856,
          "stdev": 0.025253813613805267,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0.030089650263257342,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.09090909090909091,
          "median": 0.09090909090909091,
          "stdev": 0.128564869306645,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.034482758620689655,
          "median": 0.034482758620689655,
          "stdev": 0.04876598490941707,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 1.4142135623730951,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 13.435028842544403,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 4.5,
          "median": 4.5,
          "stdev": 6.363961030678928,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 7,
          "median": 7.0,
          "stdev": 9.899494936611665,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4571428571428572,
          "median": 0.4571428571428572,
          "stdev": 0.646497628513415,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_comprehensive_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06896551724137931,
          "median": 0.06896551724137931,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.12903225806451615,
          "median": 0.12903225806451615,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9029411764705882,
          "median": 0.9029411764705882,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0136986301369863,
          "median": 0.0136986301369863,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.037037037037037035,
          "median": 0.037037037037037035,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.027027027027027025,
          "median": 0.027027027027027025,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 26,
          "median": 26,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 50,
          "median": 50,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.358,
          "median": 0.358,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02702702702702703,
          "median": 0.02702702702702703,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.05263157894736841,
          "median": 0.05263157894736841,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9423076923076923,
          "median": 0.9423076923076923,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02488425925925926,
          "median": 0.02488425925925926,
          "stdev": 0.009002516890106508,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.02986906710310966,
          "median": 0.02986906710310966,
          "stdev": 0.01215158952939239,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.13392857142857142,
          "median": 0.13392857142857142,
          "stdev": 0.012626906806902628,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.04848484848484849,
          "median": 0.04848484848484849,
          "stdev": 0.017141982574219342,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 0.0,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 14.849242404917497,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 6.5,
          "median": 6.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 10.5,
          "median": 10.5,
          "stdev": 2.1213203435596424,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.8604166666666666,
          "median": 0.8604166666666666,
          "stdev": 0.061871843353822925,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_comprehensive_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.023809523809523808,
          "median": 0.023809523809523808,
          "stdev": 0.03367175148507369,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0.060179300526514684,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.04878048780487805,
          "median": 0.04878048780487805,
          "stdev": 0.06898602743283391,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.045454545454545456,
          "median": 0.045454545454545456,
          "stdev": 0.0642824346533225,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2.0,
          "stdev": 2.8284271247461903,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 34.5,
          "median": 34.5,
          "stdev": 12.020815280171307,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 18.5,
          "median": 18.5,
          "stdev": 26.16295090390226,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 21.5,
          "median": 21.5,
          "stdev": 30.405591591021544,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.39476744186046514,
          "median": 0.39476744186046514,
          "stdev": 0.558285470262402,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.4714045207910317,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_comprehensive_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.016666666666666666,
          "median": 0.016666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.07142857142857142,
          "median": 0.07142857142857142,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.032786885245901634,
          "median": 0.032786885245901634,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 59,
          "median": 59,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.6728813559322034,
          "median": 0.6728813559322034,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9,
          "median": 0.9,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06521739130434782,
          "median": 0.06521739130434782,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10714285714285714,
          "median": 0.10714285714285714,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.12244897959183672,
          "median": 0.12244897959183672,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9456521739130435,
          "median": 0.9456521739130435,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06060606060606061,
          "median": 0.06060606060606061,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.125,
          "median": 0.125,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.11428571428571428,
          "median": 0.11428571428571428,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 21,
          "median": 21,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8500000000000001,
          "median": 0.8500000000000001,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.010869565217391304,
          "median": 0.010869565217391304,
          "stdev": 0.015371886547533641,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.019230769230769232,
          "median": 0.019230769230769232,
          "stdev": 0.02719641466102106,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.023809523809523808,
          "median": 0.023809523809523808,
          "stdev": 0.03367175148507369,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0.030089650263257342,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 12.5,
          "median": 12.5,
          "stdev": 17.67766952966369,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.445,
          "median": 0.445,
          "stdev": 0.6293250352560273,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_minimal_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.010638297872340425,
          "median": 0.010638297872340425,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.020833333333333332,
          "median": 0.020833333333333332,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.021052631578947368,
          "median": 0.021052631578947368,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 80,
          "median": 80,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.03076923076923077,
          "median": 0.03076923076923077,
          "stdev": 0.0435142634576337,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0.060179300526514684,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.09090909090909091,
          "median": 0.09090909090909091,
          "stdev": 0.128564869306645,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.05797101449275362,
          "median": 0.05797101449275362,
          "stdev": 0.08198339492017942,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2.0,
          "stdev": 2.8284271247461903,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 34.5,
          "median": 34.5,
          "stdev": 12.020815280171307,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9.0,
          "stdev": 12.727922061357855,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 21.5,
          "median": 21.5,
          "stdev": 30.405591591021544,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4488372093023256,
          "median": 0.4488372093023256,
          "stdev": 0.6347516686930404,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_structured_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.17857142857142858,
          "median": 0.17857142857142858,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.2631578947368421,
          "median": 0.2631578947368421,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.35714285714285715,
          "median": 0.35714285714285715,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.30303030303030304,
          "median": 0.30303030303030304,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9657894736842106,
          "median": 0.9657894736842106,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.07894736842105263,
          "median": 0.07894736842105263,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10714285714285714,
          "median": 0.10714285714285714,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.23076923076923078,
          "median": 0.23076923076923078,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.14634146341463414,
          "median": 0.14634146341463414,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 15,
          "median": 15,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.015151515151515152,
          "median": 0.015151515151515152,
          "stdev": 0.021427478217774167,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.019230769230769232,
          "median": 0.019230769230769232,
          "stdev": 0.02719641466102106,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.0625,
          "median": 0.0625,
          "stdev": 0.08838834764831845,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.029411764705882353,
          "median": 0.029411764705882353,
          "stdev": 0.04159451654038515,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 3.5,
          "median": 3.5,
          "stdev": 4.949747468305833,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 6.5,
          "median": 6.5,
          "stdev": 9.192388155425117,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.45576923076923076,
          "median": 0.45576923076923076,
          "stdev": 0.6445550274661991,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.4714045207910317,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_structured_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0196078431372549,
          "median": 0.0196078431372549,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.2,
          "median": 0.2,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03846153846153846,
          "median": 0.03846153846153846,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 20,
          "median": 20,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.043478260869565216,
          "median": 0.043478260869565216,
          "stdev": 0.061487546190134565,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.06382978723404255,
          "median": 0.06382978723404255,
          "stdev": 0.09026895078977201,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.10714285714285714,
          "median": 0.10714285714285714,
          "stdev": 0.1515228816828316,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.08,
          "median": 0.08,
          "stdev": 0.1131370849898476,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3.0,
          "stdev": 4.242640687119285,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 33.5,
          "median": 33.5,
          "stdev": 10.606601717798213,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 21,
          "median": 21.0,
          "stdev": 29.698484809834994,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.3922619047619048,
          "median": 0.3922619047619048,
          "stdev": 0.5547421057165891,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_optimization_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.043478260869565216,
          "median": 0.043478260869565216,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.07142857142857142,
          "median": 0.07142857142857142,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 26,
          "median": 26,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.865909090909091,
          "median": 0.865909090909091,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.014285714285714285,
          "median": 0.014285714285714285,
          "stdev": 0.020203050891044214,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.019230769230769232,
          "median": 0.019230769230769232,
          "stdev": 0.02719641466102106,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.05,
          "median": 0.05,
          "stdev": 0.07071067811865475,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.027777777777777776,
          "median": 0.027777777777777776,
          "stdev": 0.039283710065919304,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 4.5,
          "median": 4.5,
          "stdev": 6.363961030678928,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 6.5,
          "median": 6.5,
          "stdev": 9.192388155425117,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.44999999999999996,
          "median": 0.44999999999999996,
          "stdev": 0.6363961030678927,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.4714045207910317,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_optimization_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.10344827586206896,
          "median": 0.10344827586206896,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.15789473684210525,
          "median": 0.15789473684210525,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.23076923076923078,
          "median": 0.23076923076923078,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.18749999999999997,
          "median": 0.18749999999999997,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 16,
          "median": 16,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 21,
          "median": 21,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8547619047619047,
          "median": 0.8547619047619047,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017543859649122806,
          "median": 0.017543859649122806,
          "stdev": 0.02481076425215956,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0.030089650263257342,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0.11785113019775792,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.03389830508474576,
          "median": 0.03389830508474576,
          "stdev": 0.04793944279230831,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 1.4142135623730951,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 13.435028842544403,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 5,
          "median": 5.0,
          "stdev": 7.0710678118654755,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 7,
          "median": 7.0,
          "stdev": 9.899494936611665,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.46785714285714286,
          "median": 0.46785714285714286,
          "stdev": 0.661649916681698,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_optimization_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017857142857142856,
          "median": 0.017857142857142856,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03508771929824561,
          "median": 0.03508771929824561,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06896551724137931,
          "median": 0.06896551724137931,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.12903225806451615,
          "median": 0.12903225806451615,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9147058823529413,
          "median": 0.9147058823529413,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02564102564102564,
          "median": 0.02564102564102564,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.05,
          "median": 0.05,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9249999999999999,
          "median": 0.9249999999999999,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.014285714285714285,
          "median": 0.014285714285714285,
          "stdev": 0.020203050891044214,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.019230769230769232,
          "median": 0.019230769230769232,
          "stdev": 0.02719641466102106,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.05,
          "median": 0.05,
          "stdev": 0.07071067811865475,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.027777777777777776,
          "median": 0.027777777777777776,
          "stdev": 0.039283710065919304,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 4.5,
          "median": 4.5,
          "stdev": 6.363961030678928,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 6.5,
          "median": 6.5,
          "stdev": 9.192388155425117,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4403846153846154,
          "median": 0.4403846153846154,
          "stdev": 0.6227978957373822,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_improved_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.01818181818181818,
          "median": 0.01818181818181818,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1111111111111111,
          "median": 0.1111111111111111,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 8,
          "median": 8,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 40,
          "median": 40,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8150000000000001,
          "median": 0.8150000000000001,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.029850746268656716,
          "median": 0.029850746268656716,
          "stdev": 0.04221533022009239,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0.060179300526514684,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0.11785113019775792,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.056338028169014086,
          "median": 0.056338028169014086,
          "stdev": 0.07967400351397719,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2.0,
          "stdev": 2.8284271247461903,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 34.5,
          "median": 34.5,
          "stdev": 12.020815280171307,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 22,
          "median": 22.0,
          "stdev": 31.11269837220809,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4977272727272727,
          "median": 0.4977272727272727,
          "stdev": 0.7038926594538814,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_evidence_based_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.12121212121212122,
          "median": 0.12121212121212122,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.21052631578947367,
          "median": 0.21052631578947367,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.2222222222222222,
          "median": 0.2222222222222222,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.21621621621621623,
          "median": 0.21621621621621623,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 15,
          "median": 15,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.04285714285714286,
          "median": 0.04285714285714286,
          "stdev": 0.060609152673132646,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.057692307692307696,
          "median": 0.057692307692307696,
          "stdev": 0.08158924398306318,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.125,
          "median": 0.125,
          "stdev": 0.1767766952966369,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.07894736842105263,
          "median": 0.07894736842105263,
          "stdev": 0.11164843913471803,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1.5,
          "median": 1.5,
          "stdev": 2.1213203435596424,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35,
          "median": 35.0,
          "stdev": 16.97056274847714,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 4.5,
          "median": 4.5,
          "stdev": 6.363961030678928,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 9.5,
          "median": 9.5,
          "stdev": 13.435028842544403,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4947368421052632,
          "median": 0.4947368421052632,
          "stdev": 0.6996635519108997,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_evidence_based_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.17857142857142858,
          "median": 0.17857142857142858,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.18518518518518517,
          "median": 0.18518518518518517,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.18181818181818182,
          "median": 0.18181818181818182,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 32,
          "median": 32,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.038098693759071114,
          "median": 0.038098693759071114,
          "stdev": 0.0005131398992645508,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.040507364975450086,
          "median": 0.040507364975450086,
          "stdev": 0.0028932356022362805,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.625,
          "median": 0.625,
          "stdev": 0.5303300858899106,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.0734006734006734,
          "median": 0.0734006734006734,
          "stdev": 0.000952332365234407,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1.5,
          "median": 1.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35,
          "median": 35.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 3,
          "median": 3.0,
          "stdev": 4.242640687119285,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 8.5,
          "median": 8.5,
          "stdev": 10.606601717798213,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0.0,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_evidence_based_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.011363636363636364,
          "median": 0.011363636363636364,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.023809523809523808,
          "median": 0.023809523809523808,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.022471910112359546,
          "median": 0.022471910112359546,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 41,
          "median": 41,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 102,
          "median": 102,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9705882352941176,
          "median": 0.9705882352941176,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.041666666666666664,
          "median": 0.041666666666666664,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.08,
          "median": 0.08,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 8,
          "median": 8,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.013157894736842105,
          "median": 0.013157894736842105,
          "stdev": 0.01860807318911967,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.019230769230769232,
          "median": 0.019230769230769232,
          "stdev": 0.02719641466102106,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.038461538461538464,
          "median": 0.038461538461538464,
          "stdev": 0.05439282932204212,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.025641025641025644,
          "median": 0.025641025641025644,
          "stdev": 0.03626188621469475,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 15.556349186104045,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 6,
          "median": 6.0,
          "stdev": 8.48528137423857,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 8,
          "median": 8.0,
          "stdev": 11.313708498984761,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.496875,
          "median": 0.496875,
          "stdev": 0.7026873638041317,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.4714045207910317,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_evidence_based_concise_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02564102564102564,
          "median": 0.02564102564102564,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.05,
          "median": 0.05,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 16,
          "median": 16,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9875,
          "median": 0.9875,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.009615384615384616,
          "median": 0.009615384615384616,
          "stdev": 0.01359820733051053,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.010638297872340425,
          "median": 0.010638297872340425,
          "stdev": 0.015044825131628671,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0.11785113019775792,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.018867924528301886,
          "median": 0.018867924528301886,
          "stdev": 0.02668327476175651,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 36,
          "median": 36.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 2.5,
          "median": 2.5,
          "stdev": 3.5355339059327378,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 10,
          "median": 10.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.4925,
          "median": 0.4925,
          "stdev": 0.6965001794687493,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_evidence_based_concise_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017543859649122806,
          "median": 0.017543859649122806,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.09090909090909091,
          "median": 0.09090909090909091,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.034482758620689655,
          "median": 0.034482758620689655,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 41,
          "median": 41,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.04,
          "median": 0.04,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.07692307692307693,
          "median": 0.07692307692307693,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 6,
          "median": 6,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.990909090909091,
          "median": 0.990909090909091,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_deepseek-reasoner_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.024390243902439025,
          "median": 0.024390243902439025,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.07142857142857142,
          "median": 0.07142857142857142,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.047619047619047616,
          "median": 0.047619047619047616,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 21,
          "median": 21,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02488425925925926,
          "median": 0.02488425925925926,
          "stdev": 0.009002516890106508,
          "count": 2
        },
        "mapping_precision": {
          "mean": 0.02986906710310966,
          "median": 0.02986906710310966,
          "stdev": 0.01215158952939239,
          "count": 2
        },
        "mapping_recall": {
          "mean": 0.13392857142857142,
          "median": 0.13392857142857142,
          "stdev": 0.012626906806902628,
          "count": 2
        },
        "mapping_f1_score": {
          "mean": 0.04848484848484849,
          "median": 0.04848484848484849,
          "stdev": 0.017141982574219342,
          "count": 2
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1.0,
          "stdev": 0.0,
          "count": 2
        },
        "mapping_false_positives": {
          "mean": 35.5,
          "median": 35.5,
          "stdev": 14.849242404917497,
          "count": 2
        },
        "mapping_false_negatives": {
          "mean": 6.5,
          "median": 6.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "gold_mappings_count": {
          "mean": 13.5,
          "median": 13.5,
          "stdev": 0.7071067811865476,
          "count": 2
        },
        "comp_mappings_count": {
          "mean": 41,
          "median": 41.0,
          "stdev": 14.142135623730951,
          "count": 2
        },
        "gold_avg_confidence": {
          "mean": 0.9848901098901099,
          "median": 0.9848901098901099,
          "stdev": 0.01126708607385162,
          "count": 2
        },
        "comp_avg_confidence": {
          "mean": 0.8725806451612903,
          "median": 0.8725806451612903,
          "stdev": 0.03193385463423118,
          "count": 2
        },
        "gold_compliance_score": {
          "mean": 0.5,
          "median": 0.5,
          "stdev": 0.23570226039551584,
          "count": 2
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0.0,
          "count": 2
        }
      },
      "direct_mcode_evidence_based_with_codes_claude-3_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-4o-mini_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017241379310344827,
          "median": 0.017241379310344827,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03389830508474576,
          "median": 0.03389830508474576,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 35,
          "median": 35,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9799999999999999,
          "median": 0.9799999999999999,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      }
    },
    "overall_metrics": {
      "mapping_jaccard_similarity": {
        "mean": 0.03200833598205859,
        "median": 0.015182648401826484,
        "stdev": 0.05545113346909122,
        "min": 0.0,
        "max": 0.352112676056338
      },
      "mapping_precision": {
        "mean": 0.04833287772857441,
        "median": 0.02127659574468085,
        "stdev": 0.08740679096799375,
        "min": 0.0,
        "max": 0.5102040816326531
      },
      "mapping_recall": {
        "mean": 0.09244505236165644,
        "median": 0.042328042328042326,
        "stdev": 0.139425172066122,
        "min": 0,
        "max": 1.0
      },
      "mapping_f1_score": {
        "mean": 0.057261009490746785,
        "median": 0.02990695613646433,
        "stdev": 0.0901414428783911,
        "min": 0,
        "max": 0.5208333333333334
      },
      "mapping_true_positives": {
        "mean": 1.49,
        "median": 1.0,
        "stdev": 3.076450138478674,
        "min": 0,
        "max": 25
      },
      "mapping_false_positives": {
        "mean": 31.67,
        "median": 27.0,
        "stdev": 12.116484305242668,
        "min": 0,
        "max": 47
      },
      "mapping_false_negatives": {
        "mean": 7.66,
        "median": 5.5,
        "stdev": 9.791998382517857,
        "min": 0,
        "max": 47
      },
      "gold_mappings_count": {
        "mean": 14.47,
        "median": 11.5,
        "stdev": 19.174612318786462,
        "min": 0,
        "max": 102
      },
      "comp_mappings_count": {
        "mean": 40.92,
        "median": 34.0,
        "stdev": 15.862209712700718,
        "min": 0,
        "max": 66
      },
      "gold_avg_confidence": {
        "mean": 0.47323710797218915,
        "median": 0.7041679506933745,
        "stdev": 0.46347564741063785,
        "min": 0,
        "max": 1.0
      },
      "comp_avg_confidence": {
        "mean": 0.8813384684926431,
        "median": 0.8770833333333333,
        "stdev": 0.09714976033991386,
        "min": 0,
        "max": 0.9617647058823531
      },
      "gold_compliance_score": {
        "mean": 0.22,
        "median": 0.3333333333333333,
        "stdev": 0.23792971639516422,
        "min": 0.0,
        "max": 1.0
      },
      "comp_compliance_score": {
        "mean": 0.39666666666666667,
        "median": 0.3333333333333333,
        "stdev": 0.13970467488263535,
        "min": 0.0,
        "max": 0.6666666666666666
      }
    }
  }
}