{
  "metadata": {
    "timestamp": "2025-09-19T08:18:22.239503",
    "total_tasks": 10,
    "successful_tasks": 10
  },
  "results": [
    {
      "task_id": "486893d0-ea38-4823-b870-6896e36e20f9",
      "trial_id": "NCT01026116",
      "gold_config": "direct_mcode_comprehensive_gpt-4-turbo",
      "comp_config": "direct_mcode_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.125,
        "mapping_precision": 0.21428571428571427,
        "mapping_recall": 0.23076923076923078,
        "mapping_f1_score": 0.22222222222222224,
        "mapping_true_positives": 3,
        "mapping_false_positives": 11,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 14,
        "comp_mappings_count": 14,
        "gold_avg_confidence": 0.9535714285714285,
        "comp_avg_confidence": 0.9857142857142858,
        "true_positive_examples": [
          "GenomicVariant=\"10828004\"",
          "CancerCondition=\"443237005\"",
          "GenomicVariant=\"405538009\""
        ],
        "false_positive_examples": [
          "Procedure=\"387713003\"",
          "GenomicVariant=\"48694002\"",
          "CancerStage=\"258219007\"",
          "ResearchStudy=\"NCT01026116\"",
          "Patient=\"M\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedication=\"Q2019\"",
          "TNMClinicalStageGroup=\"368582007\"",
          "TNMClinicalStageGroup=\"368581000119106\"",
          "CancerRelatedMedication=\"J9264\"",
          "CancerRelatedProcedure=\"23426006\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 38911.667823791504
    },
    {
      "task_id": "26cb6474-619e-486b-9bdc-3c751fc4d1f5",
      "trial_id": "NCT01026116",
      "gold_config": "direct_mcode_minimal_gpt-4-turbo",
      "comp_config": "direct_mcode_improved_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0.0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 13,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 11,
        "comp_mappings_count": 14,
        "gold_avg_confidence": 0.8954545454545454,
        "comp_avg_confidence": 0.9500000000000001,
        "true_positive_examples": [],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"367651003\"",
          "CancerRelatedMedication=\"L0210\"",
          "CancerRelatedMedication=\"J9264\"",
          "CancerRelatedProcedure=\"387713003\"",
          "CancerCondition=\"C50\""
        ],
        "false_negative_examples": [
          "Condition=\"C50.919\"",
          "Observation=\"C50.9\"",
          "Patient=\"M-8010/3\"",
          "CancerCondition=\"254837009\"",
          "Patient=\"C50.9\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 51991.06192588806
    },
    {
      "task_id": "ade030dd-4ddb-4af7-b444-bbcbd4a03d41",
      "trial_id": "NCT00109785",
      "gold_config": "direct_mcode_improved_gpt-4-turbo",
      "comp_config": "direct_mcode_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.05263157894736842,
        "mapping_precision": 0.09090909090909091,
        "mapping_recall": 0.1111111111111111,
        "mapping_f1_score": 0.09999999999999999,
        "mapping_true_positives": 1,
        "mapping_false_positives": 10,
        "mapping_false_negatives": 8,
        "gold_mappings_count": 9,
        "comp_mappings_count": 11,
        "gold_avg_confidence": 0.9277777777777777,
        "comp_avg_confidence": 0.859090909090909,
        "true_positive_examples": [
          "CancerCondition=\"C50\""
        ],
        "false_positive_examples": [
          "Observation=\"LP72251-7\"",
          "MedicationStatement=\"C1883721\"",
          "CancerCondition=\"C50.919\"",
          "Observation=\"LP212175-6\"",
          "MedicationStatement=\"C1546467\""
        ],
        "false_negative_examples": [
          "KarnofskyPerformanceStatus=\"Not available\"",
          "TNMClinicalStageGroup=\"Not available\"",
          "CancerCondition=\"254837009\"",
          "CancerRelatedProcedure=\"P0-0093\"",
          "CancerRelatedProcedure=\"108290001\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 53536.39197349548
    },
    {
      "task_id": "875c457b-37ad-4a45-bbb3-647777cef06a",
      "trial_id": "NCT06650748",
      "gold_config": "direct_mcode_structured_gpt-4-turbo",
      "comp_config": "direct_mcode_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.0967741935483871,
        "mapping_precision": 0.2,
        "mapping_recall": 0.15789473684210525,
        "mapping_f1_score": 0.17647058823529413,
        "mapping_true_positives": 3,
        "mapping_false_positives": 12,
        "mapping_false_negatives": 16,
        "gold_mappings_count": 22,
        "comp_mappings_count": 16,
        "gold_avg_confidence": 0.85,
        "comp_avg_confidence": 0.95,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"128700001\"",
          "GenomicVariant=\"HGNC:3467\""
        ],
        "false_positive_examples": [
          "Procedure=\"P0-00910\"",
          "GenomicVariant=\"Multigene Risk Score\"",
          "Observation=\"LP212175-6\"",
          "Observation=\"C77.9\"",
          "Patient=\"M\""
        ],
        "false_negative_examples": [
          "MedicationStatement=\"N/A\"",
          "CancerRelatedProcedure=\"129317005\"",
          "CancerCondition=\"HER2-\"",
          "Treatment=\"CORALLEEN\"",
          "Treatment=\"PALLET\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 90798.5782623291
    },
    {
      "task_id": "493c863f-1ce9-4976-b2f4-7bfd66051dde",
      "trial_id": "NCT00109785",
      "gold_config": "direct_mcode_evidence_based_gpt-4-turbo",
      "comp_config": "direct_mcode_optimization_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.04878048780487805,
        "mapping_precision": 0.08695652173913043,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.09302325581395349,
        "mapping_true_positives": 2,
        "mapping_false_positives": 21,
        "mapping_false_negatives": 18,
        "gold_mappings_count": 25,
        "comp_mappings_count": 28,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8410714285714286,
        "true_positive_examples": [
          "CancerCondition=\"C50\"",
          "CancerCondition=\"C50.919\""
        ],
        "false_positive_examples": [
          "Medication=\"C1884\"",
          "Observation=\"263495000\"",
          "Medication=\"A9552\"",
          "CancerStageObservation=\"405536007\"",
          "Patient=\"446151000124109\""
        ],
        "false_negative_examples": [
          "ResearchStudy=\"NCT00109785\"",
          "KarnofskyPerformanceStatus=\"Not available\"",
          "TNMClinicalStageGroup=\"Not available\"",
          "Procedure=\"387713003\"",
          "PatientSex=\"Not available\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 100738.64984512329
    },
    {
      "task_id": "b6ba5749-e6fe-4ad4-bf99-4370cdd2c37b",
      "trial_id": "NCT06650748",
      "gold_config": "direct_mcode_optimization_gpt-4-turbo",
      "comp_config": "direct_mcode_improved_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.08333333333333333,
        "mapping_precision": 0.17647058823529413,
        "mapping_recall": 0.13636363636363635,
        "mapping_f1_score": 0.15384615384615383,
        "mapping_true_positives": 3,
        "mapping_false_positives": 14,
        "mapping_false_negatives": 19,
        "gold_mappings_count": 24,
        "comp_mappings_count": 20,
        "gold_avg_confidence": 0.875,
        "comp_avg_confidence": 0.9075,
        "true_positive_examples": [
          "CancerCondition=\"C50\"",
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:6284\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"cT2N1M0\"",
          "CancerRelatedProcedure=\"129317005\"",
          "GenomicVariant=\"Not Available\"",
          "CancerCondition=\"C50.9\"",
          "CancerRelatedMedication=\"LOINC:LP29693-2\""
        ],
        "false_negative_examples": [
          "MedicationStatement=\"N/A\"",
          "MedicationStatement=\"1366043\"",
          "MedicationStatement=\"197604\"",
          "MedicationStatement=\"259255\"",
          "MedicationStatement=\"1366048\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 117051.89514160156
    },
    {
      "task_id": "05244780-9f1f-42cf-bbec-84d735df51fe",
      "trial_id": "NCT01922921",
      "gold_config": "direct_mcode_gpt-4-turbo",
      "comp_config": "direct_mcode_simple_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.4642857142857143,
        "mapping_precision": 0.5652173913043478,
        "mapping_recall": 0.7222222222222222,
        "mapping_f1_score": 0.6341463414634146,
        "mapping_true_positives": 13,
        "mapping_false_positives": 10,
        "mapping_false_negatives": 5,
        "gold_mappings_count": 22,
        "comp_mappings_count": 29,
        "gold_avg_confidence": 0.890909090909091,
        "comp_avg_confidence": 0.9655172413793104,
        "true_positive_examples": [
          "MedicationStatement=\"C1647\"",
          "CancerCondition=\"C50.919\"",
          "GenomicVariant=\"HGNC:3430\"",
          "Observation=\"789-8\"",
          "Observation=\"C131488\""
        ],
        "false_positive_examples": [
          "Observation=\"LP128504-0\"",
          "Procedure=\"385798007\"",
          "Observation=\"LP212175-6\"",
          "Observation=\"C28554\"",
          "MedicationStatement=\"C106261\""
        ],
        "false_negative_examples": [
          "Observation=\"C14155\"",
          "Observation=\"LP21258-6\"",
          "Observation=\"C51948\"",
          "Procedure=\"392021009\"",
          "Observation=\"LA6724-4\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 149690.31405448914
    },
    {
      "task_id": "8287ce78-2518-4ba5-8f67-5ca5e3dc3123",
      "trial_id": "NCT00616135",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-4-turbo",
      "comp_config": "direct_mcode_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.023809523809523808,
        "mapping_precision": 0.041666666666666664,
        "mapping_recall": 0.05263157894736842,
        "mapping_f1_score": 0.04651162790697675,
        "mapping_true_positives": 1,
        "mapping_false_positives": 23,
        "mapping_false_negatives": 18,
        "gold_mappings_count": 22,
        "comp_mappings_count": 26,
        "gold_avg_confidence": 0.9454545454545454,
        "comp_avg_confidence": 0.9346153846153846,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Condition=\"367336001\"",
          "Observation=\"424361007\"",
          "Condition=\"238131007\"",
          "Procedure=\"23426006\"",
          "Observation=\"363812007\""
        ],
        "false_negative_examples": [
          "CancerTreatment=\"387713003\"",
          "PatientCharacteristic=\"263495000\"",
          "CancerTreatment=\"225287009\"",
          "BodyStructure=\"76751001\"",
          "CancerTreatment=\"180030006\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 115171.6091632843
    },
    {
      "task_id": "2f549857-46d3-4f0d-90c5-0432661d5669",
      "trial_id": "NCT00616135",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-4-turbo",
      "comp_config": "direct_mcode_optimization_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.03571428571428571,
        "mapping_precision": 0.043478260869565216,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.06896551724137931,
        "mapping_true_positives": 1,
        "mapping_false_positives": 22,
        "mapping_false_negatives": 5,
        "gold_mappings_count": 10,
        "comp_mappings_count": 27,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Condition=\"64572001\"",
          "CancerCondition=\"408643008\"",
          "Observation=\"385432009\"",
          "Observation=\"423827005\"",
          "Procedure=\"23426006\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"372130007\"",
          "PatientDemographics=\"248153007\"",
          "CancerTreatment=\"108290001\"",
          "PatientDemographics=\"184099003\"",
          "CancerTreatment=\"396487001\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 112742.12098121643
    },
    {
      "task_id": "516f0848-2f52-415d-8e3f-d4eb5905dd9e",
      "trial_id": "NCT01922921",
      "gold_config": "direct_mcode_simple_gpt-4-turbo",
      "comp_config": "direct_mcode_improved_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.023809523809523808,
        "mapping_precision": 0.05,
        "mapping_recall": 0.043478260869565216,
        "mapping_f1_score": 0.046511627906976744,
        "mapping_true_positives": 1,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 22,
        "gold_mappings_count": 29,
        "comp_mappings_count": 27,
        "gold_avg_confidence": 0.9655172413793104,
        "comp_avg_confidence": 0.9407407407407407,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "CancerDiseaseStatus=\"359746009\"",
          "CancerDiseaseStatus=\"260415000\"",
          "CancerCondition=\"8140/3\"",
          "CancerRelatedMedication=\"C1674\"",
          "CancerRelatedMedication=\"715688004\""
        ],
        "false_negative_examples": [
          "MedicationStatement=\"C2037\"",
          "Observation=\"2160-0\"",
          "MedicationStatement=\"C94226\"",
          "Observation=\"C51963\"",
          "Observation=\"1920-8\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 227606.0290336609
    }
  ],
  "analysis": {
    "summary": {
      "total_comparisons": 10,
      "successful_comparisons": 10,
      "success_rate": 1.0,
      "unique_config_pairs": 10
    },
    "configuration_analysis": {
      "direct_mcode_comprehensive_gpt-4-turbo_vs_direct_mcode_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.125,
          "median": 0.125,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.21428571428571427,
          "median": 0.21428571428571427,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.23076923076923078,
          "median": 0.23076923076923078,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.22222222222222224,
          "median": 0.22222222222222224,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9535714285714285,
          "median": 0.9535714285714285,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9857142857142858,
          "median": 0.9857142857142858,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_gpt-4-turbo_vs_direct_mcode_improved_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8954545454545454,
          "median": 0.8954545454545454,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9500000000000001,
          "median": 0.9500000000000001,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_gpt-4-turbo_vs_direct_mcode_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.09090909090909091,
          "median": 0.09090909090909091,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1111111111111111,
          "median": 0.1111111111111111,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.09999999999999999,
          "median": 0.09999999999999999,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 8,
          "median": 8,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9277777777777777,
          "median": 0.9277777777777777,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.859090909090909,
          "median": 0.859090909090909,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_gpt-4-turbo_vs_direct_mcode_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.0967741935483871,
          "median": 0.0967741935483871,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.2,
          "median": 0.2,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.15789473684210525,
          "median": 0.15789473684210525,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.17647058823529413,
          "median": 0.17647058823529413,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 12,
          "median": 12,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 16,
          "median": 16,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 16,
          "median": 16,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.85,
          "median": 0.85,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.95,
          "median": 0.95,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_gpt-4-turbo_vs_direct_mcode_optimization_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.04878048780487805,
          "median": 0.04878048780487805,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.08695652173913043,
          "median": 0.08695652173913043,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.09302325581395349,
          "median": 0.09302325581395349,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 21,
          "median": 21,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8410714285714286,
          "median": 0.8410714285714286,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_gpt-4-turbo_vs_direct_mcode_improved_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.17647058823529413,
          "median": 0.17647058823529413,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.13636363636363635,
          "median": 0.13636363636363635,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.15384615384615383,
          "median": 0.15384615384615383,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 20,
          "median": 20,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.875,
          "median": 0.875,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9075,
          "median": 0.9075,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_gpt-4-turbo_vs_direct_mcode_simple_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.4642857142857143,
          "median": 0.4642857142857143,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.5652173913043478,
          "median": 0.5652173913043478,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.7222222222222222,
          "median": 0.7222222222222222,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.6341463414634146,
          "median": 0.6341463414634146,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 29,
          "median": 29,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.890909090909091,
          "median": 0.890909090909091,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9655172413793104,
          "median": 0.9655172413793104,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_gpt-4-turbo_vs_direct_mcode_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.023809523809523808,
          "median": 0.023809523809523808,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.041666666666666664,
          "median": 0.041666666666666664,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.04651162790697675,
          "median": 0.04651162790697675,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 26,
          "median": 26,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9454545454545454,
          "median": 0.9454545454545454,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9346153846153846,
          "median": 0.9346153846153846,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-4-turbo_vs_direct_mcode_optimization_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.043478260869565216,
          "median": 0.043478260869565216,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.06896551724137931,
          "median": 0.06896551724137931,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.85,
          "median": 0.85,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_gpt-4-turbo_vs_direct_mcode_improved_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.023809523809523808,
          "median": 0.023809523809523808,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.05,
          "median": 0.05,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.043478260869565216,
          "median": 0.043478260869565216,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.046511627906976744,
          "median": 0.046511627906976744,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 29,
          "median": 29,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9655172413793104,
          "median": 0.9655172413793104,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9407407407407407,
          "median": 0.9407407407407407,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      }
    },
    "overall_metrics": {
      "mapping_jaccard_similarity": {
        "mean": 0.09541386412530145,
        "median": 0.050706033376123234,
        "stdev": 0.13499661516048603,
        "min": 0.0,
        "max": 0.4642857142857143
      },
      "mapping_precision": {
        "mean": 0.14689842340098094,
        "median": 0.08893280632411067,
        "stdev": 0.16421254420795336,
        "min": 0.0,
        "max": 0.5652173913043478
      },
      "mapping_recall": {
        "mean": 0.1721137443791906,
        "median": 0.12373737373737373,
        "stdev": 0.20465082848728355,
        "min": 0.0,
        "max": 0.7222222222222222
      },
      "mapping_f1_score": {
        "mean": 0.1541697334636371,
        "median": 0.09651162790697673,
        "stdev": 0.18147175188668585,
        "min": 0,
        "max": 0.6341463414634146
      },
      "mapping_true_positives": {
        "mean": 2.8,
        "median": 1.5,
        "stdev": 3.73571352696584,
        "min": 0,
        "max": 13
      },
      "mapping_false_positives": {
        "mean": 15.5,
        "median": 13.5,
        "stdev": 5.190803834132479,
        "min": 10,
        "max": 23
      },
      "mapping_false_negatives": {
        "mean": 13.2,
        "median": 13.5,
        "stdev": 6.160808027812225,
        "min": 5,
        "max": 22
      },
      "gold_mappings_count": {
        "mean": 18.8,
        "median": 22.0,
        "stdev": 7.130529043797833,
        "min": 9,
        "max": 29
      },
      "comp_mappings_count": {
        "mean": 21.2,
        "median": 23.0,
        "stdev": 6.941021378570864,
        "min": 11,
        "max": 29
      },
      "gold_avg_confidence": {
        "mean": 0.9303684629546698,
        "median": 0.9366161616161616,
        "stdev": 0.05164623023859518,
        "min": 0.85,
        "max": 1.0
      },
      "comp_avg_confidence": {
        "mean": 0.9184249990112059,
        "median": 0.9376780626780626,
        "stdev": 0.05142962274974675,
        "min": 0.8410714285714286,
        "max": 0.9857142857142858
      },
      "gold_compliance_score": {
        "mean": 0.39999999999999997,
        "median": 0.3333333333333333,
        "stdev": 0.14054567378526128,
        "min": 0.3333333333333333,
        "max": 0.6666666666666666
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0.0,
        "min": 0.3333333333333333,
        "max": 0.3333333333333333
      }
    }
  }
}