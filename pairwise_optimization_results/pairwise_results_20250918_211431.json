{
  "metadata": {
    "timestamp": "2025-09-18T21:14:31.829740",
    "total_tasks": 50,
    "successful_tasks": 50
  },
  "results": [
    {
      "task_id": "28e0b2c4-4824-4ae9-bcf9-9b21ce8a01e7",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_simple_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.15789473684210525,
        "mapping_precision": 0.2553191489361702,
        "mapping_recall": 0.2926829268292683,
        "mapping_f1_score": 0.2727272727272727,
        "mapping_true_positives": 12,
        "mapping_false_positives": 35,
        "mapping_false_negatives": 29,
        "gold_mappings_count": 53,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.8650943396226415,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "CancerDiseaseStatus=\"LA9622-7\"",
          "CancerRelatedSurgicalProcedure=\"446508008\"",
          "CancerCondition=\"C91110\"",
          "CancerRelatedSurgicalProcedure=\"LA28873-6\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"LA26831-5\"",
          "Observation=\"54134-2\"",
          "Observation=\"76437-3\"",
          "GenomicVariant=\"LA26611-1\"",
          "GenomicVariant=\"LA26613-7\""
        ],
        "false_negative_examples": [
          "Patient=\"442083009\"",
          "PerformanceStatus=\"LA28873-6\"",
          "CancerRelatedSurgicalProcedure=\"77477000\"",
          "Patient=\"103579009\"",
          "RelatedPerson=\"442991009\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 21.785736083984375
    },
    {
      "task_id": "83f519d7-f854-4048-8e65-79e1b098584f",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.046511627906976744,
        "mapping_precision": 0.07692307692307693,
        "mapping_recall": 0.10526315789473684,
        "mapping_f1_score": 0.08888888888888889,
        "mapping_true_positives": 2,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 17,
        "gold_mappings_count": 23,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9021739130434783,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "Procedure=\"387713003\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "MedicationStatement=\"386876001\"",
          "MedicationStatement=\"387561004\"",
          "MedicationStatement=\"C945\"",
          "CancerCondition=\"108369006\""
        ],
        "false_negative_examples": [
          "ResearchStudy=\"R-00317\"",
          "ResearchStudy=\"R-00321\"",
          "MedicationStatement=\"387458008\"",
          "ResearchStudy=\"R-00319\"",
          "PatientCharacteristic=\"424144002\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 29.993057250976562
    },
    {
      "task_id": "2505fa06-0820-4461-9c8e-8dd51f117433",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_simple_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.10256410256410256,
        "mapping_precision": 0.14285714285714285,
        "mapping_recall": 0.26666666666666666,
        "mapping_f1_score": 0.18604651162790697,
        "mapping_true_positives": 4,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 17,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9617647058823531,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:1101\"",
          "GenomicVariant=\"HGNC:1100\"",
          "CancerCondition=\"254837009\"",
          "Procedure=\"396487001\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "ResearchStudy=\"clinical-trial\"",
          "Procedure=\"33195004\"",
          "CancerCondition=\"92546004\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "CancerResearchStudy=\"N/A\"",
          "Observation=\"21907-1\"",
          "Observation=\"385432009\"",
          "CancerCondition=\"109355002\"",
          "BodyStructure=\"76751001\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 31.362056732177734
    },
    {
      "task_id": "7b2a857e-24a2-4737-8973-aa788d9f1978",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.28125,
        "mapping_precision": 0.47368421052631576,
        "mapping_recall": 0.4090909090909091,
        "mapping_f1_score": 0.43902439024390244,
        "mapping_true_positives": 9,
        "mapping_false_positives": 10,
        "mapping_false_negatives": 13,
        "gold_mappings_count": 28,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9107142857142857,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"NCT00386685\"",
          "ResearchStudy=\"research-study\"",
          "Patient=\"30525-0\"",
          "Observation=\"LP212175-6\""
        ],
        "false_positive_examples": [
          "Observation=\"21908-9\"",
          "CancerCondition=\"C1265770\"",
          "ResearchSubject=\"LA30165-3\"",
          "MedicationStatement=\"763140\"",
          "MedicationStatement=\"C94413\""
        ],
        "false_negative_examples": [
          "MedicationStatement=\"386872004\"",
          "Observation=\"79385-9\"",
          "CancerDiseaseStatus=\"LA9622-7\"",
          "Patient=\"72826-1\"",
          "MedicationStatement=\"L01XC03\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 32.656192779541016
    },
    {
      "task_id": "3e22098b-f5bc-4df4-bca3-44ae0a0b51a7",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.10526315789473684,
        "mapping_precision": 0.14285714285714285,
        "mapping_recall": 0.2857142857142857,
        "mapping_f1_score": 0.19047619047619047,
        "mapping_true_positives": 4,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 17,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9764705882352942,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:1101\"",
          "GenomicVariant=\"HGNC:1100\"",
          "CancerCondition=\"254837009\"",
          "Procedure=\"396487001\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "ResearchStudy=\"clinical-trial\"",
          "Procedure=\"33195004\"",
          "CancerCondition=\"92546004\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "CancerDiseaseStatus=\"260385009\"",
          "CancerCondition=\"260385009\"",
          "CancerCondition=\"126906006\"",
          "Observation=\"21907-1\"",
          "CancerCondition=\"254582000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 34.12508964538574
    },
    {
      "task_id": "a3158131-2cf6-4cc0-9e6b-a4dc59933dfe",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_simple_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.046511627906976744,
        "mapping_precision": 0.07692307692307693,
        "mapping_recall": 0.10526315789473684,
        "mapping_f1_score": 0.08888888888888889,
        "mapping_true_positives": 2,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 17,
        "gold_mappings_count": 23,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.8913043478260869,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "Patient=\"424144002\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "MedicationStatement=\"386876001\"",
          "MedicationStatement=\"387561004\"",
          "MedicationStatement=\"C945\""
        ],
        "false_negative_examples": [
          "StudyDesign=\"RANDOMIZED\"",
          "Treatment=\"373873005\"",
          "CancerCondition=\"399068003\"",
          "StudyPurpose=\"TREATMENT\"",
          "Masking=\"NONE\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 12.965917587280273
    },
    {
      "task_id": "64f66c6c-dc14-4d7a-913b-9999e47a7e82",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_simple_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.11904761904761904,
        "mapping_precision": 0.2631578947368421,
        "mapping_recall": 0.17857142857142858,
        "mapping_f1_score": 0.2127659574468085,
        "mapping_true_positives": 5,
        "mapping_false_positives": 14,
        "mapping_false_negatives": 23,
        "gold_mappings_count": 34,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9352941176470588,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "ResearchStudy=\"research-study\"",
          "GenomicVariant=\"HGNC:3430\"",
          "CancerCondition=\"C50.911\"",
          "ResearchStudy=\"NCT00386685\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763875007\"",
          "Observation=\"21908-9\"",
          "CancerCondition=\"C1265770\"",
          "ResearchSubject=\"LA30165-3\"",
          "MedicationStatement=\"763140\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"C50.9\"",
          "GenomicVariant=\"LA26421-1\"",
          "GenomicVariant=\"LA6576-8\"",
          "CancerDiseaseStatus=\"LA14040-8\"",
          "ResearchStudy.design.interventionModel=\"SINGLE_GROUP\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 34.9428653717041
    },
    {
      "task_id": "9cad325f-f3a0-4106-b853-4903faa570ea",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.030303030303030304,
        "mapping_precision": 0.0425531914893617,
        "mapping_recall": 0.09523809523809523,
        "mapping_f1_score": 0.0588235294117647,
        "mapping_true_positives": 2,
        "mapping_false_positives": 45,
        "mapping_false_negatives": 19,
        "gold_mappings_count": 55,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.7354545454545455,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "Procedure=\"387713003\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "TNMClinicalStageGroup=\"21908-9\"",
          "Condition=\"C0006142\"",
          "Procedure=\"78815000\"",
          "GenomicVariant=\"C0205709\""
        ],
        "false_negative_examples": [
          "StudyDesign=\"NONE\"",
          "ResearchStudy.officialTitle=\"NA\"",
          "Observation=\"unknown\"",
          "StudyDesign=\"OTHER\"",
          "Device=\"unknown\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 37.98389434814453
    },
    {
      "task_id": "1427384f-5279-4a16-9980-1e4ffd017c21",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-chat",
      "metrics": {
        "mapping_jaccard_similarity": 0.352112676056338,
        "mapping_precision": 0.5102040816326531,
        "mapping_recall": 0.5319148936170213,
        "mapping_f1_score": 0.5208333333333334,
        "mapping_true_positives": 25,
        "mapping_false_positives": 24,
        "mapping_false_negatives": 22,
        "gold_mappings_count": 51,
        "comp_mappings_count": 54,
        "gold_avg_confidence": 0.85,
        "comp_avg_confidence": 0.8351851851851853,
        "true_positive_examples": [
          "Observation=\"54134-2\"",
          "Observation=\"72109-2\"",
          "GenomicVariant=\"LA26611-1\"",
          "ECOGPerformanceStatus=\"LA9623-5\"",
          "Patient=\"F\""
        ],
        "false_positive_examples": [
          "Observation=\"72107-6\"",
          "CancerRelatedSurgicalProcedure=\"SNOMED_CT_PLACEHOLDER\"",
          "Comorbidity=\"267432004\"",
          "Observation=\"44255-8\"",
          "Observation=\"77994-7\""
        ],
        "false_negative_examples": [
          "TNMClinicalStageGroup=\"LA26831-5\"",
          "CancerCondition=\"C50.9\"",
          "Observation=\"76437-3\"",
          "GenomicVariant=\"LA26613-7\"",
          "CancerDiseaseStatus=\"385633008\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 39.7639274597168
    },
    {
      "task_id": "34a8200f-ce65-4a25-a62d-534d89ee5d18",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_simple_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0136986301369863,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.037037037037037035,
        "mapping_f1_score": 0.027027027027027025,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 26,
        "gold_mappings_count": 50,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.358,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"21908-9\"",
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "Condition=\"C0006142\"",
          "Procedure=\"78815000\""
        ],
        "false_negative_examples": [
          "MenopausalStatus=\"263347007\"",
          "DeviceUsed=\"unknown\"",
          "MenopausalStatus=\"363406005\"",
          "ObservationResult=\"unknown\"",
          "ResearchStudy.officialTitle=\"NA\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.26984977722168
    },
    {
      "task_id": "79fb39f3-e34b-4558-8bff-e341b4aaeb86",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_comprehensive_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06896551724137931,
        "mapping_precision": 0.10526315789473684,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.12903225806451615,
        "mapping_true_positives": 2,
        "mapping_false_positives": 17,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 17,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9029411764705882,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763875007\"",
          "Observation=\"21908-9\"",
          "CancerCondition=\"C1265770\"",
          "ResearchSubject=\"LA30165-3\"",
          "MedicationStatement=\"763140\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"C4872\"",
          "CancerRelatedMedication=\"76332\"",
          "GenomicVariant=\"LA6576-8\"",
          "CancerRelatedMedication=\"NOC\"",
          "CancerDiseaseStatus=\"LA9621-1\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.790939331054688
    },
    {
      "task_id": "b2f5c378-7437-4529-b8ea-8773622bdb00",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_comprehensive_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02702702702702703,
        "mapping_precision": 0.03571428571428571,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.05263157894736841,
        "mapping_true_positives": 1,
        "mapping_false_positives": 27,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 13,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9423076923076923,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "ResearchStudy=\"clinical-trial\"",
          "Procedure=\"33195004\"",
          "CancerCondition=\"92546004\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "CancerRelatedProcedure=\"129286009\"",
          "CancerRelatedProcedure=\"396487001\"",
          "GenomicVariant=\"UO:0001700\"",
          "CancerRelatedProcedure=\"103693007\"",
          "CancerDiseaseStatus=\"260415000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 14.288902282714844
    },
    {
      "task_id": "a731d00c-3dfa-4c6b-b585-2d471f2362ea",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_comprehensive_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03571428571428571,
        "mapping_precision": 0.0425531914893617,
        "mapping_recall": 0.18181818181818182,
        "mapping_f1_score": 0.06896551724137931,
        "mapping_true_positives": 2,
        "mapping_false_positives": 45,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 14,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.9142857142857144,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerDiseaseStatus=\"268910001\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"LA26831-5\"",
          "CancerCondition=\"C50.9\"",
          "Observation=\"54134-2\"",
          "Observation=\"76437-3\"",
          "GenomicVariant=\"LA26611-1\""
        ],
        "false_negative_examples": [
          "CancerDiseaseStatus=\"55561003\"",
          "TNMClinicalStageGroup=\"21908-9\"",
          "GenomicVariant=\"C1706425\"",
          "GenomicVariant=\"C1706427\"",
          "GenomicVariant=\"C1706430\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.870664596557617
    },
    {
      "task_id": "63958445-82b8-4325-a39d-a8ff64d6022a",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_comprehensive_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03125,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.14285714285714285,
        "mapping_f1_score": 0.060606060606060615,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 6,
        "gold_mappings_count": 12,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9041666666666667,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "MedicationStatement=\"386876001\"",
          "MedicationStatement=\"387561004\"",
          "MedicationStatement=\"C945\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedication=\"372897005\"",
          "CancerRelatedProcedure=\"448385000\"",
          "CancerRelatedMedication=\"367336001\"",
          "CancerRelatedMedication=\"387207008\"",
          "CancerRelatedProcedure=\"387713003\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.393972396850586
    },
    {
      "task_id": "cebe3b19-a2fb-4006-9804-1406e9673afc",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_comprehensive_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.016666666666666666,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.07142857142857142,
        "mapping_f1_score": 0.032786885245901634,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 13,
        "gold_mappings_count": 59,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.6728813559322034,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"21908-9\"",
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "Condition=\"C0006142\"",
          "Procedure=\"78815000\""
        ],
        "false_negative_examples": [
          "KarnofskyPerformanceStatus=\"NA\"",
          "GenomicVariant=\"NA\"",
          "CancerRelatedMedication=\"NA\"",
          "TNMClinicalStageGroup=\"NA\"",
          "CancerDiseaseStatus=\"NA\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.83013343811035
    },
    {
      "task_id": "1f105b17-0378-4a3a-b95a-5e7ba635d7a4",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_minimal_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06060606060606061,
        "mapping_precision": 0.10526315789473684,
        "mapping_recall": 0.125,
        "mapping_f1_score": 0.11428571428571428,
        "mapping_true_positives": 2,
        "mapping_false_positives": 17,
        "mapping_false_negatives": 14,
        "gold_mappings_count": 21,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.8500000000000001,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763875007\"",
          "Observation=\"21908-9\"",
          "CancerCondition=\"C1265770\"",
          "ResearchSubject=\"LA30165-3\"",
          "MedicationStatement=\"763140\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"C50.9\"",
          "PrimaryCancerCondition=\"254837009\"",
          "CancerRelatedMedicationRequest=\"386452007\"",
          "GenomicVariant=\"LA6576-8\"",
          "CancerRelatedMedicationAdministration=\"C1234\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 14.724016189575195
    },
    {
      "task_id": "4831dec2-fd51-420a-a1ba-971e9c7b3130",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_minimal_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.047619047619047616,
        "mapping_precision": 0.0851063829787234,
        "mapping_recall": 0.0975609756097561,
        "mapping_f1_score": 0.09090909090909091,
        "mapping_true_positives": 4,
        "mapping_false_positives": 43,
        "mapping_false_negatives": 37,
        "gold_mappings_count": 43,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.7895348837209303,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "CancerCondition=\"254837009\"",
          "CancerRelatedComorbidities=\"72892002\"",
          "CancerCondition=\"C50.919\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"LA26831-5\"",
          "Observation=\"54134-2\"",
          "Observation=\"76437-3\"",
          "GenomicVariant=\"LA26611-1\"",
          "GenomicVariant=\"LA26613-7\""
        ],
        "false_negative_examples": [
          "TNMClinicalStageGroup=\"21908-9\"",
          "TumorMarker=\"59847-4\"",
          "Comorbidity=\"Z76.82\"",
          "CancerRelatedSurgicalProcedure=\"108290001\"",
          "Standard deviation=\"9279-1\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.779827117919922
    },
    {
      "task_id": "c21294e1-d673-405e-807c-07df88e3ab83",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_minimal_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.021739130434782608,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.047619047619047616,
        "mapping_f1_score": 0.0425531914893617,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 20,
        "gold_mappings_count": 25,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.89,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "MedicationStatement=\"386876001\"",
          "MedicationStatement=\"387561004\"",
          "MedicationStatement=\"C945\""
        ],
        "false_negative_examples": [
          "Intervention Model=\"C70810\"",
          "ClinicalStatus=\"261665006\"",
          "MedicationStatement=\"372897005\"",
          "PatientCharacteristic=\"266919005\"",
          "ClinicalTrial=\"NCT00286117\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 13.541221618652344
    },
    {
      "task_id": "583183bb-cd66-4e63-8ee6-4f15a15003ee",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_minimal_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06521739130434782,
        "mapping_precision": 0.10714285714285714,
        "mapping_recall": 0.14285714285714285,
        "mapping_f1_score": 0.12244897959183672,
        "mapping_true_positives": 3,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 18,
        "gold_mappings_count": 23,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9456521739130435,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "Procedure=\"396487001\"",
          "CancerCondition=\"254837009\"",
          "Condition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "ResearchStudy=\"clinical-trial\"",
          "Procedure=\"33195004\"",
          "CancerCondition=\"92546004\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "Procedure=\"443402002\"",
          "CancerCondition=\"260385009\"",
          "Procedure=\"108290001\"",
          "Observation=\"44662000\"",
          "Observation=\"21907-1\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 14.881134033203125
    },
    {
      "task_id": "b159dbfa-a238-4a37-8300-f88d1ecff92b",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_structured_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.17857142857142858,
        "mapping_precision": 0.2631578947368421,
        "mapping_recall": 0.35714285714285715,
        "mapping_f1_score": 0.30303030303030304,
        "mapping_true_positives": 5,
        "mapping_false_positives": 14,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 19,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9657894736842106,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "MedicationStatement=\"763875007\"",
          "ResearchStudy=\"research-study\"",
          "GenomicVariant=\"HGNC:3430\"",
          "CancerCondition=\"C50.911\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"21908-9\"",
          "CancerCondition=\"C1265770\"",
          "ResearchSubject=\"LA30165-3\"",
          "MedicationStatement=\"763140\"",
          "ResearchStudy=\"NCT00386685\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"C50.9\"",
          "CancerRelatedMedicationAdministration=\"76314003\"",
          "GenomicVariant=\"LA6576-8\"",
          "CancerRelatedMedicationContraindication=\"LA19544-7\"",
          "GenomicVariant=\"HGNC:6018\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 12.122869491577148
    },
    {
      "task_id": "13c87ca2-0d01-4595-a048-3cd176b38e48",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_minimal_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.010638297872340425,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.020833333333333332,
        "mapping_f1_score": 0.021052631578947368,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 47,
        "gold_mappings_count": 80,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "Observation=\"1975-2\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"21908-9\"",
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "Condition=\"C0006142\"",
          "Procedure=\"78815000\""
        ],
        "false_negative_examples": [
          "Outcome Measure Description=\"NA\"",
          "Mammographic Breast Density=\"363680008\"",
          "Observation=\"679-2\"",
          "Outcome Measure Group ID=\"NA\"",
          "Population Description=\"NA\""
        ],
        "gold_compliance_score": 0.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.9290771484375
    },
    {
      "task_id": "5f7b2c16-dcd8-485d-b525-3f98a2e1abbb",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_structured_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.07894736842105263,
        "mapping_precision": 0.10714285714285714,
        "mapping_recall": 0.23076923076923078,
        "mapping_f1_score": 0.14634146341463414,
        "mapping_true_positives": 3,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 15,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:1100\"",
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:1101\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "ResearchStudy=\"clinical-trial\"",
          "Procedure=\"33195004\"",
          "CancerCondition=\"92546004\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"260385009\"",
          "TumorMarkerTest=\"85319-2\"",
          "CancerCondition=\"126906006\"",
          "CancerCondition=\"109355002\"",
          "CancerCondition=\"254848004\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 14.069080352783203
    },
    {
      "task_id": "eb834d69-2bd2-4287-bc24-32ea0a83261f",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_structured_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06153846153846154,
        "mapping_precision": 0.0851063829787234,
        "mapping_recall": 0.18181818181818182,
        "mapping_f1_score": 0.11594202898550723,
        "mapping_true_positives": 4,
        "mapping_false_positives": 43,
        "mapping_false_negatives": 18,
        "gold_mappings_count": 43,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.8976744186046512,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerDiseaseStatus=\"385633008\"",
          "CancerCondition=\"C50.919\"",
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"363346000\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"LA26831-5\"",
          "CancerCondition=\"C50.9\"",
          "Observation=\"54134-2\"",
          "Observation=\"76437-3\"",
          "GenomicVariant=\"LA26611-1\""
        ],
        "false_negative_examples": [
          "CancerDiseaseStatus=\"LA9623-7\"",
          "CancerDiseaseStatus=\"LOINC_PLACEHOLDER\"",
          "CancerRelatedSurgicalProcedure=\"SNOMED_CT_PLACEHOLDER\"",
          "CancerCondition=\"C78.7\"",
          "GenomicVariant=\"HGNC:9446\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.092798233032227
    },
    {
      "task_id": "4783ffdc-793a-4968-874d-85d484eff668",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_structured_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.030303030303030304,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.125,
        "mapping_f1_score": 0.058823529411764705,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 7,
        "gold_mappings_count": 13,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9115384615384615,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "MedicationStatement=\"386876001\"",
          "MedicationStatement=\"387561004\"",
          "MedicationStatement=\"C945\""
        ],
        "false_negative_examples": [
          "CancerTreatment=\"387207008\"",
          "CancerCondition=\"C0006826\"",
          "CancerTreatment=\"372864008\"",
          "CancerTreatment=\"372857005\"",
          "CancerTreatment=\"372856001\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.5029296875
    },
    {
      "task_id": "37505558-f25d-4e19-9f42-68430cb16d4b",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_structured_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.0196078431372549,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.2,
        "mapping_f1_score": 0.03846153846153846,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 4,
        "gold_mappings_count": 20,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "Condition=\"C0006142\"",
          "Procedure=\"78815000\"",
          "TNMClinicalStageGroup=\"21908-9\""
        ],
        "false_negative_examples": [
          "Procedure=\"367336001\"",
          "Device=\"700000000000\"",
          "ImagingStudy=\"394914008\"",
          "CancerCondition=\"363346000\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.958070755004883
    },
    {
      "task_id": "3d86f483-ab88-44be-be63-3480af3d2c49",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_optimization_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.10344827586206896,
        "mapping_precision": 0.15789473684210525,
        "mapping_recall": 0.23076923076923078,
        "mapping_f1_score": 0.18749999999999997,
        "mapping_true_positives": 3,
        "mapping_false_positives": 16,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 21,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.8547619047619047,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:3430\"",
          "CancerCondition=\"C50.911\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763875007\"",
          "Observation=\"21908-9\"",
          "CancerCondition=\"C1265770\"",
          "ResearchSubject=\"LA30165-3\"",
          "MedicationStatement=\"763140\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedicationAdministration=\"76388\"",
          "CancerRelatedMedicationAdministration=\"XRP9881\"",
          "Patient=\"LA14006-8\"",
          "CancerDiseaseStatus=\"LA9622-7\"",
          "CancerDiseaseStatus=\"LA14006-8\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 13.44609260559082
    },
    {
      "task_id": "5d183838-2eec-4333-a1ca-abb5fc5bf8b9",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_optimization_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.043478260869565216,
        "mapping_precision": 0.07142857142857142,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.08333333333333333,
        "mapping_true_positives": 2,
        "mapping_false_positives": 26,
        "mapping_false_negatives": 18,
        "gold_mappings_count": 22,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.865909090909091,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "Procedure=\"396487001\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "ResearchStudy=\"clinical-trial\"",
          "Procedure=\"33195004\"",
          "CancerCondition=\"92546004\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "CancerDiseaseStatus=\"260385009\"",
          "CancerCondition=\"260385009\"",
          "Procedure=\"387713003\"",
          "BodyStructure=\"76752008\"",
          "Observation=\"48694002\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 14.097213745117188
    },
    {
      "task_id": "a9c0a8b7-8683-4846-9608-03d29fcfee1c",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_optimization_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02857142857142857,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.05555555555555555,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 13,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.8999999999999999,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "MedicationStatement=\"386876001\"",
          "MedicationStatement=\"387561004\"",
          "MedicationStatement=\"C945\""
        ],
        "false_negative_examples": [
          "CancerTreatment=\"373994007\"",
          "CancerCondition=\"433581000124108\"",
          "MedicationStatement=\"386864001\"",
          "CancerTreatment=\"372876000\"",
          "CancerCondition=\"373150008\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 12.453794479370117
    },
    {
      "task_id": "90b53b42-398c-4933-bc58-b0f223c8deb6",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_optimization_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.08695652173913043,
        "mapping_precision": 0.1276595744680851,
        "mapping_recall": 0.21428571428571427,
        "mapping_f1_score": 0.16,
        "mapping_true_positives": 6,
        "mapping_false_positives": 41,
        "mapping_false_negatives": 22,
        "gold_mappings_count": 42,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.7845238095238096,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "Patient=\"305780008\"",
          "CancerCondition=\"363346000\"",
          "Patient=\"F\"",
          "CancerDiseaseStatus=\"385633008\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"LA26831-5\"",
          "CancerCondition=\"C50.9\"",
          "Observation=\"54134-2\"",
          "Observation=\"76437-3\"",
          "GenomicVariant=\"LA26611-1\""
        ],
        "false_negative_examples": [
          "Patient=\"442083009\"",
          "CancerDiseaseStatus=\"281647001\"",
          "CancerCondition=\"108369006\"",
          "TNMStaging=\"254292007\"",
          "ECOGPerformanceStatus=\"LA9622-8\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.15826988220215
    },
    {
      "task_id": "e9be80f3-3e00-4abd-9f6b-2aa9eac0afc9",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_improved_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.06896551724137931,
        "mapping_precision": 0.10526315789473684,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.12903225806451615,
        "mapping_true_positives": 2,
        "mapping_false_positives": 17,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 17,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.9147058823529413,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763875007\"",
          "Observation=\"21908-9\"",
          "CancerCondition=\"C1265770\"",
          "ResearchSubject=\"LA30165-3\"",
          "MedicationStatement=\"763140\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"C50.9\"",
          "CancerRelatedMedication=\"372687004\"",
          "CancerDiseaseStatus=\"LA9622-7\"",
          "CancerRelatedProcedure=\"252416005\"",
          "TNMClinicalStageGroup=\"LA26831-3\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 14.397144317626953
    },
    {
      "task_id": "b1020485-37ee-44c3-93ed-1286a47239eb",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_optimization_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.017857142857142856,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.03508771929824561,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 14,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "Condition=\"C0006142\"",
          "Procedure=\"78815000\"",
          "TNMClinicalStageGroup=\"21908-9\""
        ],
        "false_negative_examples": [
          "ECOGPerformanceStatus=\"255428009\"",
          "OutcomeMeasure=\"NA\"",
          "Procedure=\"123456789\"",
          "Observation=\"246090004\"",
          "Observation=\"123456789\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.499923706054688
    },
    {
      "task_id": "9d87f630-5d98-4968-af35-a13a2076564c",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_improved_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03508771929824561,
        "mapping_precision": 0.0425531914893617,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.06779661016949153,
        "mapping_true_positives": 2,
        "mapping_false_positives": 45,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 14,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.9357142857142857,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerDiseaseStatus=\"268910001\"",
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"LA26831-5\"",
          "CancerCondition=\"C50.9\"",
          "Observation=\"54134-2\"",
          "Observation=\"76437-3\"",
          "GenomicVariant=\"LA26611-1\""
        ],
        "false_negative_examples": [
          "CancerDiseaseStatus=\"55561003\"",
          "GenomicVariant=\"C3665328\"",
          "TNMClinicalStageGroup=\"21908-9\"",
          "GenomicVariant=\"C3665327\"",
          "CancerCondition=\"C91150\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 18.182992935180664
    },
    {
      "task_id": "4f85da72-a839-45e2-bd33-37d623068cd6",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_improved_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02564102564102564,
        "mapping_precision": 0.03571428571428571,
        "mapping_recall": 0.08333333333333333,
        "mapping_f1_score": 0.05,
        "mapping_true_positives": 1,
        "mapping_false_positives": 27,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 14,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9249999999999999,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "ResearchStudy=\"clinical-trial\"",
          "Procedure=\"33195004\"",
          "CancerCondition=\"92546004\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "CancerRelatedProcedure=\"129286009\"",
          "CancerRelatedProcedure=\"396487001\"",
          "CancerDiseaseStatus=\"260415000\"",
          "CancerRelatedProcedure=\"180325003\"",
          "GenomicVariant=\"BRCAl\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 15.77305793762207
    },
    {
      "task_id": "256687b6-6765-4432-ad5c-a177d106f859",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_improved_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02857142857142857,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.05555555555555555,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 13,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.8807692307692307,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "MedicationStatement=\"386876001\"",
          "MedicationStatement=\"387561004\"",
          "MedicationStatement=\"C945\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedication=\"372897005\"",
          "CancerRelatedMedication=\"372756006\"",
          "CancerRelatedMedication=\"367336001\"",
          "CancerCondition=\"128462008\"",
          "CancerRelatedProcedure=\"108290001\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 14.002084732055664
    },
    {
      "task_id": "2007a7f6-ec84-4d4d-8402-f02399e3a137",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_improved_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.01818181818181818,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.1111111111111111,
        "mapping_f1_score": 0.03571428571428571,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 8,
        "gold_mappings_count": 40,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.8150000000000001,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "Condition=\"C0006142\"",
          "Procedure=\"78815000\"",
          "TNMClinicalStageGroup=\"21908-9\""
        ],
        "false_negative_examples": [
          "CancerDiseaseStatus=\"55561003\"",
          "GenomicVariant=\"NA\"",
          "CancerCondition=\"363346000\"",
          "CancerRelatedProcedure=\"387713003\"",
          "CancerRelatedMedication=\"372098003\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 16.22295379638672
    },
    {
      "task_id": "dff80d90-5a75-4daa-b712-94a4fc0ddd5a",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.12121212121212122,
        "mapping_precision": 0.21052631578947367,
        "mapping_recall": 0.2222222222222222,
        "mapping_f1_score": 0.21621621621621623,
        "mapping_true_positives": 4,
        "mapping_false_positives": 15,
        "mapping_false_negatives": 14,
        "gold_mappings_count": 19,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "ResearchStudy=\"NCT00386685\"",
          "ResearchStudy=\"research-study\"",
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763875007\"",
          "Observation=\"21908-9\"",
          "CancerCondition=\"C1265770\"",
          "ResearchSubject=\"LA30165-3\"",
          "MedicationStatement=\"763140\""
        ],
        "false_negative_examples": [
          "ResearchStudy=\"NON_RANDOMIZED\"",
          "ResearchStudy=\"LA30174-4\"",
          "ResearchStudy=\"TREATMENT\"",
          "CancerRelatedMedication=\"L01XC03\"",
          "ResearchStudy=\"clinical-trial\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 14.799833297729492
    },
    {
      "task_id": "1c33a701-5b26-465c-9a6d-733e88b2ee78",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.05970149253731343,
        "mapping_precision": 0.0851063829787234,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.11267605633802817,
        "mapping_true_positives": 4,
        "mapping_false_positives": 43,
        "mapping_false_negatives": 20,
        "gold_mappings_count": 44,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.9954545454545454,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "Patient=\"F\"",
          "CancerCondition=\"254837009\"",
          "Observation=\"72826-1\"",
          "ResearchStudy=\"research-study\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"LA26831-5\"",
          "CancerCondition=\"C50.9\"",
          "Observation=\"54134-2\"",
          "Observation=\"76437-3\"",
          "GenomicVariant=\"LA26611-1\""
        ],
        "false_negative_examples": [
          "Observation=\"77993-7\"",
          "ResearchSubject=\"research-subject\"",
          "Patient=\"LA33-6\"",
          "ResearchStudy=\"clinical-research\"",
          "ResearchStudy=\"NCT04092816\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 17.587900161743164
    },
    {
      "task_id": "ba94100d-962b-4c44-a36d-bf0abb805c78",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.1,
        "mapping_precision": 0.17857142857142858,
        "mapping_recall": 0.18518518518518517,
        "mapping_f1_score": 0.18181818181818182,
        "mapping_true_positives": 5,
        "mapping_false_positives": 23,
        "mapping_false_negatives": 22,
        "gold_mappings_count": 32,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "ResearchStudy=\"NCT05417516\"",
          "Condition=\"254837009\"",
          "GenomicVariant=\"HGNC:1100\"",
          "Procedure=\"396487001\"",
          "GenomicVariant=\"HGNC:1101\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "ResearchStudy=\"clinical-trial\"",
          "Procedure=\"33195004\"",
          "CancerCondition=\"92546004\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "ResearchStudy=\"maskingDescription\"",
          "CancerDiseaseStatus=\"260415000\"",
          "RadiationProcedure=\"385798007\"",
          "CancerTreatment=\"108290001\"",
          "ResearchStudy=\"interventionModel\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 15.470743179321289
    },
    {
      "task_id": "0defe133-468c-4e40-94a4-49d17c4b4511",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.08571428571428572,
        "mapping_precision": 0.11538461538461539,
        "mapping_recall": 0.25,
        "mapping_f1_score": 0.15789473684210525,
        "mapping_true_positives": 3,
        "mapping_false_positives": 23,
        "mapping_false_negatives": 9,
        "gold_mappings_count": 19,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9894736842105264,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "CancerCondition=\"254837009\"",
          "ResearchStudy=\"NCT00286117\""
        ],
        "false_positive_examples": [
          "Procedure=\"387713003\"",
          "MedicationStatement=\"386876001\"",
          "MedicationStatement=\"387561004\"",
          "MedicationStatement=\"C945\"",
          "CancerCondition=\"108369006\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedication=\"372897005\"",
          "Biomarker=\"ER\"",
          "CancerRelatedMedication=\"372906003\"",
          "PatientDemographics=\"post-menopausal\"",
          "ResearchStudy=\"N/A\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.829086303710938
    },
    {
      "task_id": "7f46c2ce-6059-4271-84fe-4be3c2e4ed03",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_concise_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03773584905660377,
        "mapping_precision": 0.0425531914893617,
        "mapping_recall": 0.25,
        "mapping_f1_score": 0.07272727272727272,
        "mapping_true_positives": 2,
        "mapping_false_positives": 45,
        "mapping_false_negatives": 6,
        "gold_mappings_count": 16,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "CancerCondition=\"363346000\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"LA26831-5\"",
          "CancerCondition=\"C50.9\"",
          "Observation=\"54134-2\"",
          "Observation=\"76437-3\"",
          "GenomicVariant=\"LA26611-1\""
        ],
        "false_negative_examples": [
          "TNMStage=\"399518008\"",
          "PatientDemographics=\"184100006\"",
          "PatientDemographics=\"424144002\"",
          "PatientDemographics=\"184099003\"",
          "PatientDemographics=\"248152002\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 16.26110076904297
    },
    {
      "task_id": "619c5101-ce46-44f7-b897-da343d0d975e",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_concise_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.041666666666666664,
        "mapping_precision": 0.05263157894736842,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.08,
        "mapping_true_positives": 1,
        "mapping_false_positives": 18,
        "mapping_false_negatives": 5,
        "gold_mappings_count": 8,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763875007\"",
          "Observation=\"21908-9\"",
          "CancerCondition=\"C1265770\"",
          "ResearchSubject=\"LA30165-3\"",
          "MedicationStatement=\"763140\""
        ],
        "false_negative_examples": [
          "PatientDemographics=\"424144002\"",
          "CancerTreatment=\"763875007\"",
          "CancerCondition=\"108369006\"",
          "CancerCondition=\"702971005\"",
          "CancerTreatment=\"387018007\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.47098159790039
    },
    {
      "task_id": "3d3e30b2-a2ac-4887-8464-59185dcdd75e",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.011363636363636364,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.023809523809523808,
        "mapping_f1_score": 0.022471910112359546,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 41,
        "gold_mappings_count": 102,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.9705882352941176,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"21908-9\"",
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "Condition=\"C0006142\"",
          "Procedure=\"78815000\""
        ],
        "false_negative_examples": [
          "LaboratoryTest=\"165889000119104\"",
          "GenomicVariant=\"10828004\"",
          "Procedure=\"445528004\"",
          "Demographic=\"66839005\"",
          "OutcomeMeasure=\"NA\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 19.980907440185547
    },
    {
      "task_id": "29ca5cb5-62db-4536-8208-3c6d47d36d88",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02564102564102564,
        "mapping_precision": 0.03571428571428571,
        "mapping_recall": 0.08333333333333333,
        "mapping_f1_score": 0.05,
        "mapping_true_positives": 1,
        "mapping_false_positives": 27,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 16,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 0.9875,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "ResearchStudy=\"clinical-trial\"",
          "Procedure=\"33195004\"",
          "CancerCondition=\"92546004\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "ResearchStudy=\"Not Applicable\"",
          "CancerTreatment=\"129286009\"",
          "CancerTreatment=\"385798007\"",
          "TNMStage=\"261665006\"",
          "PatientDemographics=\"248152002\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 14.650106430053711
    },
    {
      "task_id": "6e761d70-bf8e-4fe0-9e6a-45f86a124d74",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.02631578947368421,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.07692307692307693,
        "mapping_f1_score": 0.05128205128205129,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 12,
        "gold_mappings_count": 16,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.99375,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "MedicationStatement=\"386876001\"",
          "MedicationStatement=\"387561004\"",
          "MedicationStatement=\"C945\""
        ],
        "false_negative_examples": [
          "PatientCharacteristic=\"424144002\"",
          "Masking=\"N/A\"",
          "CancerTreatment=\"372756006\"",
          "PatientCharacteristic=\"365873007\"",
          "CancerTreatment=\"372857005\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.966176986694336
    },
    {
      "task_id": "1bc44aa4-4a44-40fd-aaf8-07086f35ad9d",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.017543859649122806,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.09090909090909091,
        "mapping_f1_score": 0.034482758620689655,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 41,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"21908-9\"",
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "Condition=\"C0006142\"",
          "Procedure=\"78815000\""
        ],
        "false_negative_examples": [
          "StudyDesign=\"NONE\"",
          "CancerTreatment=\"NA\"",
          "Study=\"NA\"",
          "StudyDesign=\"OTHER\"",
          "StudyDesign=\"NA\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 15.985965728759766
    },
    {
      "task_id": "4d7337d1-2aa6-4901-bd24-409afc347010",
      "trial_id": "NCT00386685",
      "gold_config": "direct_mcode_evidence_based_with_codes_deepseek-chat",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.04,
        "mapping_precision": 0.05263157894736842,
        "mapping_recall": 0.14285714285714285,
        "mapping_f1_score": 0.07692307692307693,
        "mapping_true_positives": 1,
        "mapping_false_positives": 18,
        "mapping_false_negatives": 6,
        "gold_mappings_count": 11,
        "comp_mappings_count": 24,
        "gold_avg_confidence": 0.990909090909091,
        "comp_avg_confidence": 0.8770833333333333,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "MedicationStatement=\"763875007\"",
          "Observation=\"21908-9\"",
          "CancerCondition=\"C1265770\"",
          "ResearchSubject=\"LA30165-3\"",
          "MedicationStatement=\"763140\""
        ],
        "false_negative_examples": [
          "PatientDemographic=\"184099003\"",
          "CancerCondition=\"371494000\"",
          "TumorMarker=\"371494000\"",
          "CancerTreatment=\"367336001\"",
          "CancerCondition=\"706891004\""
        ],
        "gold_compliance_score": 1.0,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 12.570858001708984
    },
    {
      "task_id": "d5fcdb6e-7d40-4a02-bfcb-3e9bbfb3d25f",
      "trial_id": "NCT05417516",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-4-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.024390243902439025,
        "mapping_precision": 0.03571428571428571,
        "mapping_recall": 0.07142857142857142,
        "mapping_f1_score": 0.047619047619047616,
        "mapping_true_positives": 1,
        "mapping_false_positives": 27,
        "mapping_false_negatives": 13,
        "gold_mappings_count": 21,
        "comp_mappings_count": 34,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.9617647058823531,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C1306459\"",
          "ResearchStudy=\"clinical-trial\"",
          "Procedure=\"33195004\"",
          "CancerCondition=\"92546004\"",
          "Patient=\"F\""
        ],
        "false_negative_examples": [
          "CancerTreatment=\"396487001\"",
          "CancerCondition=\"372130007\"",
          "CancerCondition=\"371494000\"",
          "CancerCondition=\"109356001\"",
          "TumorMarkers=\"371495004\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.6666666666666666
      },
      "status": "Success",
      "duration_ms": 11.387109756469727
    },
    {
      "task_id": "c79fa89e-b591-41ce-92b9-a62912d504ea",
      "trial_id": "NCT04092816",
      "gold_config": "direct_mcode_evidence_based_with_codes_deepseek-coder",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.019230769230769232,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.03773584905660377,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 5,
        "gold_mappings_count": 20,
        "comp_mappings_count": 51,
        "gold_avg_confidence": 0.985,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"LA26831-5\"",
          "CancerCondition=\"C50.9\"",
          "Observation=\"54134-2\"",
          "Observation=\"76437-3\"",
          "GenomicVariant=\"LA26611-1\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"371494000\"",
          "PatientDemographics=\"184099003\"",
          "PatientDemographics=\"248152002\"",
          "PatientDemographics=\"248153007\"",
          "TNMStage=\"399537006\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 16.33906364440918
    },
    {
      "task_id": "1bb7f6e2-99a7-4570-912f-25055ae23b73",
      "trial_id": "NCT00286117",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-4o",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.03125,
        "mapping_precision": 0.038461538461538464,
        "mapping_recall": 0.14285714285714285,
        "mapping_f1_score": 0.060606060606060615,
        "mapping_true_positives": 1,
        "mapping_false_positives": 25,
        "mapping_false_negatives": 6,
        "gold_mappings_count": 14,
        "comp_mappings_count": 31,
        "gold_avg_confidence": 0.9928571428571429,
        "comp_avg_confidence": 0.8951612903225806,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "MedicationStatement=\"386876001\"",
          "MedicationStatement=\"387561004\"",
          "MedicationStatement=\"C945\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"432469009\"",
          "CancerTreatment=\"386876001\"",
          "CancerCondition=\"371494000\"",
          "CancerTreatment=\"387136007\"",
          "PatientDemographics=\"248153007\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 11.071920394897461
    },
    {
      "task_id": "1af73f75-02eb-45c3-8f30-f9c535bd223c",
      "trial_id": "NCT02438358",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-3.5-turbo",
      "comp_config": "direct_mcode_deepseek-coder",
      "metrics": {
        "mapping_jaccard_similarity": 0.017241379310344827,
        "mapping_precision": 0.02127659574468085,
        "mapping_recall": 0.08333333333333333,
        "mapping_f1_score": 0.03389830508474576,
        "mapping_true_positives": 1,
        "mapping_false_positives": 46,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 35,
        "comp_mappings_count": 66,
        "gold_avg_confidence": 0.9799999999999999,
        "comp_avg_confidence": 0.8681818181818182,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"21908-9\"",
          "CancerCondition=\"C50.9\"",
          "Procedure=\"387713003\"",
          "Condition=\"C0006142\"",
          "Procedure=\"78815000\""
        ],
        "false_negative_examples": [
          "CancerTreatment=\"396487001\"",
          "StudyDesign=\"OTHER\"",
          "CancerCondition=\"371494000\"",
          "Masking=\"NO\"",
          "StudyDesign=\"NA\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 10.636091232299805
    }
  ],
  "analysis": {
    "summary": {
      "total_comparisons": 50,
      "successful_comparisons": 50,
      "success_rate": 1.0,
      "unique_config_pairs": 50
    },
    "configuration_analysis": {
      "direct_mcode_simple_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.15789473684210525,
          "median": 0.15789473684210525,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.2553191489361702,
          "median": 0.2553191489361702,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.2926829268292683,
          "median": 0.2926829268292683,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.2727272727272727,
          "median": 0.2727272727272727,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 12,
          "median": 12,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 35,
          "median": 35,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 29,
          "median": 29,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 53,
          "median": 53,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 51,
          "median": 51,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8650943396226415,
          "median": 0.8650943396226415,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.85,
          "median": 0.85,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.046511627906976744,
          "median": 0.046511627906976744,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.07692307692307693,
          "median": 0.07692307692307693,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.08888888888888889,
          "median": 0.08888888888888889,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 31,
          "median": 31,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9021739130434783,
          "median": 0.9021739130434783,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8951612903225806,
          "median": 0.8951612903225806,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.10256410256410256,
          "median": 0.10256410256410256,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.26666666666666666,
          "median": 0.26666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.18604651162790697,
          "median": 0.18604651162790697,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.28125,
          "median": 0.28125,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.47368421052631576,
          "median": 0.47368421052631576,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.4090909090909091,
          "median": 0.4090909090909091,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.43902439024390244,
          "median": 0.43902439024390244,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9107142857142857,
          "median": 0.9107142857142857,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.2857142857142857,
          "median": 0.2857142857142857,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.19047619047619047,
          "median": 0.19047619047619047,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9764705882352942,
          "median": 0.9764705882352942,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.046511627906976744,
          "median": 0.046511627906976744,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.07692307692307693,
          "median": 0.07692307692307693,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.08888888888888889,
          "median": 0.08888888888888889,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 31,
          "median": 31,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8913043478260869,
          "median": 0.8913043478260869,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8951612903225806,
          "median": 0.8951612903225806,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.11904761904761904,
          "median": 0.11904761904761904,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.2631578947368421,
          "median": 0.2631578947368421,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.17857142857142858,
          "median": 0.17857142857142858,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.2127659574468085,
          "median": 0.2127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9352941176470588,
          "median": 0.9352941176470588,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.030303030303030304,
          "median": 0.030303030303030304,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.09523809523809523,
          "median": 0.09523809523809523,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.0588235294117647,
          "median": 0.0588235294117647,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 45,
          "median": 45,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 55,
          "median": 55,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.7354545454545455,
          "median": 0.7354545454545455,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_deepseek-coder_vs_direct_mcode_deepseek-chat": {
        "mapping_jaccard_similarity": {
          "mean": 0.352112676056338,
          "median": 0.352112676056338,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.5102040816326531,
          "median": 0.5102040816326531,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.5319148936170213,
          "median": 0.5319148936170213,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.5208333333333334,
          "median": 0.5208333333333334,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 51,
          "median": 51,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 54,
          "median": 54,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.85,
          "median": 0.85,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8351851851851853,
          "median": 0.8351851851851853,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0136986301369863,
          "median": 0.0136986301369863,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.037037037037037035,
          "median": 0.037037037037037035,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.027027027027027025,
          "median": 0.027027027027027025,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 26,
          "median": 26,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 50,
          "median": 50,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.358,
          "median": 0.358,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06896551724137931,
          "median": 0.06896551724137931,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.12903225806451615,
          "median": 0.12903225806451615,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9029411764705882,
          "median": 0.9029411764705882,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02702702702702703,
          "median": 0.02702702702702703,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.05263157894736841,
          "median": 0.05263157894736841,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9423076923076923,
          "median": 0.9423076923076923,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.18181818181818182,
          "median": 0.18181818181818182,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.06896551724137931,
          "median": 0.06896551724137931,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 45,
          "median": 45,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 51,
          "median": 51,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9142857142857144,
          "median": 0.9142857142857144,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.85,
          "median": 0.85,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.03125,
          "median": 0.03125,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.038461538461538464,
          "median": 0.038461538461538464,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.060606060606060615,
          "median": 0.060606060606060615,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 6,
          "median": 6,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 12,
          "median": 12,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 31,
          "median": 31,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9041666666666667,
          "median": 0.9041666666666667,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8951612903225806,
          "median": 0.8951612903225806,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.016666666666666666,
          "median": 0.016666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.07142857142857142,
          "median": 0.07142857142857142,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.032786885245901634,
          "median": 0.032786885245901634,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 59,
          "median": 59,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.6728813559322034,
          "median": 0.6728813559322034,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06060606060606061,
          "median": 0.06060606060606061,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.125,
          "median": 0.125,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.11428571428571428,
          "median": 0.11428571428571428,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 21,
          "median": 21,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8500000000000001,
          "median": 0.8500000000000001,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.047619047619047616,
          "median": 0.047619047619047616,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0851063829787234,
          "median": 0.0851063829787234,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.0975609756097561,
          "median": 0.0975609756097561,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.09090909090909091,
          "median": 0.09090909090909091,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 43,
          "median": 43,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 37,
          "median": 37,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 43,
          "median": 43,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 51,
          "median": 51,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.7895348837209303,
          "median": 0.7895348837209303,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.85,
          "median": 0.85,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.021739130434782608,
          "median": 0.021739130434782608,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.038461538461538464,
          "median": 0.038461538461538464,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.047619047619047616,
          "median": 0.047619047619047616,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 20,
          "median": 20,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 31,
          "median": 31,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.89,
          "median": 0.89,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8951612903225806,
          "median": 0.8951612903225806,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06521739130434782,
          "median": 0.06521739130434782,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10714285714285714,
          "median": 0.10714285714285714,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.12244897959183672,
          "median": 0.12244897959183672,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9456521739130435,
          "median": 0.9456521739130435,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.17857142857142858,
          "median": 0.17857142857142858,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.2631578947368421,
          "median": 0.2631578947368421,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.35714285714285715,
          "median": 0.35714285714285715,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.30303030303030304,
          "median": 0.30303030303030304,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9657894736842106,
          "median": 0.9657894736842106,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_minimal_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.010638297872340425,
          "median": 0.010638297872340425,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.020833333333333332,
          "median": 0.020833333333333332,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.021052631578947368,
          "median": 0.021052631578947368,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 47,
          "median": 47,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 80,
          "median": 80,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.07894736842105263,
          "median": 0.07894736842105263,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10714285714285714,
          "median": 0.10714285714285714,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.23076923076923078,
          "median": 0.23076923076923078,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.14634146341463414,
          "median": 0.14634146341463414,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 15,
          "median": 15,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06153846153846154,
          "median": 0.06153846153846154,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0851063829787234,
          "median": 0.0851063829787234,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.18181818181818182,
          "median": 0.18181818181818182,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.11594202898550723,
          "median": 0.11594202898550723,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 43,
          "median": 43,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 43,
          "median": 43,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 51,
          "median": 51,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8976744186046512,
          "median": 0.8976744186046512,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.85,
          "median": 0.85,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.030303030303030304,
          "median": 0.030303030303030304,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.038461538461538464,
          "median": 0.038461538461538464,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.125,
          "median": 0.125,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.058823529411764705,
          "median": 0.058823529411764705,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 7,
          "median": 7,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 31,
          "median": 31,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9115384615384615,
          "median": 0.9115384615384615,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8951612903225806,
          "median": 0.8951612903225806,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.0196078431372549,
          "median": 0.0196078431372549,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.2,
          "median": 0.2,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03846153846153846,
          "median": 0.03846153846153846,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 20,
          "median": 20,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.10344827586206896,
          "median": 0.10344827586206896,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.15789473684210525,
          "median": 0.15789473684210525,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.23076923076923078,
          "median": 0.23076923076923078,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.18749999999999997,
          "median": 0.18749999999999997,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 16,
          "median": 16,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 21,
          "median": 21,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8547619047619047,
          "median": 0.8547619047619047,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.043478260869565216,
          "median": 0.043478260869565216,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.07142857142857142,
          "median": 0.07142857142857142,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 26,
          "median": 26,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.865909090909091,
          "median": 0.865909090909091,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02857142857142857,
          "median": 0.02857142857142857,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.038461538461538464,
          "median": 0.038461538461538464,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.05555555555555555,
          "median": 0.05555555555555555,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 31,
          "median": 31,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8999999999999999,
          "median": 0.8999999999999999,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8951612903225806,
          "median": 0.8951612903225806,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.08695652173913043,
          "median": 0.08695652173913043,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.1276595744680851,
          "median": 0.1276595744680851,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.21428571428571427,
          "median": 0.21428571428571427,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.16,
          "median": 0.16,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 6,
          "median": 6,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 41,
          "median": 41,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 42,
          "median": 42,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 51,
          "median": 51,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.7845238095238096,
          "median": 0.7845238095238096,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.85,
          "median": 0.85,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.06896551724137931,
          "median": 0.06896551724137931,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.10526315789473684,
          "median": 0.10526315789473684,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.12903225806451615,
          "median": 0.12903225806451615,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 17,
          "median": 17,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9147058823529413,
          "median": 0.9147058823529413,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017857142857142856,
          "median": 0.017857142857142856,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03508771929824561,
          "median": 0.03508771929824561,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.03508771929824561,
          "median": 0.03508771929824561,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.06779661016949153,
          "median": 0.06779661016949153,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 45,
          "median": 45,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 51,
          "median": 51,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9357142857142857,
          "median": 0.9357142857142857,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.85,
          "median": 0.85,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02564102564102564,
          "median": 0.02564102564102564,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.05,
          "median": 0.05,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9249999999999999,
          "median": 0.9249999999999999,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02857142857142857,
          "median": 0.02857142857142857,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.038461538461538464,
          "median": 0.038461538461538464,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.05555555555555555,
          "median": 0.05555555555555555,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 31,
          "median": 31,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8807692307692307,
          "median": 0.8807692307692307,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8951612903225806,
          "median": 0.8951612903225806,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.01818181818181818,
          "median": 0.01818181818181818,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1111111111111111,
          "median": 0.1111111111111111,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 8,
          "median": 8,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 40,
          "median": 40,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8150000000000001,
          "median": 0.8150000000000001,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.12121212121212122,
          "median": 0.12121212121212122,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.21052631578947367,
          "median": 0.21052631578947367,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.2222222222222222,
          "median": 0.2222222222222222,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.21621621621621623,
          "median": 0.21621621621621623,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 15,
          "median": 15,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.05970149253731343,
          "median": 0.05970149253731343,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0851063829787234,
          "median": 0.0851063829787234,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.11267605633802817,
          "median": 0.11267605633802817,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 4,
          "median": 4,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 43,
          "median": 43,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 20,
          "median": 20,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 44,
          "median": 44,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 51,
          "median": 51,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9954545454545454,
          "median": 0.9954545454545454,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.85,
          "median": 0.85,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.17857142857142858,
          "median": 0.17857142857142858,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.18518518518518517,
          "median": 0.18518518518518517,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.18181818181818182,
          "median": 0.18181818181818182,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 32,
          "median": 32,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.08571428571428572,
          "median": 0.08571428571428572,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.11538461538461539,
          "median": 0.11538461538461539,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.25,
          "median": 0.25,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.15789473684210525,
          "median": 0.15789473684210525,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 31,
          "median": 31,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9894736842105264,
          "median": 0.9894736842105264,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8951612903225806,
          "median": 0.8951612903225806,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.03773584905660377,
          "median": 0.03773584905660377,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0425531914893617,
          "median": 0.0425531914893617,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.25,
          "median": 0.25,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.07272727272727272,
          "median": 0.07272727272727272,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 45,
          "median": 45,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 6,
          "median": 6,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 16,
          "median": 16,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 51,
          "median": 51,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.85,
          "median": 0.85,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.041666666666666664,
          "median": 0.041666666666666664,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.08,
          "median": 0.08,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 8,
          "median": 8,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.011363636363636364,
          "median": 0.011363636363636364,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.023809523809523808,
          "median": 0.023809523809523808,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.022471910112359546,
          "median": 0.022471910112359546,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 41,
          "median": 41,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 102,
          "median": 102,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9705882352941176,
          "median": 0.9705882352941176,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02564102564102564,
          "median": 0.02564102564102564,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.05,
          "median": 0.05,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 16,
          "median": 16,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9875,
          "median": 0.9875,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.02631578947368421,
          "median": 0.02631578947368421,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.038461538461538464,
          "median": 0.038461538461538464,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.07692307692307693,
          "median": 0.07692307692307693,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.05128205128205129,
          "median": 0.05128205128205129,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 12,
          "median": 12,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 16,
          "median": 16,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 31,
          "median": 31,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.99375,
          "median": 0.99375,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8951612903225806,
          "median": 0.8951612903225806,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017543859649122806,
          "median": 0.017543859649122806,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.09090909090909091,
          "median": 0.09090909090909091,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.034482758620689655,
          "median": 0.034482758620689655,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 41,
          "median": 41,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_deepseek-chat_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.04,
          "median": 0.04,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.07692307692307693,
          "median": 0.07692307692307693,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 6,
          "median": 6,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.990909090909091,
          "median": 0.990909090909091,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8770833333333333,
          "median": 0.8770833333333333,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-4-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.024390243902439025,
          "median": 0.024390243902439025,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.07142857142857142,
          "median": 0.07142857142857142,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.047619047619047616,
          "median": 0.047619047619047616,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 21,
          "median": 21,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 34,
          "median": 34,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9617647058823531,
          "median": 0.9617647058823531,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_deepseek-coder_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.019230769230769232,
          "median": 0.019230769230769232,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03773584905660377,
          "median": 0.03773584905660377,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 20,
          "median": 20,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 51,
          "median": 51,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.985,
          "median": 0.985,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.85,
          "median": 0.85,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-4o_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.03125,
          "median": 0.03125,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.038461538461538464,
          "median": 0.038461538461538464,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.14285714285714285,
          "median": 0.14285714285714285,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.060606060606060615,
          "median": 0.060606060606060615,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 6,
          "median": 6,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 31,
          "median": 31,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9928571428571429,
          "median": 0.9928571428571429,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8951612903225806,
          "median": 0.8951612903225806,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-3.5-turbo_vs_direct_mcode_deepseek-coder": {
        "mapping_jaccard_similarity": {
          "mean": 0.017241379310344827,
          "median": 0.017241379310344827,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.02127659574468085,
          "median": 0.02127659574468085,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.03389830508474576,
          "median": 0.03389830508474576,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 46,
          "median": 46,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 35,
          "median": 35,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 66,
          "median": 66,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9799999999999999,
          "median": 0.9799999999999999,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8681818181818182,
          "median": 0.8681818181818182,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      }
    },
    "overall_metrics": {
      "mapping_jaccard_similarity": {
        "mean": 0.06250670045414568,
        "median": 0.038867924528301886,
        "stdev": 0.06536269426094517,
        "min": 0.010638297872340425,
        "max": 0.352112676056338
      },
      "mapping_precision": {
        "mean": 0.09504546085813083,
        "median": 0.04759238521836506,
        "stdev": 0.10457833818867586,
        "min": 0.02127659574468085,
        "max": 0.5102040816326531
      },
      "mapping_recall": {
        "mean": 0.15989010472331286,
        "median": 0.14285714285714285,
        "stdev": 0.09789779897407458,
        "min": 0.020833333333333332,
        "max": 0.5319148936170213
      },
      "mapping_f1_score": {
        "mean": 0.11158599204546663,
        "median": 0.07482517482517483,
        "stdev": 0.10117690467064569,
        "min": 0.021052631578947368,
        "max": 0.5208333333333334
      },
      "mapping_true_positives": {
        "mean": 2.92,
        "median": 2.0,
        "stdev": 3.8589413796310215,
        "min": 1,
        "max": 25
      },
      "mapping_false_positives": {
        "mean": 30.52,
        "median": 25.0,
        "stdev": 11.765116199327291,
        "min": 10,
        "max": 46
      },
      "mapping_false_negatives": {
        "mean": 14.5,
        "median": 11.0,
        "stdev": 9.11659173693542,
        "min": 4,
        "max": 47
      },
      "gold_mappings_count": {
        "mean": 27.84,
        "median": 20.5,
        "stdev": 18.828289614192744,
        "min": 8,
        "max": 102
      },
      "comp_mappings_count": {
        "mean": 41.26,
        "median": 34.0,
        "stdev": 15.449469973076086,
        "min": 24,
        "max": 66
      },
      "gold_avg_confidence": {
        "mean": 0.8546991952661318,
        "median": 0.9144957983193278,
        "stdev": 0.24341621937669283,
        "min": 0.0,
        "max": 1.0
      },
      "comp_avg_confidence": {
        "mean": 0.8901419332477207,
        "median": 0.8770833333333333,
        "stdev": 0.03927935255214733,
        "min": 0.8351851851851853,
        "max": 0.9617647058823531
      },
      "gold_compliance_score": {
        "mean": 0.41333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0.1724835264407127,
        "min": 0.0,
        "max": 1.0
      },
      "comp_compliance_score": {
        "mean": 0.39999999999999997,
        "median": 0.3333333333333333,
        "stdev": 0.13468700594029476,
        "min": 0.3333333333333333,
        "max": 0.6666666666666666
      }
    }
  }
}