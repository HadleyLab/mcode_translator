{
  "metadata": {
    "timestamp": "2025-09-19T08:52:09.247974",
    "total_tasks": 10,
    "successful_tasks": 10
  },
  "results": [
    {
      "task_id": "eb85d8a1-09ed-4d4b-8c33-96f1eae16208",
      "trial_id": "NCT01026116",
      "gold_config": "direct_mcode_minimal_gpt-4-turbo",
      "comp_config": "direct_mcode_improved_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.0,
        "mapping_precision": 0.0,
        "mapping_recall": 0.0,
        "mapping_f1_score": 0,
        "mapping_true_positives": 0,
        "mapping_false_positives": 13,
        "mapping_false_negatives": 11,
        "gold_mappings_count": 11,
        "comp_mappings_count": 14,
        "gold_avg_confidence": 0.8954545454545454,
        "comp_avg_confidence": 0.9500000000000001,
        "true_positive_examples": [],
        "false_positive_examples": [
          "CancerRelatedMedication=\"J9264\"",
          "TNMClinicalStageGroup=\"367651003\"",
          "CancerCondition=\"C50\"",
          "ECOGPerformanceStatus=\"89261002\"",
          "ECOGPerformanceStatus=\"371928008\""
        ],
        "false_negative_examples": [
          "CancerCondition=\"254837009\"",
          "Patient=\"C50.9\"",
          "Procedure=\"152198000\"",
          "Observation=\"ECOG\"",
          "Patient=\"M-8010/3\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 30.818939208984375
    },
    {
      "task_id": "306de487-dd39-4fcd-897b-37986f435de1",
      "trial_id": "NCT00109785",
      "gold_config": "direct_mcode_improved_gpt-4-turbo",
      "comp_config": "direct_mcode_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.05263157894736842,
        "mapping_precision": 0.09090909090909091,
        "mapping_recall": 0.1111111111111111,
        "mapping_f1_score": 0.09999999999999999,
        "mapping_true_positives": 1,
        "mapping_false_positives": 10,
        "mapping_false_negatives": 8,
        "gold_mappings_count": 9,
        "comp_mappings_count": 11,
        "gold_avg_confidence": 0.9277777777777777,
        "comp_avg_confidence": 0.859090909090909,
        "true_positive_examples": [
          "CancerCondition=\"C50\""
        ],
        "false_positive_examples": [
          "Procedure=\"P5-09.3\"",
          "Observation=\"LP29684-5\"",
          "Procedure=\"B02.3\"",
          "Procedure=\"3E02329\"",
          "MedicationStatement=\"C1883721\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedication=\"not available\"",
          "CancerCondition=\"254837009\"",
          "CancerRelatedProcedure=\"108290001\"",
          "KarnofskyPerformanceStatus=\"Not available\"",
          "TNMClinicalStageGroup=\"Not available\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 31.075716018676758
    },
    {
      "task_id": "75ab58c9-9ba0-41b8-a11a-30861cc3b007",
      "trial_id": "NCT06650748",
      "gold_config": "direct_mcode_structured_gpt-4-turbo",
      "comp_config": "direct_mcode_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.0967741935483871,
        "mapping_precision": 0.2,
        "mapping_recall": 0.15789473684210525,
        "mapping_f1_score": 0.17647058823529413,
        "mapping_true_positives": 3,
        "mapping_false_positives": 12,
        "mapping_false_negatives": 16,
        "gold_mappings_count": 22,
        "comp_mappings_count": 16,
        "gold_avg_confidence": 0.85,
        "comp_avg_confidence": 0.95,
        "true_positive_examples": [
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:3467\"",
          "CancerCondition=\"128700001\""
        ],
        "false_positive_examples": [
          "Observation=\"21975-4\"",
          "GenomicVariant=\"Multigene Risk Score\"",
          "ResearchStudy=\"NCT06650748\"",
          "Observation=\"C77.9\"",
          "Consent=\"N/A\""
        ],
        "false_negative_examples": [
          "Treatment=\"PALLET\"",
          "CancerDiseaseStatus=\"260385009\"",
          "MedicationStatement=\"N/A\"",
          "Treatment=\"NeoMONARCH\"",
          "TumorMarkerTest=\"85319-2\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 32.00984001159668
    },
    {
      "task_id": "7ee565fa-1754-4a80-b56c-0f3de143009d",
      "trial_id": "NCT00109785",
      "gold_config": "direct_mcode_evidence_based_gpt-4-turbo",
      "comp_config": "direct_mcode_optimization_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.04878048780487805,
        "mapping_precision": 0.08695652173913043,
        "mapping_recall": 0.1,
        "mapping_f1_score": 0.09302325581395349,
        "mapping_true_positives": 2,
        "mapping_false_positives": 21,
        "mapping_false_negatives": 18,
        "gold_mappings_count": 25,
        "comp_mappings_count": 28,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.8410714285714286,
        "true_positive_examples": [
          "CancerCondition=\"C50\"",
          "CancerCondition=\"C50.919\""
        ],
        "false_positive_examples": [
          "Observation=\"21905-5\"",
          "CancerStageObservation=\"405536007\"",
          "Observation=\"LP212175-6\"",
          "Substance=\"C0079541\"",
          "Procedure=\"C8907\""
        ],
        "false_negative_examples": [
          "ResearchStudy=\"NCT00109785\"",
          "Procedure=\"387713003\"",
          "DiagnosticTest=\"LP29692-5\"",
          "DiagnosticTest=\"LP15055-8\"",
          "ResearchStudy=\"NA\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 31.656980514526367
    },
    {
      "task_id": "cc3a5e79-b63d-4f3f-bd7b-c982cbb3b96a",
      "trial_id": "NCT06650748",
      "gold_config": "direct_mcode_optimization_gpt-4-turbo",
      "comp_config": "direct_mcode_improved_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.08333333333333333,
        "mapping_precision": 0.17647058823529413,
        "mapping_recall": 0.13636363636363635,
        "mapping_f1_score": 0.15384615384615383,
        "mapping_true_positives": 3,
        "mapping_false_positives": 14,
        "mapping_false_negatives": 19,
        "gold_mappings_count": 24,
        "comp_mappings_count": 20,
        "gold_avg_confidence": 0.875,
        "comp_avg_confidence": 0.9075,
        "true_positive_examples": [
          "CancerCondition=\"C50\"",
          "CancerCondition=\"254837009\"",
          "GenomicVariant=\"HGNC:6284\""
        ],
        "false_positive_examples": [
          "TNMClinicalStageGroup=\"cT2N1M0\"",
          "GenomicVariant=\"HGNC:3467\"",
          "CancerRelatedMedication=\"1140850\"",
          "GenomicVariant=\"LNG:000000\"",
          "CancerRelatedProcedure=\"129317005\""
        ],
        "false_negative_examples": [
          "MedicationStatement=\"1366043\"",
          "TumorMarkerTest=\"85319-2\"",
          "MedicationStatement=\"1366048\"",
          "RiskAssessment=\"GENEVA\"",
          "TumorMarkerTest=\"85337-4\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 35.017967224121094
    },
    {
      "task_id": "985b862d-baa3-4d70-88d2-eb87912a8ecd",
      "trial_id": "NCT01026116",
      "gold_config": "direct_mcode_comprehensive_gpt-4-turbo",
      "comp_config": "direct_mcode_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.125,
        "mapping_precision": 0.21428571428571427,
        "mapping_recall": 0.23076923076923078,
        "mapping_f1_score": 0.22222222222222224,
        "mapping_true_positives": 3,
        "mapping_false_positives": 11,
        "mapping_false_negatives": 10,
        "gold_mappings_count": 14,
        "comp_mappings_count": 14,
        "gold_avg_confidence": 0.9535714285714285,
        "comp_avg_confidence": 0.9857142857142858,
        "true_positive_examples": [
          "GenomicVariant=\"10828004\"",
          "GenomicVariant=\"405538009\"",
          "CancerCondition=\"443237005\""
        ],
        "false_positive_examples": [
          "Procedure=\"387713003\"",
          "CancerCondition=\"254837009\"",
          "Observation=\"364075005\"",
          "ResearchStudy=\"NCT01026116\"",
          "CancerStage=\"258219007\""
        ],
        "false_negative_examples": [
          "CancerRelatedMedication=\"J9264\"",
          "CancerRelatedProcedure=\"23426006\"",
          "CancerCondition=\"C50\"",
          "ECOGPerformanceStatus=\"89261002\"",
          "TNMClinicalStageGroup=\"368581000119106\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 35.74085235595703
    },
    {
      "task_id": "5b271423-9244-486b-b374-bdd9df14c569",
      "trial_id": "NCT01922921",
      "gold_config": "direct_mcode_gpt-4-turbo",
      "comp_config": "direct_mcode_simple_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.4642857142857143,
        "mapping_precision": 0.5652173913043478,
        "mapping_recall": 0.7222222222222222,
        "mapping_f1_score": 0.6341463414634146,
        "mapping_true_positives": 13,
        "mapping_false_positives": 10,
        "mapping_false_negatives": 5,
        "gold_mappings_count": 22,
        "comp_mappings_count": 29,
        "gold_avg_confidence": 0.890909090909091,
        "comp_avg_confidence": 0.9655172413793104,
        "true_positive_examples": [
          "Observation=\"718-7\"",
          "Observation=\"1975-2\"",
          "Observation=\"789-8\"",
          "Observation=\"C25428\"",
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "Observation=\"C28554\"",
          "ResearchStudy=\"NCT01922921\"",
          "MedicationStatement=\"C18216\"",
          "Observation=\"LP128504-0\"",
          "MedicationStatement=\"C2037\""
        ],
        "false_negative_examples": [
          "Observation=\"LA6724-4\"",
          "Observation=\"C51948\"",
          "Observation=\"C14155\"",
          "Procedure=\"392021009\"",
          "Observation=\"LP21258-6\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 36.13591194152832
    },
    {
      "task_id": "4cf6fa0b-a0c6-4024-b38a-31f09ec95fcb",
      "trial_id": "NCT01922921",
      "gold_config": "direct_mcode_simple_gpt-4-turbo",
      "comp_config": "direct_mcode_improved_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.023809523809523808,
        "mapping_precision": 0.05,
        "mapping_recall": 0.043478260869565216,
        "mapping_f1_score": 0.046511627906976744,
        "mapping_true_positives": 1,
        "mapping_false_positives": 19,
        "mapping_false_negatives": 22,
        "gold_mappings_count": 29,
        "comp_mappings_count": 27,
        "gold_avg_confidence": 0.9655172413793104,
        "comp_avg_confidence": 0.9407407407407407,
        "true_positive_examples": [
          "GenomicVariant=\"HGNC:3430\""
        ],
        "false_positive_examples": [
          "CancerRelatedMedication=\"C106032\"",
          "CancerRelatedMedication=\"C2039\"",
          "TNMClinicalStageGroup=\"110245001\"",
          "CancerRelatedMedication=\"C1647\"",
          "CancerRelatedMedication=\"715688004\""
        ],
        "false_negative_examples": [
          "Observation=\"LP212175-6\"",
          "MedicationStatement=\"C1647\"",
          "Observation=\"1975-2\"",
          "Observation=\"C28554\"",
          "Observation=\"LP128504-0\""
        ],
        "gold_compliance_score": 0.3333333333333333,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 36.56196594238281
    },
    {
      "task_id": "de9388e5-9071-4f31-aa00-b15c151d90cb",
      "trial_id": "NCT00616135",
      "gold_config": "direct_mcode_evidence_based_with_codes_gpt-4-turbo",
      "comp_config": "direct_mcode_optimization_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.03571428571428571,
        "mapping_precision": 0.043478260869565216,
        "mapping_recall": 0.16666666666666666,
        "mapping_f1_score": 0.06896551724137931,
        "mapping_true_positives": 1,
        "mapping_false_positives": 22,
        "mapping_false_negatives": 5,
        "gold_mappings_count": 10,
        "comp_mappings_count": 27,
        "gold_avg_confidence": 1.0,
        "comp_avg_confidence": 0.85,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Procedure=\"234262008\"",
          "Procedure=\"119954001\"",
          "Observation=\"248104008\"",
          "Procedure=\"173333001\"",
          "Procedure=\"23426006\""
        ],
        "false_negative_examples": [
          "CancerTreatment=\"108290001\"",
          "PatientDemographics=\"248153007\"",
          "CancerCondition=\"372130007\"",
          "CancerTreatment=\"396487001\"",
          "PatientDemographics=\"184099003\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 9.567022323608398
    },
    {
      "task_id": "27aa23d0-f77a-4864-9ec7-15032d2d3ca3",
      "trial_id": "NCT00616135",
      "gold_config": "direct_mcode_evidence_based_concise_gpt-4-turbo",
      "comp_config": "direct_mcode_gpt-4-turbo",
      "metrics": {
        "mapping_jaccard_similarity": 0.023809523809523808,
        "mapping_precision": 0.041666666666666664,
        "mapping_recall": 0.05263157894736842,
        "mapping_f1_score": 0.04651162790697675,
        "mapping_true_positives": 1,
        "mapping_false_positives": 23,
        "mapping_false_negatives": 18,
        "gold_mappings_count": 22,
        "comp_mappings_count": 26,
        "gold_avg_confidence": 0.9454545454545454,
        "comp_avg_confidence": 0.9346153846153846,
        "true_positive_examples": [
          "CancerCondition=\"254837009\""
        ],
        "false_positive_examples": [
          "Observation=\"K90.2\"",
          "Condition=\"238131007\"",
          "Procedure=\"19301\"",
          "Procedure=\"23426006\"",
          "ResearchStudy=\"NCT00616135\""
        ],
        "false_negative_examples": [
          "Procedure=\"180325003\"",
          "BodyStructure=\"76751001\"",
          "CancerTreatment=\"108290001\"",
          "CancerTreatment=\"225287009\"",
          "CancerCondition=\"363346000\""
        ],
        "gold_compliance_score": 0.6666666666666666,
        "comp_compliance_score": 0.3333333333333333
      },
      "status": "Success",
      "duration_ms": 10.753154754638672
    }
  ],
  "analysis": {
    "summary": {
      "total_comparisons": 10,
      "successful_comparisons": 10,
      "success_rate": 1.0,
      "unique_config_pairs": 10
    },
    "configuration_analysis": {
      "direct_mcode_minimal_gpt-4-turbo_vs_direct_mcode_improved_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.0,
          "median": 0.0,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 0,
          "median": 0,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.8954545454545454,
          "median": 0.8954545454545454,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9500000000000001,
          "median": 0.9500000000000001,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_improved_gpt-4-turbo_vs_direct_mcode_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.09090909090909091,
          "median": 0.09090909090909091,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1111111111111111,
          "median": 0.1111111111111111,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.09999999999999999,
          "median": 0.09999999999999999,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 8,
          "median": 8,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 9,
          "median": 9,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9277777777777777,
          "median": 0.9277777777777777,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.859090909090909,
          "median": 0.859090909090909,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_structured_gpt-4-turbo_vs_direct_mcode_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.0967741935483871,
          "median": 0.0967741935483871,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.2,
          "median": 0.2,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.15789473684210525,
          "median": 0.15789473684210525,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.17647058823529413,
          "median": 0.17647058823529413,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 12,
          "median": 12,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 16,
          "median": 16,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 16,
          "median": 16,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.85,
          "median": 0.85,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.95,
          "median": 0.95,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_gpt-4-turbo_vs_direct_mcode_optimization_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.04878048780487805,
          "median": 0.04878048780487805,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.08695652173913043,
          "median": 0.08695652173913043,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.1,
          "median": 0.1,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.09302325581395349,
          "median": 0.09302325581395349,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 2,
          "median": 2,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 21,
          "median": 21,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 25,
          "median": 25,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 28,
          "median": 28,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.8410714285714286,
          "median": 0.8410714285714286,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_optimization_gpt-4-turbo_vs_direct_mcode_improved_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.08333333333333333,
          "median": 0.08333333333333333,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.17647058823529413,
          "median": 0.17647058823529413,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.13636363636363635,
          "median": 0.13636363636363635,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.15384615384615383,
          "median": 0.15384615384615383,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 24,
          "median": 24,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 20,
          "median": 20,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.875,
          "median": 0.875,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9075,
          "median": 0.9075,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_comprehensive_gpt-4-turbo_vs_direct_mcode_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.125,
          "median": 0.125,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.21428571428571427,
          "median": 0.21428571428571427,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.23076923076923078,
          "median": 0.23076923076923078,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.22222222222222224,
          "median": 0.22222222222222224,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 3,
          "median": 3,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 11,
          "median": 11,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 14,
          "median": 14,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9535714285714285,
          "median": 0.9535714285714285,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9857142857142858,
          "median": 0.9857142857142858,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_gpt-4-turbo_vs_direct_mcode_simple_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.4642857142857143,
          "median": 0.4642857142857143,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.5652173913043478,
          "median": 0.5652173913043478,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.7222222222222222,
          "median": 0.7222222222222222,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.6341463414634146,
          "median": 0.6341463414634146,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 13,
          "median": 13,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 29,
          "median": 29,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.890909090909091,
          "median": 0.890909090909091,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9655172413793104,
          "median": 0.9655172413793104,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_simple_gpt-4-turbo_vs_direct_mcode_improved_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.023809523809523808,
          "median": 0.023809523809523808,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.05,
          "median": 0.05,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.043478260869565216,
          "median": 0.043478260869565216,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.046511627906976744,
          "median": 0.046511627906976744,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 19,
          "median": 19,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 29,
          "median": 29,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9655172413793104,
          "median": 0.9655172413793104,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9407407407407407,
          "median": 0.9407407407407407,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_with_codes_gpt-4-turbo_vs_direct_mcode_optimization_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.03571428571428571,
          "median": 0.03571428571428571,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.043478260869565216,
          "median": 0.043478260869565216,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.16666666666666666,
          "median": 0.16666666666666666,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.06896551724137931,
          "median": 0.06896551724137931,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 5,
          "median": 5,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 10,
          "median": 10,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 27,
          "median": 27,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 1.0,
          "median": 1.0,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.85,
          "median": 0.85,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      },
      "direct_mcode_evidence_based_concise_gpt-4-turbo_vs_direct_mcode_gpt-4-turbo": {
        "mapping_jaccard_similarity": {
          "mean": 0.023809523809523808,
          "median": 0.023809523809523808,
          "stdev": 0,
          "count": 1
        },
        "mapping_precision": {
          "mean": 0.041666666666666664,
          "median": 0.041666666666666664,
          "stdev": 0,
          "count": 1
        },
        "mapping_recall": {
          "mean": 0.05263157894736842,
          "median": 0.05263157894736842,
          "stdev": 0,
          "count": 1
        },
        "mapping_f1_score": {
          "mean": 0.04651162790697675,
          "median": 0.04651162790697675,
          "stdev": 0,
          "count": 1
        },
        "mapping_true_positives": {
          "mean": 1,
          "median": 1,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_positives": {
          "mean": 23,
          "median": 23,
          "stdev": 0,
          "count": 1
        },
        "mapping_false_negatives": {
          "mean": 18,
          "median": 18,
          "stdev": 0,
          "count": 1
        },
        "gold_mappings_count": {
          "mean": 22,
          "median": 22,
          "stdev": 0,
          "count": 1
        },
        "comp_mappings_count": {
          "mean": 26,
          "median": 26,
          "stdev": 0,
          "count": 1
        },
        "gold_avg_confidence": {
          "mean": 0.9454545454545454,
          "median": 0.9454545454545454,
          "stdev": 0,
          "count": 1
        },
        "comp_avg_confidence": {
          "mean": 0.9346153846153846,
          "median": 0.9346153846153846,
          "stdev": 0,
          "count": 1
        },
        "gold_compliance_score": {
          "mean": 0.6666666666666666,
          "median": 0.6666666666666666,
          "stdev": 0,
          "count": 1
        },
        "comp_compliance_score": {
          "mean": 0.3333333333333333,
          "median": 0.3333333333333333,
          "stdev": 0,
          "count": 1
        }
      }
    },
    "overall_metrics": {
      "mapping_jaccard_similarity": {
        "mean": 0.09541386412530145,
        "median": 0.050706033376123234,
        "stdev": 0.13499661516048603,
        "min": 0.0,
        "max": 0.4642857142857143
      },
      "mapping_precision": {
        "mean": 0.14689842340098094,
        "median": 0.08893280632411067,
        "stdev": 0.16421254420795336,
        "min": 0.0,
        "max": 0.5652173913043478
      },
      "mapping_recall": {
        "mean": 0.1721137443791906,
        "median": 0.12373737373737373,
        "stdev": 0.20465082848728355,
        "min": 0.0,
        "max": 0.7222222222222222
      },
      "mapping_f1_score": {
        "mean": 0.1541697334636371,
        "median": 0.09651162790697673,
        "stdev": 0.18147175188668585,
        "min": 0,
        "max": 0.6341463414634146
      },
      "mapping_true_positives": {
        "mean": 2.8,
        "median": 1.5,
        "stdev": 3.73571352696584,
        "min": 0,
        "max": 13
      },
      "mapping_false_positives": {
        "mean": 15.5,
        "median": 13.5,
        "stdev": 5.190803834132479,
        "min": 10,
        "max": 23
      },
      "mapping_false_negatives": {
        "mean": 13.2,
        "median": 13.5,
        "stdev": 6.160808027812225,
        "min": 5,
        "max": 22
      },
      "gold_mappings_count": {
        "mean": 18.8,
        "median": 22.0,
        "stdev": 7.130529043797833,
        "min": 9,
        "max": 29
      },
      "comp_mappings_count": {
        "mean": 21.2,
        "median": 23.0,
        "stdev": 6.941021378570864,
        "min": 11,
        "max": 29
      },
      "gold_avg_confidence": {
        "mean": 0.9303684629546698,
        "median": 0.9366161616161616,
        "stdev": 0.05164623023859518,
        "min": 0.85,
        "max": 1.0
      },
      "comp_avg_confidence": {
        "mean": 0.9184249990112059,
        "median": 0.9376780626780626,
        "stdev": 0.05142962274974675,
        "min": 0.8410714285714286,
        "max": 0.9857142857142858
      },
      "gold_compliance_score": {
        "mean": 0.39999999999999997,
        "median": 0.3333333333333333,
        "stdev": 0.14054567378526128,
        "min": 0.3333333333333333,
        "max": 0.6666666666666666
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0.0,
        "min": 0.3333333333333333,
        "max": 0.3333333333333333
      }
    }
  }
}