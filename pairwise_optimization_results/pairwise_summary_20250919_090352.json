{
  "summary": {
    "total_comparisons": 10,
    "successful_comparisons": 10,
    "success_rate": 1.0,
    "unique_config_pairs": 10
  },
  "configuration_analysis": {
    "direct_mcode_comprehensive_gpt-4-turbo_vs_direct_mcode_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.043478260869565216,
        "median": 0.043478260869565216,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.07692307692307693,
        "median": 0.07692307692307693,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.09090909090909091,
        "median": 0.09090909090909091,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.08333333333333334,
        "median": 0.08333333333333334,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 1,
        "median": 1,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 12,
        "median": 12,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 10,
        "median": 10,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 11,
        "median": 11,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 15,
        "median": 15,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 0.9727272727272727,
        "median": 0.9727272727272727,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.9533333333333334,
        "median": 0.9533333333333334,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_improved_gpt-4-turbo_vs_direct_mcode_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.22727272727272727,
        "median": 0.22727272727272727,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.29411764705882354,
        "median": 0.29411764705882354,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.5,
        "median": 0.5,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.37037037037037035,
        "median": 0.37037037037037035,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 5,
        "median": 5,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 12,
        "median": 12,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 5,
        "median": 5,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 11,
        "median": 11,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 18,
        "median": 18,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 0.8772727272727273,
        "median": 0.8772727272727273,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.8416666666666669,
        "median": 0.8416666666666669,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_optimization_gpt-4-turbo_vs_direct_mcode_improved_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.08333333333333333,
        "median": 0.08333333333333333,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.15789473684210525,
        "median": 0.15789473684210525,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.15,
        "median": 0.15,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.15384615384615385,
        "median": 0.15384615384615385,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 3,
        "median": 3,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 16,
        "median": 16,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 17,
        "median": 17,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 23,
        "median": 23,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 21,
        "median": 21,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 0.8782608695652173,
        "median": 0.8782608695652173,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.9476190476190477,
        "median": 0.9476190476190477,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_minimal_gpt-4-turbo_vs_direct_mcode_improved_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.10526315789473684,
        "median": 0.10526315789473684,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.16666666666666666,
        "median": 0.16666666666666666,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.2222222222222222,
        "median": 0.2222222222222222,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.1904761904761905,
        "median": 0.1904761904761905,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 2,
        "median": 2,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 10,
        "median": 10,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 7,
        "median": 7,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 12,
        "median": 12,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 14,
        "median": 14,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 0.9583333333333334,
        "median": 0.9583333333333334,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.9500000000000001,
        "median": 0.9500000000000001,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_structured_gpt-4-turbo_vs_direct_mcode_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.26666666666666666,
        "median": 0.26666666666666666,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.4,
        "median": 0.4,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.4444444444444444,
        "median": 0.4444444444444444,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.4210526315789474,
        "median": 0.4210526315789474,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 8,
        "median": 8,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 12,
        "median": 12,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 10,
        "median": 10,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 21,
        "median": 21,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 22,
        "median": 22,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 0.9523809523809522,
        "median": 0.9523809523809522,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.9636363636363636,
        "median": 0.9636363636363636,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_evidence_based_concise_gpt-4-turbo_vs_direct_mcode_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.10344827586206896,
        "median": 0.10344827586206896,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.21428571428571427,
        "median": 0.21428571428571427,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.16666666666666666,
        "median": 0.16666666666666666,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.1875,
        "median": 0.1875,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 3,
        "median": 3,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 11,
        "median": 11,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 15,
        "median": 15,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 22,
        "median": 22,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 18,
        "median": 18,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 0.9454545454545453,
        "median": 0.9454545454545453,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.9500000000000001,
        "median": 0.9500000000000001,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.6666666666666666,
        "median": 0.6666666666666666,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.6666666666666666,
        "median": 0.6666666666666666,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_evidence_based_gpt-4-turbo_vs_direct_mcode_optimization_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.03125,
        "median": 0.03125,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.1,
        "median": 0.1,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.043478260869565216,
        "median": 0.043478260869565216,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.06060606060606061,
        "median": 0.06060606060606061,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 1,
        "median": 1,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 9,
        "median": 9,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 22,
        "median": 22,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 25,
        "median": 25,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 12,
        "median": 12,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 1.0,
        "median": 1.0,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.8816666666666667,
        "median": 0.8816666666666667,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.6666666666666666,
        "median": 0.6666666666666666,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_gpt-4-turbo_vs_direct_mcode_simple_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.3611111111111111,
        "median": 0.3611111111111111,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.5652173913043478,
        "median": 0.5652173913043478,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.5,
        "median": 0.5,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.5306122448979592,
        "median": 0.5306122448979592,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 13,
        "median": 13,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 10,
        "median": 10,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 13,
        "median": 13,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 38,
        "median": 38,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 32,
        "median": 32,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 0.9315789473684208,
        "median": 0.9315789473684208,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.9546874999999999,
        "median": 0.9546874999999999,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_simple_gpt-4-turbo_vs_direct_mcode_improved_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.22580645161290322,
        "median": 0.22580645161290322,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.4666666666666667,
        "median": 0.4666666666666667,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.30434782608695654,
        "median": 0.30434782608695654,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.3684210526315789,
        "median": 0.3684210526315789,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 7,
        "median": 7,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 8,
        "median": 8,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 16,
        "median": 16,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 32,
        "median": 32,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 30,
        "median": 30,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 0.9546874999999999,
        "median": 0.9546874999999999,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.9316666666666665,
        "median": 0.9316666666666665,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      }
    },
    "direct_mcode_evidence_based_with_codes_gpt-4-turbo_vs_direct_mcode_optimization_gpt-4-turbo": {
      "mapping_jaccard_similarity": {
        "mean": 0.1111111111111111,
        "median": 0.1111111111111111,
        "stdev": 0,
        "count": 1
      },
      "mapping_precision": {
        "mean": 0.14285714285714285,
        "median": 0.14285714285714285,
        "stdev": 0,
        "count": 1
      },
      "mapping_recall": {
        "mean": 0.3333333333333333,
        "median": 0.3333333333333333,
        "stdev": 0,
        "count": 1
      },
      "mapping_f1_score": {
        "mean": 0.2,
        "median": 0.2,
        "stdev": 0,
        "count": 1
      },
      "mapping_true_positives": {
        "mean": 2,
        "median": 2,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_positives": {
        "mean": 12,
        "median": 12,
        "stdev": 0,
        "count": 1
      },
      "mapping_false_negatives": {
        "mean": 4,
        "median": 4,
        "stdev": 0,
        "count": 1
      },
      "gold_mappings_count": {
        "mean": 10,
        "median": 10,
        "stdev": 0,
        "count": 1
      },
      "comp_mappings_count": {
        "mean": 19,
        "median": 19,
        "stdev": 0,
        "count": 1
      },
      "gold_avg_confidence": {
        "mean": 1.0,
        "median": 1.0,
        "stdev": 0,
        "count": 1
      },
      "comp_avg_confidence": {
        "mean": 0.881578947368421,
        "median": 0.881578947368421,
        "stdev": 0,
        "count": 1
      },
      "gold_compliance_score": {
        "mean": 0.6666666666666666,
        "median": 0.6666666666666666,
        "stdev": 0,
        "count": 1
      },
      "comp_compliance_score": {
        "mean": 0.6666666666666666,
        "median": 0.6666666666666666,
        "stdev": 0,
        "count": 1
      }
    }
  },
  "overall_metrics": {
    "mapping_jaccard_similarity": {
      "mean": 0.15587410957342238,
      "median": 0.10818713450292397,
      "stdev": 0.10807679100825203,
      "min": 0.03125,
      "max": 0.3611111111111111
    },
    "mapping_precision": {
      "mean": 0.2584629042604544,
      "median": 0.19047619047619047,
      "stdev": 0.16689156653027887,
      "min": 0.07692307692307693,
      "max": 0.5652173913043478
    },
    "mapping_recall": {
      "mean": 0.2755401844532279,
      "median": 0.2632850241545894,
      "stdev": 0.16728583584612478,
      "min": 0.043478260869565216,
      "max": 0.5
    },
    "mapping_f1_score": {
      "mean": 0.2566218037740594,
      "median": 0.19523809523809527,
      "stdev": 0.15596262435501884,
      "min": 0.06060606060606061,
      "max": 0.5306122448979592
    },
    "mapping_true_positives": {
      "mean": 4.5,
      "median": 3.0,
      "stdev": 3.8369548110737792,
      "min": 1,
      "max": 13
    },
    "mapping_false_positives": {
      "mean": 11.2,
      "median": 11.5,
      "stdev": 2.2010098692292237,
      "min": 8,
      "max": 16
    },
    "mapping_false_negatives": {
      "mean": 11.9,
      "median": 11.5,
      "stdev": 5.743595467030115,
      "min": 4,
      "max": 22
    },
    "gold_mappings_count": {
      "mean": 20.5,
      "median": 21.5,
      "stdev": 9.606132300659707,
      "min": 10,
      "max": 38
    },
    "comp_mappings_count": {
      "mean": 20.1,
      "median": 18.5,
      "stdev": 6.5226102477799826,
      "min": 12,
      "max": 32
    },
    "gold_avg_confidence": {
      "mean": 0.9470696148102469,
      "median": 0.953534226190476,
      "stdev": 0.04258781614749753,
      "min": 0.8772727272727273,
      "max": 1.0
    },
    "comp_avg_confidence": {
      "mean": 0.9255855191957166,
      "median": 0.9488095238095239,
      "stdev": 0.04174943977704944,
      "min": 0.8416666666666669,
      "max": 0.9636363636363636
    },
    "gold_compliance_score": {
      "mean": 0.4333333333333333,
      "median": 0.3333333333333333,
      "stdev": 0.16101529717988264,
      "min": 0.3333333333333333,
      "max": 0.6666666666666666
    },
    "comp_compliance_score": {
      "mean": 0.39999999999999997,
      "median": 0.3333333333333333,
      "stdev": 0.14054567378526128,
      "min": 0.3333333333333333,
      "max": 0.6666666666666666
    }
  }
}