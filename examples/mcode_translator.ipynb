{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ **Complete mCODE Translation Workflow**\n",
    "\n",
    "Transform clinical trial data into standardized mCODE format with AI optimization.\n",
    "\n",
    "**üéØ What you'll accomplish:**\n",
    "- Fetch real clinical trial data from ClinicalTrials.gov\n",
    "- Test all AI model combinations for optimal performance\n",
    "- Convert data to mCODE format\n",
    "- Generate summaries and store in CORE Memory\n",
    "\n",
    "**‚ö° Features:**\n",
    "- Concurrent processing with 8-15 workers\n",
    "- Dynamic model/prompt discovery\n",
    "- Cross-validation optimization\n",
    "- Real-time progress tracking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß **Step 1: Environment Setup**\n",
    "\n",
    "Configure your environment and API keys to get started.\n",
    "\n",
    "**üìã Prerequisites:**\n",
    "- Python environment with dependencies installed\n",
    "- API keys for LLM providers (OpenAI, DeepSeek, etc.)\n",
    "- Optional: CORE Memory API key for data storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure environment and API keys\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Change to project root directory\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == 'examples':\n",
    "    project_root = current_dir.parent\n",
    "    os.chdir(project_root)\n",
    "    print(f\"üìÅ Changed working directory to: {project_root}\")\n",
    "else:\n",
    "    project_root = current_dir\n",
    "# Add project root to Python path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    print(\"‚úÖ Added project root to Python path\")\n",
    "# Configure API keys (replace with your actual keys)\n",
    "os.environ['CLINICAL_TRIALS_API_KEY'] = 'your_clinical_trials_api_key_here'\n",
    "os.environ['COREAI_API_KEY'] = 'your_core_memory_api_key_here'\n",
    "print(\"‚úÖ API keys configured\")\n",
    "print(\"‚úÖ Environment ready\")\n",
    "print(f\"üìç Current working directory: {Path.cwd()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä **Step 2: Data Acquisition**\n",
    "\n",
    "Fetch clinical trial data and download synthetic patient records.\n",
    "\n",
    "**üéØ Goals:**\n",
    "- Get 5 breast cancer clinical trials from ClinicalTrials.gov\n",
    "- Download synthetic patient data archives\n",
    "- Prepare data for mCODE conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch 5 breast cancer clinical trials from ClinicalTrials.gov\n",
    "# This provides real-world treatment data for mCODE conversion\n",
    "# Using 8 concurrent workers for faster fetching\n",
    "!python -m src.cli.trials_fetcher --condition \"breast cancer\" --limit 5 --out raw_trials.ndjson --workers 8 --verbose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all available synthetic patient data archives\n",
    "# This provides comprehensive test data for the workflow\n",
    "!python -m scripts.download_data --all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üë• **Step 4: Fetch Synthetic Patient Data**\n",
    "\n",
    "Download synthetic patient records that mimic real breast cancer patients.\n",
    "\n",
    "**üõ°Ô∏è Why synthetic patients?** They protect patient privacy while providing realistic data for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch 5 synthetic breast cancer patients from the 10-year archive\n",
    "# These are artificially generated but realistic patient records\n",
    "!python -m src.cli.patients_fetcher --archive breast_cancer_10_years --limit 5 --out raw_patients.ndjson --verbose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ **Step 3: AI Model Optimization**\n",
    "\n",
    "Find the best AI model and prompt combination for your data.\n",
    "\n",
    "**üî¨ Process:**\n",
    "1. Discover all available models and prompts\n",
    "2. Test all combinations (8 models √ó 4 prompts = 32 tests)\n",
    "3. Use cross-validation for reliable results\n",
    "4. Save optimal configuration for production\n",
    "\n",
    "**‚ö° Performance:** 15 concurrent workers for maximum speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get available models and prompts dynamically\n",
    "# This demonstrates how to programmatically get the available options\n",
    "import subprocess\n",
    "import json\n",
    "# Get available models\n",
    "models_output = subprocess.run([\n",
    "    \"python\", \"-m\", \"src.cli.trials_optimizer\", \"--list-models\"\n",
    "], capture_output=True, text=True, cwd=\".\")\n",
    "# Get available prompts\n",
    "prompts_output = subprocess.run([\n",
    "    \"python\", \"-m\", \"src.cli.trials_optimizer\", \"--list-prompts\"\n",
    "], capture_output=True, text=True, cwd=\".\")\n",
    "# Parse the output to extract model and prompt names\n",
    "models_lines = models_output.stdout.strip().split('\\n')\n",
    "prompts_lines = prompts_output.stdout.strip().split('\\n')\n",
    "# Extract model names (skip the header line)\n",
    "AVAILABLE_MODELS = [line.split('‚Ä¢ ')[1] for line in models_lines if '‚Ä¢ ' in line]\n",
    "# Extract prompt names (skip the header line)\n",
    "AVAILABLE_PROMPTS = [line.split('‚Ä¢ ')[1] for line in prompts_lines if '‚Ä¢ ' in line]\n",
    "print(f\"ü§ñ Available models ({len(AVAILABLE_MODELS)}): {', '.join(AVAILABLE_MODELS)}\")\n",
    "print(f\"üìù Available prompts ({len(AVAILABLE_PROMPTS)}): {', '.join(AVAILABLE_PROMPTS)}\")\n",
    "# Create comma-separated strings for command-line usage\n",
    "MODELS_STR = ','.join(AVAILABLE_MODELS)\n",
    "PROMPTS_STR = ','.join(AVAILABLE_PROMPTS)\n",
    "print(f\"\\nüìã Command-ready strings:\")\n",
    "print(f\"   Models: {MODELS_STR}\")\n",
    "print(f\"   Prompts: {PROMPTS_STR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Demo: List all available models\n",
    "!python -m src.cli.trials_optimizer --list-models\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Demo: List all available prompts\n",
    "!python -m src.cli.trials_optimizer --list-prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Full optimization using ALL available models and prompts\n",
    "# This tests all combinations: 8 models √ó 4 prompts = 32 total combinations\n",
    "# The optimizer only works with files, never uses APIs directly\n",
    "# Using 15 concurrent workers for maximum speed\n",
    "!python -m src.cli.trials_optimizer --trials-file raw_trials.ndjson --cv-folds 3 --prompts direct_mcode_evidence_based_concise,direct_mcode_evidence_based,direct_mcode_minimal,direct_mcode_structured --models deepseek-coder,deepseek-chat,deepseek-reasoner,gpt-4-turbo,gpt-4o,gpt-4o-mini,gpt-3.5-turbo,claude-3 --max-combinations 0 --save-config optimal_config.json --workers 15 --verbose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a: Load Optimal Configuration\n",
    "\n",
    "Read the optimization results and store the best model/prompt combination for later use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the optimal AI configuration found by the optimizer\n",
    "import json\n",
    "from pathlib import Path\n",
    "config_file = Path('optimal_config.json')\n",
    "if config_file.exists():\n",
    "    with open(config_file, 'r') as f:\n",
    "        optimal_config = json.load(f)\n",
    "    # Store the best settings for use in later steps\n",
    "    BEST_MODEL = optimal_config['optimal_settings']['model']\n",
    "    BEST_PROMPT = optimal_config['optimal_settings']['prompt']\n",
    "    print(f\"üéØ Optimal configuration:\")\n",
    "    print(f\"   Model: {BEST_MODEL}\")\n",
    "    print(f\"   Prompt: {BEST_PROMPT}\")\n",
    "    print(f\"   CV score: {optimal_config['optimal_settings']['cv_score']:.3f}\")\n",
    "else:\n",
    "    # Fallback to defaults if optimization failed\n",
    "    BEST_MODEL = 'deepseek-coder'\n",
    "    BEST_PROMPT = 'direct_mcode_evidence_based_concise'\n",
    "    print(\"‚ö†Ô∏è  Using default configuration (optimization may have failed)\")\n",
    "    print(f\"   Model: {BEST_MODEL}\")\n",
    "    print(f\"   Prompt: {BEST_PROMPT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è **Step 4: Data Processing**\n",
    "\n",
    "Convert raw clinical data to standardized mCODE format.\n",
    "\n",
    "**üîÑ Transformations:**\n",
    "- Clinical trials ‚Üí mCODE format\n",
    "- Patient records ‚Üí mCODE format\n",
    "- Apply optimal AI model configuration\n",
    "\n",
    "**‚ö° Performance:** 12 concurrent workers for efficient processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw trial data to mCODE format using the best AI model\n",
    "# This structures the trial information according to mCODE standards\n",
    "# Using 12 concurrent workers for faster processing\n",
    "!python -m src.cli.trials_processor raw_trials.ndjson --out mcode_trials.ndjson --model {BEST_MODEL} --prompt {BEST_PROMPT} --workers 12 --verbose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üë®‚Äç‚öïÔ∏è **Step 7: Process Patients to mCODE Format**\n",
    "\n",
    "Convert raw patient data to structured mCODE format.\n",
    "\n",
    "**üìã Patient processing** focuses on individual medical histories, diagnoses, and treatments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw patient data to mCODE format\n",
    "# This structures patient medical histories according to mCODE standards\n",
    "# Using 12 concurrent workers for faster processing\n",
    "!python -m src.cli.patients_processor --in raw_patients.ndjson --out mcode_patients.ndjson --workers 12 --verbose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù **Step 5: Generate Summaries & Store**\n",
    "\n",
    "Create human-readable summaries and store everything permanently.\n",
    "\n",
    "**üìã Outputs:**\n",
    "- Readable summaries of all processed data\n",
    "- Permanent storage in CORE Memory\n",
    "- Searchable clinical information database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate human-readable summaries of the mCODE trial data\n",
    "# Store summaries in CORE Memory for permanent access and search\n",
    "!python -m src.cli.trials_summarizer --in mcode_trials.ndjson --model {BEST_MODEL} --ingest --verbose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate human-readable summaries of the mCODE patient data\n",
    "# Store summaries in CORE Memory for permanent access and search\n",
    "!python -m src.cli.patients_summarizer --in mcode_patients.ndjson --ingest --verbose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ **Step 6: Verify Results**\n",
    "\n",
    "Check that everything worked correctly and celebrate success!\n",
    "\n",
    "**üìä Validation:**\n",
    "- Confirm all files were created\n",
    "- Verify data integrity\n",
    "- Check processing statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which files were created and their sizes\n",
    "import os\n",
    "from pathlib import Path\n",
    "files_to_check = [\n",
    "    'optimal_config.json',\n",
    "    'raw_trials.ndjson',\n",
    "    'raw_patients.ndjson',\n",
    "    'mcode_trials.ndjson',\n",
    "    'mcode_patients.ndjson'\n",
    "]\n",
    "print(\"üìÅ Generated files:\")\n",
    "for filename in files_to_check:\n",
    "    file_path = Path(filename)\n",
    "    if file_path.exists():\n",
    "        size = file_path.stat().st_size\n",
    "        print(f\"   ‚úÖ {filename} ({size} bytes)\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {filename} (not found)\")\n",
    "print(\"\\nüéâ mCODE translation workflow completed!\")\n",
    "print(\"All data has been processed and stored in CORE Memory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ **Workflow Complete!**\n",
    "\n",
    "You've successfully transformed clinical trial data into standardized mCODE format!\n",
    "\n",
    "**üèÜ Achievements:**\n",
    "- ‚úÖ Fetched clinical trial data\n",
    "- ‚úÖ Optimized AI model performance\n",
    "- ‚úÖ Converted to mCODE format\n",
    "- ‚úÖ Generated readable summaries\n",
    "- ‚úÖ Stored in CORE Memory\n",
    "\n",
    "**üöÄ Next Steps:**\n",
    "- Explore your processed mCODE data\n",
    "- Search CORE Memory for specific information\n",
    "- Run with different conditions or datasets\n",
    "- Integrate with other clinical systems\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}