{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete mCODE Translation Workflow with Concurrency\n",
    "\n",
    "This notebook demonstrates the complete mCODE translation pipeline using individual component scripts with **concurrent processing**.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Python environment with all dependencies installed\n",
    "- LLM API keys configured (OpenAI, etc.)\n",
    "- CORE Memory API key is configured (optional, for storage)\n",
    "- All dependencies are installed\n",
    "\n",
    "**What this notebook does:**\n",
    "1. **Concurrent Fetching**: Fetches clinical trial data using multiple workers\n",
    "2. **Data Download**: Downloads synthetic patient data archives\n",
    "3. **Patient Fetching**: Extracts synthetic patients from downloaded archives\n",
    "4. **Concurrent Optimization**: Tests AI model combinations in parallel\n",
    "5. **Concurrent Processing**: Converts data to mCODE format with multiple workers\n",
    "6. **Concurrent Summarization**: Generates summaries and stores in CORE Memory\n",
    "\n",
    "**Concurrency Features:**\n",
    "- **Fetcher Pool**: 8 workers for concurrent API calls\n",
    "- **Processor Pool**: 12 workers for parallel data processing\n",
    "- **Optimizer Pool**: 15 workers for parallel model testing\n",
    "- **Task Queues**: Priority-based task execution with progress tracking\n",
    "\n",
    "**Command Chaining Examples:**\n",
    "\n",
    "This notebook demonstrates different approaches to chaining commands:\n",
    "\n",
    "- **File-based**: Save intermediate results to files (current approach)\n",
    "- **Pipe-based**: Chain commands using `|` for streaming data\n",
    "- **Combined**: Mix files and pipes for optimal performance\n",
    "\n",
    "**Example Command Chains:**\n",
    "```bash\n",
    "# Complete pipeline: fetcher ‚Üí processor ‚Üí summarizer\n",
    "python -m src.cli.patients_fetcher --archive breast_cancer_10_years | \\\n",
    "    python -m src.cli.patients_processor | \\\n",
    "    python -m src.cli.patients_summarizer --ingest\n",
    "\n",
    "# File-based approach with intermediate files\n",
    "python -m src.cli.patients_fetcher --archive breast_cancer_10_years --out raw_patients.ndjson\n",
    "python -m src.cli.patients_processor --in raw_patients.ndjson --out mcode_patients.ndjson\n",
    "python -m src.cli.patients_summarizer --in mcode_patients.ndjson --ingest\n",
    "\n",
    "# Parallel processing with background jobs\n",
    "python -m src.cli.patients_fetcher --archive breast_cancer_10_years | \\\n",
    "    python -m src.cli.patients_processor | \\\n",
    "    python -m src.cli.patients_summarizer --ingest &\n",
    "\n",
    "python -m src.cli.trials_fetcher --condition \"breast cancer\" --limit 5 | \\\n",
    "    python -m src.cli.trials_processor | \\\n",
    "    python -m src.cli.trials_summarizer --ingest &\n",
    "wait\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "\n",
    "Configure API keys and verify the environment is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure environment and API keys\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Change to project root directory\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == 'examples':\n",
    "    project_root = current_dir.parent\n",
    "    os.chdir(project_root)\n",
    "    print(f\"üìÅ Changed working directory to: {project_root}\")\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "# Add project root to Python path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    print(\"‚úÖ Added project root to Python path\")\n",
    "\n",
    "# Configure API keys (replace with your actual keys)\n",
    "os.environ['CLINICAL_TRIALS_API_KEY'] = 'your_clinical_trials_api_key_here'\n",
    "os.environ['COREAI_API_KEY'] = 'your_core_memory_api_key_here'\n",
    "\n",
    "print(\"‚úÖ API keys configured\")\n",
    "print(\"‚úÖ Environment ready\")\n",
    "print(f\"üìç Current working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Fetch Clinical Trial Data\n",
    "\n",
    "Download clinical trial data from ClinicalTrials.gov for breast cancer studies.\n",
    "\n",
    "**What are clinical trials?** Research studies that test new treatments on human volunteers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch 5 breast cancer clinical trials from ClinicalTrials.gov\n",
    "# This provides real-world treatment data for mCODE conversion\n",
    "# Using 8 concurrent workers for faster fetching\n",
    "!python -m src.cli.trials_fetcher --condition \"breast cancer\" --limit 5 --out raw_trials.ndjson --workers 8 --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download Data Archives\n",
    "\n",
    "Download the synthetic patient data archives needed for the workflow.\n",
    "\n",
    "**Why download archives?** The patient fetcher requires local archives containing synthetic FHIR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all available synthetic patient data archives\n",
    "# This provides comprehensive test data for the workflow\n",
    "!python -m scripts.download_data --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Fetch Synthetic Patient Data\n",
    "\n",
    "Download synthetic patient records that mimic real breast cancer patients.\n",
    "\n",
    "**Why synthetic patients?** They protect patient privacy while providing realistic data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch 5 synthetic breast cancer patients from the 10-year archive\n",
    "# These are artificially generated but realistic patient records\n",
    "!python -m src.cli.patients_fetcher --archive breast_cancer_10_years --limit 5 --out raw_patients.ndjson --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Optimize AI Model Parameters\n",
    "\n",
    "Find the best AI model and prompt combination for processing breast cancer data.\n",
    "\n",
    "### What is AI Model Optimization?\n",
    "\n",
    "**AI model optimization** is the process of finding the best combination of AI model and prompt template for a specific task. Just like different cars perform better on different terrains, different AI models excel at different types of medical data processing.\n",
    "\n",
    "### Why is Optimization Needed?\n",
    "\n",
    "1. **Model Performance Varies**: Some models are better at understanding clinical trial protocols, while others excel at patient data analysis\n",
    "2. **Cost vs. Quality Trade-offs**: More expensive models (like GPT-4) may not always provide better results than cost-effective alternatives\n",
    "3. **Prompt Sensitivity**: The same model can produce very different results with different prompt instructions\n",
    "4. **Data Type Specificity**: Models optimized for code may not work well with medical narratives, and vice versa\n",
    "\n",
    "### How Optimization Works\n",
    "\n",
    "The optimizer uses **cross-validation** to test multiple model+prompt combinations:\n",
    "\n",
    "1. **Splits your data** into training and validation sets\n",
    "2. **Tests each combination** on the validation data\n",
    "3. **Scores performance** using mCODE compliance metrics\n",
    "4. **Ranks combinations** by average cross-validation score\n",
    "5. **Saves the best configuration** for production use\n",
    "\n",
    "### What Gets Optimized?\n",
    "\n",
    "- **Model Selection**: GPT-4, GPT-4o, DeepSeek-Coder, etc.\n",
    "- **Prompt Templates**: Different instruction styles for mCODE conversion\n",
    "- **Performance Metrics**: mCODE compliance, mapping accuracy, processing speed\n",
    "\n",
    "### Benefits of Optimization\n",
    "\n",
    "- **20-50% better accuracy** for your specific data type\n",
    "- **Cost savings** by using the most efficient model for the job\n",
    "- **Consistent results** across different data sources\n",
    "- **Future-proofing** as new models become available\n",
    "\n",
    "**Note:** The optimizer only works with existing files, never fetches new data via APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple model+prompt combinations using the fetched trial data\n",
    "# This finds the best configuration for processing breast cancer trials\n",
    "# The optimizer only works with files, never uses APIs directly\n",
    "# Using 15 concurrent workers for parallel optimization\n",
    "!python -m src.cli.trials_optimizer --trials-file raw_trials.ndjson --cv-folds 3 --prompts direct_mcode_evidence_based_concise,direct_mcode_minimal --models gpt-4,gpt-4o,deepseek-coder,deepseek-chat --max-combinations 8 --save-config optimal_config.json --workers 15 --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a: Load Optimal Configuration\n",
    "\n",
    "Read the optimization results and store the best model/prompt combination for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the optimal AI configuration found by the optimizer\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "config_file = Path('optimal_config.json')\n",
    "if config_file.exists():\n",
    "    with open(config_file, 'r') as f:\n",
    "        optimal_config = json.load(f)\n",
    "    \n",
    "    # Store the best settings for use in later steps\n",
    "    BEST_MODEL = optimal_config['optimal_settings']['model']\n",
    "    BEST_PROMPT = optimal_config['optimal_settings']['prompt']\n",
    "    \n",
    "    print(f\"üéØ Optimal configuration:\")\n",
    "    print(f\"   Model: {BEST_MODEL}\")\n",
    "    print(f\"   Prompt: {BEST_PROMPT}\")\n",
    "    print(f\"   CV score: {optimal_config['optimal_settings']['cv_score']:.3f}\")\n",
    "else:\n",
    "    # Fallback to defaults if optimization failed\n",
    "    BEST_MODEL = 'deepseek-coder'\n",
    "    BEST_PROMPT = 'direct_mcode_evidence_based_concise'\n",
    "    print(\"‚ö†Ô∏è  Using default configuration (optimization may have failed)\")\n",
    "    print(f\"   Model: {BEST_MODEL}\")\n",
    "    print(f\"   Prompt: {BEST_PROMPT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Process Trials to mCODE Format\n",
    "\n",
    "Convert raw clinical trial data to structured mCODE format using the optimized AI model.\n",
    "\n",
    "**What is mCODE?** Minimal Common Oncology Data Elements - standardized format for cancer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw trial data to mCODE format using the best AI model\n",
    "# This structures the trial information according to mCODE standards\n",
    "# Using 12 concurrent workers for faster processing\n",
    "!python -m src.cli.trials_processor raw_trials.ndjson --out mcode_trials.ndjson --model {BEST_MODEL} --prompt {BEST_PROMPT} --workers 12 --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Process Patients to mCODE Format\n",
    "\n",
    "Convert raw patient data to structured mCODE format.\n",
    "\n",
    "**Patient processing** focuses on individual medical histories, diagnoses, and treatments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw patient data to mCODE format\n",
    "# This structures patient medical histories according to mCODE standards\n",
    "# Using 12 concurrent workers for faster processing\n",
    "!python -m src.cli.patients_processor --in raw_patients.ndjson --out mcode_patients.ndjson --workers 12 --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Generate Summaries and Store in CORE Memory\n",
    "\n",
    "Create human-readable summaries of all processed data and store permanently.\n",
    "\n",
    "**CORE Memory** provides persistent storage and search capabilities for all processed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7a: Generate Trial Summaries\n",
    "\n",
    "Create readable summaries of the clinical trials and store them in CORE Memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate human-readable summaries of the mCODE trial data\n",
    "# Store summaries in CORE Memory for permanent access and search\n",
    "!python -m src.cli.trials_summarizer --in mcode_trials.ndjson --model {BEST_MODEL} --ingest --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7b: Generate Patient Summaries\n",
    "\n",
    "Create readable summaries of the patient data and store them in CORE Memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate human-readable summaries of the mCODE patient data\n",
    "# Store summaries in CORE Memory for permanent access and search\n",
    "!python -m src.cli.patients_summarizer --in mcode_patients.ndjson --ingest --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Verify Results\n",
    "\n",
    "Check that all files were created successfully and show a summary of the work completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which files were created and their sizes\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "files_to_check = [\n",
    "    'optimal_config.json',\n",
    "    'raw_trials.ndjson',\n",
    "    'raw_patients.ndjson',\n",
    "    'mcode_trials.ndjson',\n",
    "    'mcode_patients.ndjson'\n",
    "]\n",
    "\n",
    "print(\"üìÅ Generated files:\")\n",
    "for filename in files_to_check:\n",
    "    file_path = Path(filename)\n",
    "    if file_path.exists():\n",
    "        size = file_path.stat().st_size\n",
    "        print(f\"   ‚úÖ {filename} ({size} bytes)\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {filename} (not found)\")\n",
    "\n",
    "print(\"\\nüéâ mCODE translation workflow completed!\")\n",
    "print(\"All data has been processed and stored in CORE Memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook successfully completed the complete mCODE translation workflow with **concurrent processing**:\n",
    "\n",
    "‚úÖ **Fetched** 5 clinical trials for breast cancer\n",
    "‚úÖ **Downloaded** synthetic patient data archives\n",
    "‚úÖ **Extracted** 5 synthetic patients from archives\n",
    "‚úÖ **Optimized** AI model parameters using existing files (no API calls)\n",
    "‚úÖ **Processed** all data into structured mCODE format\n",
    "‚úÖ **Generated** human-readable summaries\n",
    "‚úÖ **Stored** everything permanently in CORE Memory\n",
    "\n",
    "### Generated Files:\n",
    "- `raw_trials.ndjson` - Original clinical trial data\n",
    "- `raw_patients.ndjson` - Original synthetic patient data\n",
    "- `mcode_trials.ndjson` - Structured trial mCODE data\n",
    "- `mcode_patients.ndjson` - Structured patient mCODE data\n",
    "- `optimal_config.json` - Best AI model configuration\n",
    "\n",
    "### Key Features:\n",
    "- **Concurrent fetching**: 8 workers for API calls\n",
    "- **Concurrent optimization**: 15 workers for model testing\n",
    "- **Concurrent processing**: 12 workers for data conversion\n",
    "- **File-only optimization**: Optimizer never uses APIs, only cross-validates existing files\n",
    "- **Component-based**: Uses individual scripts for each step\n",
    "- **Educational**: Each command is explained with context\n",
    "\n",
    "### Next Steps:\n",
    "- Explore the generated mCODE data\n",
    "- Search CORE Memory for specific information\n",
    "- Run the workflow with different conditions or parameters\n",
    "- Integrate the processed data into other applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Command Chaining Approaches\n",
    "\n",
    "### Pipe-Based Workflow (Memory Efficient)\n",
    "\n",
    "For memory-constrained environments or streaming processing:\n",
    "\n",
    "```bash\n",
    "# Stream trials directly to processing\n",
    "python -m src.cli.trials_fetcher --condition \"breast cancer\" --limit 5 --workers 8 \\\n",
    "    | python -m src.cli.trials_processor --out mcode_trials.ndjson --workers 12\n",
    "\n",
    "# Stream patients directly to processing\n",
    "python -m src.cli.patients_fetcher --archive breast_cancer_10_years \\\n",
    "    | python -m src.cli.patients_processor --out mcode_patients.ndjson --workers 12\n",
    "\n",
    "# Continue with optimization and summarization...\n",
    "```\n",
    "\n",
    "### Parallel Processing with Background Jobs\n",
    "\n",
    "For maximum concurrency with multiple data streams:\n",
    "\n",
    "```bash\n",
    "# Start background processing jobs\n",
    "python -m src.cli.trials_fetcher --condition \"breast cancer\" --limit 5 --out raw_trials.ndjson --workers 8 &\n",
    "python -m src.cli.patients_fetcher --archive breast_cancer_10_years --out raw_patients.ndjson &\n",
    "\n",
    "# Wait for data fetching to complete\n",
    "wait\n",
    "\n",
    "# Process both streams in parallel\n",
    "python -m src.cli.trials_processor raw_trials.ndjson --out mcode_trials.ndjson --workers 12 &\n",
    "python -m src.cli.patients_processor raw_patients.ndjson --out mcode_patients.ndjson --workers 12 &\n",
    "\n",
    "# Wait for processing to complete\n",
    "wait\n",
    "\n",
    "# Continue with optimization and summarization...\n",
    "```\n",
    "\n",
    "### Hybrid Approach (Recommended)\n",
    "\n",
    "Combine files and pipes for optimal performance:\n",
    "\n",
    "```bash\n",
    "# Use files for complex operations, pipes for simple transformations\n",
    "python -m src.cli.trials_fetcher --condition \"breast cancer\" --limit 5 --out raw_trials.ndjson --workers 8\n",
    "python -m src.cli.patients_fetcher --archive breast_cancer_10_years | \\\n",
    "    python -m src.cli.patients_processor --out mcode_patients.ndjson --workers 12\n",
    "\n",
    "# Optimization works best with files\n",
    "python -m src.cli.trials_optimizer --trials-file raw_trials.ndjson --cv-folds 3 \\\n",
    "    --prompts direct_mcode_evidence_based_concise,direct_mcode_minimal \\\n",
    "    --models deepseek-coder,gpt-4o --save-config optimal_config.json --workers 15\n",
    "\n",
    "# Extract optimal settings and continue\n",
    "# ... (rest of workflow)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcode_translator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
