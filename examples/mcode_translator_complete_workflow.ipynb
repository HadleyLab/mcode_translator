{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete mCODE Translation Workflow with Concurrency\n",
    "\n",
    "This notebook demonstrates the complete mCODE translation pipeline using individual component scripts with **concurrent processing**.\n",
    "\n",
    "**Prerequisites:**\n",
    "- mcode_translator conda environment is active in the notebook kernel\n",
    "- API keys are configured (ClinicalTrials.gov and CORE Memory)\n",
    "- All dependencies are installed\n",
    "\n",
    "**What this notebook does:**\n",
    "1. **Concurrent Fetching**: Fetches clinical trial and patient data using multiple workers\n",
    "2. **Concurrent Optimization**: Tests AI model combinations in parallel\n",
    "3. **Concurrent Processing**: Converts data to mCODE format with multiple workers\n",
    "4. **Concurrent Summarization**: Generates summaries and stores in CORE Memory\n",
    "\n",
    "**Concurrency Features:**\n",
    "- **Fetcher Pool**: 4 workers for concurrent API calls\n",
    "- **Processor Pool**: 8 workers for parallel data processing\n",
    "- **Optimizer Pool**: 2 workers for parallel model testing\n",
    "- **Task Queues**: Priority-based task execution with progress tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "\n",
    "Configure API keys and verify the environment is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure environment and API keys\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Change to project root directory\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == 'examples':\n",
    "    project_root = current_dir.parent\n",
    "    os.chdir(project_root)\n",
    "    print(f\"üìÅ Changed working directory to: {project_root}\")\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "# Add project root to Python path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    print(\"‚úÖ Added project root to Python path\")\n",
    "\n",
    "# Configure API keys (replace with your actual keys)\n",
    "os.environ['CLINICAL_TRIALS_API_KEY'] = 'your_clinical_trials_api_key_here'\n",
    "os.environ['COREAI_API_KEY'] = 'your_core_memory_api_key_here'\n",
    "\n",
    "print(\"‚úÖ API keys configured\")\n",
    "print(\"‚úÖ Environment ready\")\n",
    "print(f\"üìç Current working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Fetch Clinical Trial Data\n",
    "\n",
    "Download clinical trial data from ClinicalTrials.gov for breast cancer studies.\n",
    "\n",
    "**What are clinical trials?** Research studies that test new treatments on human volunteers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch 5 breast cancer clinical trials from ClinicalTrials.gov\n",
    "# This provides real-world treatment data for mCODE conversion\n",
    "# Using 4 concurrent workers for faster fetching\n",
    "!python -m src.cli.trials_fetcher --condition \"breast cancer\" --limit 5 --out raw_trials.ndjson --workers 4 --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Fetch Synthetic Patient Data\n",
    "\n",
    "Download synthetic patient records that mimic real breast cancer patients.\n",
    "\n",
    "**Why synthetic patients?** They protect patient privacy while providing realistic data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch 5 synthetic breast cancer patients from the 10-year archive\n",
    "# These are artificially generated but realistic patient records\n",
    "!python -m src.cli.patients_fetcher --archive breast_cancer_10_years --limit 5 --out raw_patients.ndjson --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Optimize AI Model Parameters\n",
    "\n",
    "Find the best AI model and prompt combination for processing breast cancer data.\n",
    "\n",
    "**Why optimize?** Different AI models work better with different types of medical data.\n",
    "\n",
    "**Note:** The optimizer only works with existing files, never fetches new data via APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3 different model+prompt combinations using the fetched trial data\n",
    "# This finds the best configuration for processing breast cancer trials\n",
    "# The optimizer only works with files, never uses APIs directly\n",
    "# Using 2 concurrent workers for parallel optimization\n",
    "!python -m src.cli.trials_optimizer --trials-file raw_trials.ndjson --cv-folds 3 --max-combinations 3 --save-config optimal_config.json --workers 2 --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a: Load Optimal Configuration\n",
    "\n",
    "Read the optimization results and store the best model/prompt combination for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the optimal AI configuration found by the optimizer\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "config_file = Path('optimal_config.json')\n",
    "if config_file.exists():\n",
    "    with open(config_file, 'r') as f:\n",
    "        optimal_config = json.load(f)\n",
    "    \n",
    "    # Store the best settings for use in later steps\n",
    "    BEST_MODEL = optimal_config['optimal_settings']['model']\n",
    "    BEST_PROMPT = optimal_config['optimal_settings']['prompt']\n",
    "    \n",
    "    print(f\"üéØ Optimal configuration:\")\n",
    "    print(f\"   Model: {BEST_MODEL}\")\n",
    "    print(f\"   Prompt: {BEST_PROMPT}\")\n",
    "    print(f\"   CV score: {optimal_config['optimal_settings']['cv_score']:.3f}\")\n",
    "else:\n",
    "    # Fallback to defaults if optimization failed\n",
    "    BEST_MODEL = 'deepseek-coder'\n",
    "    BEST_PROMPT = 'direct_mcode_evidence_based_concise'\n",
    "    print(\"‚ö†Ô∏è  Using default configuration (optimization may have failed)\")\n",
    "    print(f\"   Model: {BEST_MODEL}\")\n",
    "    print(f\"   Prompt: {BEST_PROMPT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Process Trials to mCODE Format\n",
    "\n",
    "Convert raw clinical trial data to structured mCODE format using the optimized AI model.\n",
    "\n",
    "**What is mCODE?** Minimal Common Oncology Data Elements - standardized format for cancer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw trial data to mCODE format using the best AI model\n",
    "# This structures the trial information according to mCODE standards\n",
    "# Using 8 concurrent workers for faster processing\n",
    "!python -m src.cli.trials_processor raw_trials.ndjson --out mcode_trials.ndjson --model {BEST_MODEL} --prompt {BEST_PROMPT} --workers 8 --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Process Patients to mCODE Format\n",
    "\n",
    "Convert raw patient data to structured mCODE format.\n",
    "\n",
    "**Patient processing** focuses on individual medical histories, diagnoses, and treatments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw patient data to mCODE format\n",
    "# This structures patient medical histories according to mCODE standards\n",
    "# Using 8 concurrent workers for faster processing\n",
    "!python -m src.cli.patients_processor --in raw_patients.ndjson --out mcode_patients.ndjson --workers 8 --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Generate Summaries and Store in CORE Memory\n",
    "\n",
    "Create human-readable summaries of all processed data and store permanently.\n",
    "\n",
    "**CORE Memory** provides persistent storage and search capabilities for all processed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7a: Generate Trial Summaries\n",
    "\n",
    "Create readable summaries of the clinical trials and store them in CORE Memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate human-readable summaries of the mCODE trial data\n",
    "# Store summaries in CORE Memory for permanent access and search\n",
    "!python -m src.cli.trials_summarizer --in mcode_trials.ndjson --model {BEST_MODEL} --ingest --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7b: Generate Patient Summaries\n",
    "\n",
    "Create readable summaries of the patient data and store them in CORE Memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate human-readable summaries of the mCODE patient data\n",
    "# Store summaries in CORE Memory for permanent access and search\n",
    "!python -m src.cli.patients_summarizer --in mcode_patients.ndjson --ingest --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Verify Results\n",
    "\n",
    "Check that all files were created successfully and show a summary of the work completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which files were created and their sizes\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "files_to_check = [\n",
    "    'optimal_config.json',\n",
    "    'raw_trials.ndjson',\n",
    "    'raw_patients.ndjson',\n",
    "    'mcode_trials.ndjson',\n",
    "    'mcode_patients.ndjson'\n",
    "]\n",
    "\n",
    "print(\"üìÅ Generated files:\")\n",
    "for filename in files_to_check:\n",
    "    file_path = Path(filename)\n",
    "    if file_path.exists():\n",
    "        size = file_path.stat().st_size\n",
    "        print(f\"   ‚úÖ {filename} ({size} bytes)\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {filename} (not found)\")\n",
    "\n",
    "print(\"\\nüéâ mCODE translation workflow completed!\")\n",
    "print(\"All data has been processed and stored in CORE Memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook successfully completed the complete mCODE translation workflow with **concurrent processing**:\n",
    "\n",
    "‚úÖ **Fetched** 5 clinical trials and 5 synthetic patients for breast cancer\n",
    "‚úÖ **Optimized** AI model parameters using existing files (no API calls)\n",
    "‚úÖ **Processed** all data into structured mCODE format\n",
    "‚úÖ **Generated** human-readable summaries\n",
    "‚úÖ **Stored** everything permanently in CORE Memory\n",
    "\n",
    "### Generated Files:\n",
    "- `raw_trials.ndjson` - Original clinical trial data\n",
    "- `raw_patients.ndjson` - Original synthetic patient data\n",
    "- `mcode_trials.ndjson` - Structured trial mCODE data\n",
    "- `mcode_patients.ndjson` - Structured patient mCODE data\n",
    "- `optimal_config.json` - Best AI model configuration\n",
    "\n",
    "### Key Features:\n",
    "- **Concurrent fetching**: 4 workers for API calls\n",
    "- **Concurrent optimization**: 2 workers for model testing\n",
    "- **Concurrent processing**: 8 workers for data conversion\n",
    "- **File-only optimization**: Optimizer never uses APIs, only cross-validates existing files\n",
    "- **Component-based**: Uses individual scripts for each step\n",
    "- **Educational**: Each command is explained with context\n",
    "\n",
    "### Next Steps:\n",
    "- Explore the generated mCODE data\n",
    "- Search CORE Memory for specific information\n",
    "- Run the workflow with different conditions or parameters\n",
    "- Integrate the processed data into other applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcode_translator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
