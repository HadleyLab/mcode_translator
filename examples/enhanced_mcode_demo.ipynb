{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Enhanced mCODE Translator Demo\n",
    "\n",
    "**Transform clinical trial data into standardized mCODE elements with AI-powered precision**\n",
    "\n",
    "This enhanced notebook demonstrates advanced features of the mCODE Translator framework:\n",
    "- **Concurrent Processing**: Multi-worker processing for improved performance\n",
    "- **Optimized Prompts**: Breast cancer-specific prompt optimization\n",
    "- **CORE Memory Integration**: Direct storage of patient and trial summaries\n",
    "- **Process Management**: Advanced monitoring and control techniques\n",
    "- **Native IPython Commands**: Streamlined execution using `!python` magic\n",
    "\n",
    "## ðŸŽ¯ What is mCODE?\n",
    "\n",
    "mCODE (Minimal Common Oncology Data Elements) is a standardized data model that enables:\n",
    "- **Interoperability**: Consistent representation of cancer data across healthcare systems\n",
    "- **Research**: Facilitates clinical trial matching and patient recruitment\n",
    "- **Analytics**: Enables advanced analysis of cancer treatment patterns\n",
    "- **AI Integration**: Provides structured data for machine learning applications\n",
    "\n",
    "## ðŸ“‹ Prerequisites\n",
    "\n",
    "- Python 3.10+ in mcode_translator conda environment\n",
    "- ClinicalTrials.gov API key (optional for demo)\n",
    "- CORE Memory API key (optional for demo)\n",
    "- Internet connection for data fetching\n",
    "\n",
    "## ðŸ—ï¸ Enhanced Pipeline Overview\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Fetch Data    â”‚ -> â”‚   Process with   â”‚ -> â”‚  Store Results  â”‚\n",
    "â”‚  (Concurrent)   â”‚    â”‚   AI & mCODE     â”‚    â”‚                 â”‚\n",
    "â”‚ â€¢ Multi-worker  â”‚    â”‚ â€¢ Optimized      â”‚    â”‚ â€¢ CORE Memory   â”‚\n",
    "â”‚   Processing    â”‚    â”‚   Prompts        â”‚    â”‚ â€¢ Summaries     â”‚\n",
    "â”‚ â€¢ Breast Cancer â”‚    â”‚ â€¢ Concurrent     â”‚    â”‚ â€¢ Searchable    â”‚\n",
    "â”‚   Optimized     â”‚    â”‚   Workers        â”‚    â”‚ â€¢ Persistent    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## ðŸ“Š Expected Outcomes\n",
    "\n",
    "By the end of this notebook, you will have:\n",
    "- Processed clinical trial data with optimized breast cancer prompts\n",
    "- Utilized concurrent processing for improved performance\n",
    "- Stored patient and trial summaries directly in CORE Memory\n",
    "- Demonstrated advanced process management techniques\n",
    "- Visualized key insights from the enhanced processing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ Setup and Environment Configuration\n",
    "\n",
    "First, let's set up the environment and verify our configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup and imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# Add project root to path\n",
    "current_dir = Path.cwd()\n",
    "PROJECT_ROOT = current_dir.parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Working directory: {current_dir}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "# Set up environment variables (replace with your actual keys)\n",
    "os.environ['CLINICAL_TRIALS_API_KEY'] = 'your_clinical_trials_key_here'\n",
    "os.environ['COREAI_API_KEY'] = 'your_core_memory_key_here'\n",
    "\n",
    "# Verify environment\n",
    "core_api_key = os.getenv('COREAI_API_KEY')\n",
    "if core_api_key:\n",
    "    print(\"âœ… CORE API key configured\")\n",
    "else:\n",
    "    print(\"âš ï¸  CORE API key not configured - some features will be limited\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Step 1: Fetch Clinical Trial Data with Concurrency\n",
    "\n",
    "Let's fetch clinical trial data using concurrent processing for improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch clinical trials data with concurrent processing\n",
    "# Using IPython magic commands for streamlined execution\n",
    "\n",
    "print(\"ðŸš€ Fetching clinical trials with concurrent processing (4 workers)...\")\n",
    "\n",
    "# Use IPython magic for shell commands - more concise and native to Jupyter\n",
    "!cd {PROJECT_ROOT} && python -m src.cli.trials_fetcher --condition \"breast cancer\" --limit 5 --output examples/demo_trials_raw.json --workers 4 --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the fetched trial data\n",
    "\n",
    "trials_file = PROJECT_ROOT / \"examples\" / \"demo_trials_raw.json\"\n",
    "\n",
    "if trials_file.exists():\n",
    "    with open(trials_file, 'r') as f:\n",
    "        trials_raw = json.load(f)\n",
    "    \n",
    "    print(f\"ðŸ“Š Fetched {len(trials_raw)} clinical trials\")\n",
    "    \n",
    "    # Display sample trial information\n",
    "    if trials_raw:\n",
    "        trial = trials_raw[0]\n",
    "        print(\"\\nðŸ“‹ Sample Trial:\")\n",
    "        print(f\"NCT ID: {trial.get('protocolSection', {}).get('identificationModule', {}).get('nctId')}\")\n",
    "        print(f\"Title: {trial.get('protocolSection', {}).get('identificationModule', {}).get('briefTitle', 'N/A')[:100]}...\")\n",
    "        conditions = trial.get('protocolSection', {}).get('conditionsModule', {}).get('conditions', [])\n",
    "        print(f\"Conditions: {conditions}\")\n",
    "        \n",
    "        # Show data structure\n",
    "        print(f\"\\nðŸ” Raw data structure:\")\n",
    "        print(f\"Top-level keys: {list(trial.keys())}\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ Trial data file not found\")\n",
    "    trials_raw = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§ª Step 2: Process Trials with Optimized Breast Cancer Prompts\n",
    "\n",
    "Now we'll process the raw trial data using AI with breast cancer-optimized prompts and concurrent workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process trials with optimized breast cancer prompts and concurrent processing\n",
    "# Using IPython magic for streamlined execution\n",
    "\n",
    "print(\"ðŸ§ª Processing trials with breast cancer-optimized prompts (4 concurrent workers)...\")\n",
    "\n",
    "# Use optimized prompt for breast cancer trials\n",
    "!cd {PROJECT_ROOT} && python -m src.cli.trials_processor examples/demo_trials_raw.json --output examples/demo_trials_mcode.ndjson --model deepseek-coder --prompt direct_mcode_evidence_based_concise --workers 4 --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze the mCODE-processed trial data\n",
    "\n",
    "mcode_trials_file = PROJECT_ROOT / \"examples\" / \"demo_trials_mcode.ndjson\"\n",
    "mcode_trials = []\n",
    "\n",
    "if mcode_trials_file.exists():\n",
    "    with open(mcode_trials_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                mcode_trials.append(json.loads(line))\n",
    "    \n",
    "    print(f\"ðŸ“Š Processed {len(mcode_trials)} trials with mCODE mapping\")\n",
    "    \n",
    "    if mcode_trials:\n",
    "        trial = mcode_trials[0]\n",
    "        print(\"\\nðŸ”¬ Sample mCODE Trial:\")\n",
    "        print(f\"Trial ID: {trial.get('trial_id')}\")\n",
    "        \n",
    "        mcode_elements = trial.get('mcode_elements', {})\n",
    "        print(f\"mCODE elements found: {list(mcode_elements.keys())}\")\n",
    "        \n",
    "        # Show mCODE mappings\n",
    "        mappings = mcode_elements.get('mcode_mappings', [])\n",
    "        if mappings:\n",
    "            print(\"\\nðŸ“‹ First few mCODE mappings:\")\n",
    "            for mapping in mappings[:3]:\n",
    "                print(f\"  â€¢ {mapping.get('mcode_element')}: {mapping.get('value')}\")\n",
    "        \n",
    "        # Show processing metadata\n",
    "        if 'processing_metadata' in mcode_elements:\n",
    "            meta = mcode_elements['processing_metadata']\n",
    "            print(f\"\\nâš™ï¸ Processing metadata:\")\n",
    "            print(f\"  Model: {meta.get('model')}\")\n",
    "            print(f\"  Processing time: {meta.get('processing_time_seconds', 'N/A')}s\")\n",
    "            \n",
    "else:\n",
    "    print(\"âŒ mCODE trials file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¥ Step 3: Fetch and Process Patient Data\n",
    "\n",
    "Let's fetch synthetic patient data and process it with mCODE mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch synthetic patient data\n",
    "\n",
    "print(\"ðŸ¥ Fetching synthetic breast cancer patient data...\")\n",
    "\n",
    "!cd {PROJECT_ROOT} && python -m src.cli.patients_fetcher --archive breast_cancer_10_years --limit 5 --output examples/demo_patients_raw.json --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process patients with mCODE mapping and concurrent processing\n",
    "\n",
    "print(\"ðŸ§ª Processing patients with mCODE mapping (4 concurrent workers)...\")\n",
    "\n",
    "!cd {PROJECT_ROOT} && python -m src.cli.patients_processor --patients examples/demo_patients_raw.json --trials examples/demo_trials_mcode.ndjson --output examples/demo_patients_mcode.ndjson --workers 4 --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the processed patient data\n",
    "\n",
    "mcode_patients_file = PROJECT_ROOT / \"examples\" / \"demo_patients_mcode.ndjson\"\n",
    "mcode_patients = []\n",
    "\n",
    "if mcode_patients_file.exists():\n",
    "    with open(mcode_patients_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                mcode_patients.append(json.loads(line))\n",
    "    \n",
    "    print(f\"ðŸ“Š Processed {len(mcode_patients)} patients with mCODE mapping\")\n",
    "    \n",
    "    if mcode_patients:\n",
    "        patient = mcode_patients[0]\n",
    "        bundle = patient.get('patient_bundle', [])\n",
    "        \n",
    "        print(f\"\\nðŸ¥ Sample mCODE Patient:\")\n",
    "        print(f\"Patient bundle has {len(bundle)} mCODE entries\")\n",
    "        \n",
    "        # Count resource types\n",
    "        resource_types = {}\n",
    "        for entry in bundle:\n",
    "            rtype = entry.get('resource_type')\n",
    "            if rtype:\n",
    "                resource_types[rtype] = resource_types.get(rtype, 0) + 1\n",
    "        \n",
    "        print(f\"Resource types: {resource_types}\")\n",
    "        \n",
    "        # Show sample clinical data\n",
    "        print(\"\\nðŸ“‹ Sample clinical entries:\")\n",
    "        for entry in bundle[:3]:\n",
    "            rtype = entry.get('resource_type')\n",
    "            if rtype == 'Patient':\n",
    "                name = entry.get('name', {})\n",
    "                print(f\"  â€¢ Patient: {name.get('given', ['Unknown'])} {name.get('family', 'Unknown')}\")\n",
    "            elif rtype == 'Condition':\n",
    "                clinical_data = entry.get('clinical_data', {})\n",
    "                code = clinical_data.get('code', {}).get('text', 'Unknown')\n",
    "                print(f\"  â€¢ Condition: {code}\")\n",
    "            elif rtype in ['Observation', 'MedicationStatement']:\n",
    "                clinical_data = entry.get('clinical_data', {})\n",
    "                code_text = clinical_data.get('code', {}).get('text', 'Unknown')\n",
    "                print(f\"  â€¢ {rtype}: {code_text}\")\n",
    "                \n",
    "else:\n",
    "    print(\"âŒ mCODE patients file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Step 4: Store Patient and Trial Summaries in CORE Memory\n",
    "\n",
    "Let's store both patient and trial summaries directly in CORE Memory spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store trials in CORE Memory with summaries\n",
    "\n",
    "print(\"ðŸ§  Storing trials with summaries in CORE Memory...\")\n",
    "\n",
    "!cd {PROJECT_ROOT} && python -m src.cli.trials_processor examples/demo_trials_raw.json --ingest --model deepseek-coder --prompt direct_mcode_evidence_based_concise --workers 4 --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store patients in CORE Memory with summaries\n",
    "\n",
    "print(\"ðŸ¥ Storing patients with summaries in CORE Memory...\")\n",
    "\n",
    "!cd {PROJECT_ROOT} && python -m src.cli.patients_processor --patients examples/demo_patients_raw.json --trials examples/demo_trials_mcode.ndjson --ingest --workers 4 --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 5: Data Visualization and Analysis\n",
    "\n",
    "Let's create visualizations to understand the enhanced processing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations of the processed data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Analyze trial data\n",
    "if mcode_trials:\n",
    "    # Extract mCODE element types\n",
    "    element_types = []\n",
    "    for trial in mcode_trials:\n",
    "        mappings = trial.get('mcode_elements', {}).get('mcode_mappings', [])\n",
    "        for mapping in mappings:\n",
    "            element_types.append(mapping.get('mcode_element', 'Unknown'))\n",
    "    \n",
    "    # Count element types\n",
    "    element_counts = Counter(element_types)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(element_counts.keys(), element_counts.values())\n",
    "    plt.title('mCODE Elements in Clinical Trials (Optimized)')\n",
    "    plt.xlabel('Element Type')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"ðŸ“ˆ Found {len(element_counts)} different mCODE element types\")\n",
    "    print(\"Top elements:\", dict(element_counts.most_common(5)))\n",
    "else:\n",
    "    print(\"No trial data available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze patient data\n",
    "\n",
    "if mcode_patients:\n",
    "    # Extract resource types across all patients\n",
    "    all_resource_types = []\n",
    "    for patient in mcode_patients:\n",
    "        bundle = patient.get('patient_bundle', [])\n",
    "        for entry in bundle:\n",
    "            rtype = entry.get('resource_type')\n",
    "            if rtype:\n",
    "                all_resource_types.append(rtype)\n",
    "    \n",
    "    # Count resource types\n",
    "    resource_counts = Counter(all_resource_types)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(resource_counts.keys(), resource_counts.values())\n",
    "    plt.title('FHIR Resource Types in Patient Data (Enhanced)')\n",
    "    plt.xlabel('Resource Type')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"ðŸ“Š Found {len(resource_counts)} different FHIR resource types\")\n",
    "    print(\"Resource distribution:\", dict(resource_counts.most_common()))\n",
    "else:\n",
    "    print(\"No patient data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ” Step 6: Semantic Search and Analysis\n",
    "\n",
    "Now let's demonstrate semantic search capabilities across the stored data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate semantic search capabilities\n",
    "# Note: This requires CORE Memory to be properly configured\n",
    "\n",
    "try:\n",
    "    from src.utils.core_memory_client import CoreMemoryClient\n",
    "    \n",
    "    # Initialize client\n",
    "    client = CoreMemoryClient(\n",
    "        api_key=os.getenv('COREAI_API_KEY'),\n",
    "        base_url=\"https://core.heysol.ai/api/v1/mcp\"\n",
    "    )\n",
    "    \n",
    "    # Get space IDs\n",
    "    patients_space_id = client.get_patients_space_id()\n",
    "    trials_space_id = client.get_clinical_trials_space_id()\n",
    "    \n",
    "    print(\"ðŸ” Performing semantic searches...\")\n",
    "    \n",
    "    # Search for breast cancer in trials\n",
    "    print(\"\\nðŸ“‹ Searching for 'breast cancer' in clinical trials:\")\n",
    "    try:\n",
    "        results = client.search(\"breast cancer\", space_id=trials_space_id)\n",
    "        print(f\"Found {len(results.get('results', []))} results\")\n",
    "        if results.get('results'):\n",
    "            print(f\"Sample result: {results['results'][0].get('content', '')[:200]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Search failed: {e}\")\n",
    "    \n",
    "    # Search for treatment in patients\n",
    "    print(\"\\nðŸ¥ Searching for 'chemotherapy' in patient data:\")\n",
    "    try:\n",
    "        results = client.search(\"chemotherapy\", space_id=patients_space_id)\n",
    "        print(f\"Found {len(results.get('results', []))} results\")\n",
    "        if results.get('results'):\n",
    "            print(f\"Sample result: {results['results'][0].get('content', '')[:200]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Search failed: {e}\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"âŒ CORE Memory client not available\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ CORE Memory search failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Step 7: Performance Analysis and Process Management\n",
    "\n",
    "Let's analyze the performance and demonstrate process management techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance analysis and process management demonstration\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Calculate processing statistics\n",
    "stats = {\n",
    "    'trials_fetched': len(trials_raw) if 'trials_raw' in locals() else 0,\n",
    "    'trials_processed': len(mcode_trials) if 'mcode_trials' in locals() else 0,\n",
    "    'patients_fetched': len(mcode_patients) if 'mcode_patients' in locals() else 0,\n",
    "    'processing_timestamp': datetime.now().isoformat(),\n",
    "    'concurrent_workers': 4,\n",
    "    'optimized_prompts': True\n",
    "}\n",
    "\n",
    "# Calculate success rates\n",
    "if stats['trials_fetched'] > 0:\n",
    "    stats['trial_processing_success_rate'] = stats['trials_processed'] / stats['trials_fetched']\n",
    "else:\n",
    "    stats['trial_processing_success_rate'] = 0\n",
    "\n",
    "# Display statistics\n",
    "print(\"ðŸ“Š Enhanced Processing Statistics:\")\n",
    "print(f\"  Clinical Trials Fetched: {stats['trials_fetched']}\")\n",
    "print(f\"  Trials Processed with mCODE: {stats['trials_processed']}\")\n",
    "print(f\"  Patients Processed: {stats['patients_fetched']}\")\n",
    "print(f\"  Trial Processing Success Rate: {stats['trial_processing_success_rate']:.1%}\")\n",
    "print(f\"  Concurrent Workers Used: {stats['concurrent_workers']}\")\n",
    "print(f\"  Breast Cancer Optimized Prompts: {stats['optimized_prompts']}\")\n",
    "print(f\"  Processing Timestamp: {stats['processing_timestamp']}\")\n",
    "\n",
    "# Quality metrics\n",
    "if mcode_trials:\n",
    "    total_mappings = sum(len(trial.get('mcode_elements', {}).get('mcode_mappings', [])) \n",
    "                       for trial in mcode_trials)\n",
    "    avg_mappings_per_trial = total_mappings / len(mcode_trials)\n",
    "    print(f\"\\nðŸ”¬ Quality Metrics:\")\n",
    "    print(f\"  Total mCODE Mappings: {total_mappings}\")\n",
    "    print(f\"  Average Mappings per Trial: {avg_mappings_per_trial:.1f}\")\n",
    "\n",
    "# File sizes\n",
    "files_to_check = [\n",
    "    'examples/demo_trials_raw.json',\n",
    "    'examples/demo_trials_mcode.ndjson',\n",
    "    'examples/demo_patients_raw.json',\n",
    "    'examples/demo_patients_mcode.ndjson'\n",
    "]\n",
    "\n",
    "print(f\"\\nðŸ’¾ Generated Files:\")\n",
    "for file_path in files_to_check:\n",
    "    full_path = PROJECT_ROOT / file_path\n",
    "    if full_path.exists():\n",
    "        size = full_path.stat().st_size\n",
    "        print(f\"  âœ… {file_path}: {size} bytes\")\n",
    "    else:\n",
    "        print(f\"  âŒ {file_path}: not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process management demonstration\n",
    "\n",
    "print(\"ðŸ”§ Process Management Demonstration:\")\n",
    "print(\"\\n1. Check running processes:\")\n",
    "!ps aux | grep trials_processor | grep -v grep\n",
    "\n",
    "print(\"\\n2. Check file sizes:\")\n",
    "!ls -la examples/demo_trials_mcode.ndjson\n",
    "\n",
    "print(\"\\n3. Monitor system resources (if available):\")\n",
    "!df -h | head -5\n",
    "\n",
    "print(\"\\n4. Show recent log activity:\")\n",
    "!tail -10 /tmp/mcode_translator.log 2>/dev/null || echo \"No log file found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Conclusion and Advanced Features\n",
    "\n",
    "Congratulations! You've successfully completed an enhanced mCODE translation pipeline with advanced features.\n",
    "\n",
    "### âœ… What We Achieved\n",
    "\n",
    "1. **Concurrent Processing**: Utilized 4 workers for improved performance\n",
    "2. **Optimized Prompts**: Used breast cancer-specific prompt optimization\n",
    "3. **CORE Memory Integration**: Stored patient and trial summaries directly\n",
    "4. **Native IPython Commands**: Streamlined execution with `!python` magic\n",
    "5. **Process Management**: Demonstrated advanced monitoring techniques\n",
    "6. **Enhanced Visualization**: Created insights from optimized processing\n",
    "\n",
    "### ðŸš€ Advanced Features Demonstrated\n",
    "\n",
    "- **Multi-worker Processing**: `python -m src.cli.trials_processor --workers 4`\n",
    "- **Breast Cancer Optimization**: Specialized prompts for oncology data\n",
    "- **Direct CORE Memory Storage**: `--ingest` flag for immediate storage\n",
    "- **IPython Integration**: Native Jupyter magic commands\n",
    "- **Process Monitoring**: Real-time process management\n",
    "\n",
    "### ðŸ“š Key Commands Used\n",
    "\n",
    "```bash\n",
    "# Concurrent fetching\n",
    "python -m src.cli.trials_fetcher --condition \"breast cancer\" --workers 4\n",
    "\n",
    "# Optimized processing\n",
    "python -m src.cli.trials_processor --workers 4 --prompt direct_mcode_evidence_based_concise\n",
    "\n",
    "# Direct CORE Memory storage\n",
    "python -m src.cli.trials_processor --ingest --workers 4\n",
    "\n",
    "# Process monitoring\n",
    "ps aux | grep trials_processor\n",
    "```\n",
    "\n",
    "### ðŸ”§ Production Considerations\n",
    "\n",
    "- **Worker Scaling**: Adjust `--workers` based on system resources\n",
    "- **Memory Management**: Monitor RAM usage with concurrent processing\n",
    "- **API Rate Limits**: Respect ClinicalTrials.gov API limits\n",
    "- **Error Handling**: Implement retry logic for production deployments\n",
    "- **Monitoring**: Set up comprehensive logging and alerting\n",
    "\n",
    "### ðŸ“ž Support and Resources\n",
    "\n",
    "- **Documentation**: [mCODE Translator Docs](https://github.com/yourusername/mcode-translator)\n",
    "- **API Reference**: [ClinicalTrials.gov API](https://clinicaltrials.gov/data-api/)\n",
    "- **CORE Memory**: [Documentation](https://core.heysol.ai/)\n",
    "- **Issues**: [GitHub Issues](https://github.com/yourusername/mcode-translator/issues)\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸŽ¯ Ready to harness the power of concurrent, optimized mCODE processing!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}