# mCODE Translator v2.0

> **High-performance clinical trial data processing pipeline that extracts and maps eligibility criteria to standardized mCODE elements using evidence-based LLM processing.**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

## üöÄ Quick Start

```bash
# Clone and setup
git clone https://github.com/HadleyLab/mcode_translator.git
cd mcode_translator
pip install -r requirements.txt

# Configure API keys
cp .env.example .env
# Edit .env with your OPENAI_API_KEY or DEEPSEEK_API_KEY

# Process clinical trial data
python mcode_translate.py data/selected_breast_cancer_trials.json -o results.json
```

## üíª Usage

### mCODE Translator - Process Trial Data

```bash
# Basic processing
python mcode_translator.py trial_data.json -o results.json

# With specific model and prompt (using shorthands)
python mcode_translator.py trial_data.json -m deepseek-coder -p direct_mcode_evidence_based_concise -o results.json

# Batch processing
python mcode_translator.py trials_batch.json --batch -o batch_results.json
```

### mCODE Fetcher - Search and Process Trials

```bash
# Search and fetch trials
python mcode_fetcher.py --condition "breast cancer" --limit 10 -o results.json

# Search with concurrent mCODE processing
python mcode_fetcher.py --condition "lung cancer" --concurrent --process \
  --workers 8 -m deepseek-coder -o processed_results.json

# Fetch specific trials with processing
python mcode_fetcher.py --nct-ids "NCT001,NCT002,NCT003" --process -m deepseek-coder -p direct_mcode_evidence_based_concise -o trials.json

# Count available studies
python mcode_fetcher.py --condition "cancer" --count-only

# Store processed trials in CORE Memory with automatic duplicate detection
python mcode_fetcher.py --condition "breast cancer" --process --store-in-core-memory -m deepseek-coder

# Store a specific trial in CORE Memory
python mcode_fetcher.py --nct-id NCT00616135 --process --store-in-core-memory -m deepseek-coder
```

### mCODE Optimize - Cross-Validation Testing

```bash
# Full optimization across all prompt√ómodel combinations
python mcode_optimize.py data/selected_breast_cancer_trials.json --concurrent --detailed-report

# Quick optimization with limited combinations
python mcode_optimize.py data/selected_breast_cancer_trials.json --max-combinations 10 --concurrent

# Test specific models and prompts
python mcode_optimize.py data/selected_breast_cancer_trials.json --models deepseek-coder,gpt-4o \
  --prompts direct_mcode_evidence_based_concise,direct_mcode_simple \
  --detailed-report

# Set logging level (verbose)
python mcode_optimize.py data/selected_breast_cancer_trials.json --verbose
```

### Python API

```python
from src.pipeline import McodePipeline

# Initialize pipeline with evidence-based processing
pipeline = McodePipeline(
    prompt_name="direct_mcode_evidence_based_concise"
)

# Process trial data
result = pipeline.process_clinical_trial(trial_data)
print(f"Generated {len(result.mcode_mappings)} mCODE mappings")
print(f"Quality Score: {result.validation_results['compliance_score']:.3f}")
```

## üéØ Key Features

- **99.1% Quality Score** - Evidence-based processing with strict textual fidelity
- **Single-Step Pipeline** - Direct clinical text to mCODE mapping
- **Conservative Mapping** - Quality over quantity approach
- **Source Provenance** - Complete audit trail for all mappings
- **Production Ready** - Clean architecture with comprehensive error handling

## üìÅ Project Structure

```
mcode_translator/
‚îú‚îÄ‚îÄ mcode_translator.py             # Main CLI - Process trial data with mCODE
‚îú‚îÄ‚îÄ mcode_fetcher.py                # Fetcher CLI - Search and fetch trials
‚îú‚îÄ‚îÄ mcode_optimize.py               # Optimize CLI - Cross-Validation Testing
‚îú‚îÄ‚îÄ src/pipeline/                   # Core processing components
‚îÇ   ‚îú‚îÄ‚îÄ mcode_pipeline.py          # Main mCODE processing pipeline
‚îÇ   ‚îú‚îÄ‚îÄ llm_base.py            # LLM base
‚îÇ   ‚îú‚îÄ‚îÄ concurrent_fetcher.py      # Concurrent processing engine
‚îÇ   ‚îî‚îÄ‚îÄ fetcher.py                 # Core trial fetching functions
‚îú‚îÄ‚îÄ prompts/                        # Evidence-based prompt templates
‚îú‚îÄ‚îÄ models/                         # LLM model configurations
‚îú‚îÄ‚îÄ data/                           # Configuration and reference data
‚îî‚îÄ‚îÄ tests/                          # Test suite
```

## üìà Quality Metrics

| Metric | Score | Improvement |
|--------|-------|-------------|
| Overall Quality | 98.9% | +8.5 points |
| Source Text Fidelity | 99.2% | +8.5 points |
| Average Confidence | 98.2% | +8.6 points |
| Mapping Efficiency | 44.9% reduction in over-mapping | Quality over quantity |

*Validated across 5 comprehensive breast cancer clinical trials*

## üîß Configuration

### Environment Variables (.env)

```bash
# Required: Choose one LLM provider
OPENAI_API_KEY=your_openai_api_key
DEEPSEEK_API_KEY=your_deepseek_api_key
```

### Model Settings (models/models_config.json)

```json
{
  "models": {
    "deepseek-coder": {
      "provider": "deepseek",
      "max_tokens": 8000,
      "temperature": 0.1
    }
  }
}
```

## üß™ Testing

```bash
python -m pytest tests/
```

## üìÑ License

MIT License - see [LICENSE](LICENSE) file for details.

---

## ‚öôÔ∏è End-to-End Pipeline Guide

### Prerequisites

1.  **Python 3.8+**: Ensure you have Python 3.8 or a later version installed.
2.  **Dependencies**: Install the required dependencies using `pip install -r requirements.txt`.
3.  **API Keys**: Obtain API keys for your chosen LLM provider (e.g., OpenAI, DeepSeek) and set them as environment variables in a `.env` file.
4.  **Configuration**: Configure the pipeline settings in `config.json` and `models/models_config.json`, including API keys, model names, and other parameters.

### Step-by-Step Instructions

1.  **Clone the Repository**:

    ```bash
    git clone https://github.com/HadleyLab/mcode_translator.git
    cd mcode_translator
    ```
2.  **Set Up Environment**:

    ```bash
    # Create conda environment
    conda create -n mcode_translator python=3.11
    conda activate mcode_translator
    # Install dependencies
    pip install -r requirements.txt
    ```
3.  **Configure API Keys**:

    -   Copy the `.env.example` file to `.env` and edit it to include your API keys:

        ```bash
        cp .env.example .env
        nano .env  # Or your favorite text editor
        ```

    -   Ensure the `.env` file contains the necessary API keys for your chosen LLM provider:

        ```
        OPENAI_API_KEY=your_openai_api_key
        # Or
        DEEPSEEK_API_KEY=your_deepseek_api_key
        ```
4.  **Run the Pipeline**:

    -   Use the `mcode_translator.py` script to process clinical trial data:

        ```bash
        python mcode_translator.py data/selected_breast_cancer_trials.json -m deepseek-coder -o results.json
        ```

    -   You can also specify a model and prompt:

        ```bash
        python mcode_translator.py data/selected_breast_cancer_trials.json -m deepseek-coder -p direct_mcode_evidence_based_concise -o results.json
        ```

5.  **View the Results**:

    -   The processed mCODE mappings will be saved in the specified output file (e.g., `results.json`).

### Workflows

1.  **Basic mCODE Mapping**:

    -   Use the `mcode_translator.py` script to map clinical trial data to mCODE elements.

        ```bash
        python mcode_translator.py data/selected_breast_cancer_trials.json -m deepseek-coder -o results.json
        ```
2.  **Fetching and Processing Trials**:

    -   Use the `mcode_fetcher.py` script to search for clinical trials and process them:

        ```bash
        python mcode_fetcher.py --condition "breast cancer" --limit 10 --process -o results.json
        ```
3.  **CORE Memory Integration**:

    -   To store processed trials in CORE Memory, use the `--store-in-core-memory` flag:

        ```bash
        python mcode_fetcher.py --condition "breast cancer" --process --store-in-core-memory -m deepseek-coder
        ```

    -   Ensure you have the `COREAI_API_KEY` environment variable set.

### Error Handling

1.  **Missing API Keys**:

    -   If you encounter an error related to missing API keys, ensure you have set the `OPENAI_API_KEY` or `DEEPSEEK_API_KEY` environment variables in your `.env` file.
2.  **Configuration Errors**:

    -   If you encounter an error related to invalid configuration settings, check the `config.json` and `models/models_config.json` files for any inconsistencies or missing values.
3.  **Rate Limiting**:

    -   If you encounter rate limiting errors, adjust the `rate_limiting` settings in the `config.json` file.

### Validation

1.  **Compliance Scores**:

    -   The pipeline generates compliance scores to indicate the quality and completeness of the mCODE mappings. A higher compliance score indicates better mapping quality.
2.  **Error Reporting**:

    -   The pipeline provides detailed error messages and warnings to help you identify and resolve any issues with the mCODE mappings.

### CORE Memory Integration

1.  **Storing Data**:

    -   To store processed trials in CORE Memory, use the `--store-in-core-memory` flag with the `mcode_fetcher.py` script.
2.  **Automatic Duplicate Detection**:

    -   The pipeline automatically detects and prevents duplicate entries in CORE Memory based on trial identifiers.

### Retrieving Data from CORE Memory

1.  **Using CORE Memory Data**:

    -   To retrieve data from CORE Memory, you can use the CORE Memory API or command-line tools (coming soon).

    -   Once you have retrieved the data, you can use it as input for the `mcode_translator.py` script. For example:

        ```bash
        # Assuming you have retrieved data from CORE Memory and saved it to core_memory_data.json
        python mcode_translator.py core_memory_data.json -o results.json
        ```

    -   The `mcode_translator.py` script will process the data from CORE Memory and generate mCODE mappings.

---

**mCODE Translator v2.0** - Clinical trial data to standardized mCODE elements with 99.1% quality score.